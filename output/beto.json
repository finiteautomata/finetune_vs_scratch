{
    "context_hate": [
        {
            "eval_loss": 0.07986815273761749,
            "eval_calls_f1": 0.6690265486725663,
            "eval_women_f1": 0.4241164241164241,
            "eval_lgbti_f1": 0.47727272727272724,
            "eval_racism_f1": 0.6823770491803278,
            "eval_class_f1": 0.552901023890785,
            "eval_politics_f1": 0.6227347611202636,
            "eval_disabled_f1": 0.5376344086021505,
            "eval_appearance_f1": 0.72987012987013,
            "eval_criminal_f1": 0.6097560975609756,
            "eval_mean_f1": 0.589521050453186,
            "eval_mean_precision": 0.6040653586387634,
            "eval_mean_recall": 0.5804215669631958,
            "eval_hate_precision": 0.7032181168057211,
            "eval_hate_recall": 0.6566499721758486,
            "eval_hate_f1": 0.679136690647482,
            "eval_runtime": 93.8256,
            "eval_samples_per_second": 120.895,
            "eval_steps_per_second": 7.557
        },
        {
            "eval_loss": 0.07693415135145187,
            "eval_calls_f1": 0.6751361161524501,
            "eval_women_f1": 0.41276595744680855,
            "eval_lgbti_f1": 0.5026737967914437,
            "eval_racism_f1": 0.6962025316455697,
            "eval_class_f1": 0.5535055350553505,
            "eval_politics_f1": 0.6276595744680851,
            "eval_disabled_f1": 0.5671641791044777,
            "eval_appearance_f1": 0.72987012987013,
            "eval_criminal_f1": 0.6043613707165107,
            "eval_mean_f1": 0.5965932607650757,
            "eval_mean_precision": 0.6278746724128723,
            "eval_mean_recall": 0.5722306370735168,
            "eval_hate_precision": 0.7195345988977342,
            "eval_hate_recall": 0.6538675570395103,
            "eval_hate_f1": 0.685131195335277,
            "eval_runtime": 94.334,
            "eval_samples_per_second": 120.243,
            "eval_steps_per_second": 7.516
        },
        {
            "eval_loss": 0.07693415135145187,
            "eval_calls_f1": 0.6751361161524501,
            "eval_women_f1": 0.41276595744680855,
            "eval_lgbti_f1": 0.5026737967914437,
            "eval_racism_f1": 0.6962025316455697,
            "eval_class_f1": 0.5535055350553505,
            "eval_politics_f1": 0.6276595744680851,
            "eval_disabled_f1": 0.5671641791044777,
            "eval_appearance_f1": 0.72987012987013,
            "eval_criminal_f1": 0.6043613707165107,
            "eval_mean_f1": 0.5965932607650757,
            "eval_mean_precision": 0.6278746724128723,
            "eval_mean_recall": 0.5722306370735168,
            "eval_hate_precision": 0.7195345988977342,
            "eval_hate_recall": 0.6538675570395103,
            "eval_hate_f1": 0.685131195335277,
            "eval_runtime": 94.3515,
            "eval_samples_per_second": 120.221,
            "eval_steps_per_second": 7.514
        }
    ],
    "sentiment": [
        {
            "eval_loss": 1.62650728225708,
            "eval_neg_f1": 0.71708280941261,
            "eval_neg_precision": 0.7595129375951294,
            "eval_neg_recall": 0.6791425654984689,
            "eval_neu_f1": 0.5319148936170214,
            "eval_neu_precision": 0.4640151515151515,
            "eval_neu_recall": 0.6230925737538149,
            "eval_pos_f1": 0.7122847301951779,
            "eval_pos_precision": 0.7770541082164328,
            "eval_pos_recall": 0.6574819838914795,
            "eval_micro_f1": 0.6569383259911894,
            "eval_macro_f1": 0.6537608504295349,
            "eval_macro_precision": 0.6668607592582703,
            "eval_macro_recall": 0.6532390117645264,
            "eval_acc": 0.6569383259911894,
            "eval_runtime": 27.9005,
            "eval_samples_per_second": 260.354,
            "eval_steps_per_second": 8.136,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.62650728225708,
            "eval_neg_f1": 0.71708280941261,
            "eval_neg_precision": 0.7595129375951294,
            "eval_neg_recall": 0.6791425654984689,
            "eval_neu_f1": 0.5319148936170214,
            "eval_neu_precision": 0.4640151515151515,
            "eval_neu_recall": 0.6230925737538149,
            "eval_pos_f1": 0.7122847301951779,
            "eval_pos_precision": 0.7770541082164328,
            "eval_pos_recall": 0.6574819838914795,
            "eval_micro_f1": 0.6569383259911894,
            "eval_macro_f1": 0.6537608504295349,
            "eval_macro_precision": 0.6668607592582703,
            "eval_macro_recall": 0.6532390117645264,
            "eval_acc": 0.6569383259911894,
            "eval_runtime": 28.064,
            "eval_samples_per_second": 258.837,
            "eval_steps_per_second": 8.089,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.62650728225708,
            "eval_neg_f1": 0.71708280941261,
            "eval_neg_precision": 0.7595129375951294,
            "eval_neg_recall": 0.6791425654984689,
            "eval_neu_f1": 0.5319148936170214,
            "eval_neu_precision": 0.4640151515151515,
            "eval_neu_recall": 0.6230925737538149,
            "eval_pos_f1": 0.7122847301951779,
            "eval_pos_precision": 0.7770541082164328,
            "eval_pos_recall": 0.6574819838914795,
            "eval_micro_f1": 0.6569383259911894,
            "eval_macro_f1": 0.6537608504295349,
            "eval_macro_precision": 0.6668607592582703,
            "eval_macro_recall": 0.6532390117645264,
            "eval_acc": 0.6569383259911894,
            "eval_runtime": 28.0616,
            "eval_samples_per_second": 258.859,
            "eval_steps_per_second": 8.089,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.1286050081253052,
            "eval_others_f1": 0.7431906614785991,
            "eval_others_precision": 0.8013986013986014,
            "eval_others_recall": 0.6928657799274486,
            "eval_joy_f1": 0.647214854111406,
            "eval_joy_precision": 0.6224489795918368,
            "eval_joy_recall": 0.6740331491712708,
            "eval_sadness_f1": 0.7216981132075473,
            "eval_sadness_precision": 0.68,
            "eval_sadness_recall": 0.7688442211055276,
            "eval_anger_f1": 0.5854922279792746,
            "eval_anger_precision": 0.5231481481481481,
            "eval_anger_recall": 0.6647058823529411,
            "eval_surprise_f1": 0.4093567251461988,
            "eval_surprise_precision": 0.33980582524271846,
            "eval_surprise_recall": 0.5147058823529411,
            "eval_disgust_f1": 0.0,
            "eval_disgust_precision": 0.0,
            "eval_disgust_recall": 0.0,
            "eval_fear_f1": 0.5853658536585366,
            "eval_fear_precision": 0.5217391304347826,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6738223017292785,
            "eval_macro_f1": 0.527474045753479,
            "eval_macro_precision": 0.4983629584312439,
            "eval_macro_recall": 0.5688316226005554,
            "eval_acc": 0.6738223017292785,
            "eval_runtime": 6.87,
            "eval_samples_per_second": 244.105,
            "eval_steps_per_second": 15.284,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1286050081253052,
            "eval_others_f1": 0.7431906614785991,
            "eval_others_precision": 0.8013986013986014,
            "eval_others_recall": 0.6928657799274486,
            "eval_joy_f1": 0.647214854111406,
            "eval_joy_precision": 0.6224489795918368,
            "eval_joy_recall": 0.6740331491712708,
            "eval_sadness_f1": 0.7216981132075473,
            "eval_sadness_precision": 0.68,
            "eval_sadness_recall": 0.7688442211055276,
            "eval_anger_f1": 0.5854922279792746,
            "eval_anger_precision": 0.5231481481481481,
            "eval_anger_recall": 0.6647058823529411,
            "eval_surprise_f1": 0.4093567251461988,
            "eval_surprise_precision": 0.33980582524271846,
            "eval_surprise_recall": 0.5147058823529411,
            "eval_disgust_f1": 0.0,
            "eval_disgust_precision": 0.0,
            "eval_disgust_recall": 0.0,
            "eval_fear_f1": 0.5853658536585366,
            "eval_fear_precision": 0.5217391304347826,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6738223017292785,
            "eval_macro_f1": 0.527474045753479,
            "eval_macro_precision": 0.4983629584312439,
            "eval_macro_recall": 0.5688316226005554,
            "eval_acc": 0.6738223017292785,
            "eval_runtime": 6.6106,
            "eval_samples_per_second": 253.683,
            "eval_steps_per_second": 15.884,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1286050081253052,
            "eval_others_f1": 0.7431906614785991,
            "eval_others_precision": 0.8013986013986014,
            "eval_others_recall": 0.6928657799274486,
            "eval_joy_f1": 0.647214854111406,
            "eval_joy_precision": 0.6224489795918368,
            "eval_joy_recall": 0.6740331491712708,
            "eval_sadness_f1": 0.7216981132075473,
            "eval_sadness_precision": 0.68,
            "eval_sadness_recall": 0.7688442211055276,
            "eval_anger_f1": 0.5854922279792746,
            "eval_anger_precision": 0.5231481481481481,
            "eval_anger_recall": 0.6647058823529411,
            "eval_surprise_f1": 0.4093567251461988,
            "eval_surprise_precision": 0.33980582524271846,
            "eval_surprise_recall": 0.5147058823529411,
            "eval_disgust_f1": 0.0,
            "eval_disgust_precision": 0.0,
            "eval_disgust_recall": 0.0,
            "eval_fear_f1": 0.5853658536585366,
            "eval_fear_precision": 0.5217391304347826,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6738223017292785,
            "eval_macro_f1": 0.527474045753479,
            "eval_macro_precision": 0.4983629584312439,
            "eval_macro_recall": 0.5688316226005554,
            "eval_acc": 0.6738223017292785,
            "eval_runtime": 7.1904,
            "eval_samples_per_second": 233.228,
            "eval_steps_per_second": 14.603,
            "epoch": 5.0
        }
    ],
    "model_name": "dccuchile/bert-base-spanish-wwm-uncased"
}