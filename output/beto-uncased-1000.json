{
    "context_hate": [
        {
            "eval_loss": 0.07722792029380798,
            "eval_calls_f1": 0.6715063520871144,
            "eval_women_f1": 0.4279661016949153,
            "eval_lgbti_f1": 0.4615384615384616,
            "eval_racism_f1": 0.7002053388090349,
            "eval_class_f1": 0.48611111111111116,
            "eval_politics_f1": 0.6526315789473685,
            "eval_disabled_f1": 0.576388888888889,
            "eval_appearance_f1": 0.7454068241469817,
            "eval_criminal_f1": 0.6300148588410104,
            "eval_mean_f1": 0.5946410298347473,
            "eval_mean_precision": 0.6146798729896545,
            "eval_mean_recall": 0.5807741284370422,
            "eval_hate_precision": 0.7170035671819263,
            "eval_hate_recall": 0.671118530884808,
            "eval_hate_f1": 0.6933026731819488,
            "eval_runtime": 33.253,
            "eval_samples_per_second": 341.112,
            "eval_steps_per_second": 21.321
        },
        {
            "eval_loss": 0.07825862616300583,
            "eval_calls_f1": 0.6844919786096257,
            "eval_women_f1": 0.4197530864197531,
            "eval_lgbti_f1": 0.4899135446685879,
            "eval_racism_f1": 0.6959921798631475,
            "eval_class_f1": 0.4761904761904762,
            "eval_politics_f1": 0.6130653266331658,
            "eval_disabled_f1": 0.5551601423487543,
            "eval_appearance_f1": 0.7468030690537083,
            "eval_criminal_f1": 0.6381842456608812,
            "eval_mean_f1": 0.5910615921020508,
            "eval_mean_precision": 0.5920636057853699,
            "eval_mean_recall": 0.5948368906974792,
            "eval_hate_precision": 0.6911519198664441,
            "eval_hate_recall": 0.6911519198664441,
            "eval_hate_f1": 0.6911519198664441,
            "eval_runtime": 33.1293,
            "eval_samples_per_second": 342.386,
            "eval_steps_per_second": 21.401
        },
        {
            "eval_loss": 0.07774697989225388,
            "eval_calls_f1": 0.6655052264808362,
            "eval_women_f1": 0.43700787401574803,
            "eval_lgbti_f1": 0.5139664804469274,
            "eval_racism_f1": 0.6925315227934045,
            "eval_class_f1": 0.514657980456026,
            "eval_politics_f1": 0.6450511945392492,
            "eval_disabled_f1": 0.5422535211267605,
            "eval_appearance_f1": 0.736318407960199,
            "eval_criminal_f1": 0.6464924346629985,
            "eval_mean_f1": 0.5993094444274902,
            "eval_mean_precision": 0.5918756127357483,
            "eval_mean_recall": 0.6103340983390808,
            "eval_hate_precision": 0.6861471861471862,
            "eval_hate_recall": 0.7056204785754034,
            "eval_hate_f1": 0.6957475994513032,
            "eval_runtime": 33.1457,
            "eval_samples_per_second": 342.216,
            "eval_steps_per_second": 21.39
        }
    ],
    "sentiment": [
        {
            "eval_loss": 1.4834702014923096,
            "eval_neg_f1": 0.7534175462882852,
            "eval_neg_precision": 0.7665492957746479,
            "eval_neg_recall": 0.7407281388227288,
            "eval_neu_f1": 0.5231724796942189,
            "eval_neu_precision": 0.49324324324324326,
            "eval_neu_recall": 0.556968463886063,
            "eval_pos_f1": 0.732851194389656,
            "eval_pos_precision": 0.7586206896551724,
            "eval_pos_recall": 0.708774904620602,
            "eval_micro_f1": 0.6806167400881057,
            "eval_macro_f1": 0.6698138117790222,
            "eval_macro_precision": 0.6728044152259827,
            "eval_macro_recall": 0.6688238978385925,
            "eval_acc": 0.6806167400881057,
            "eval_runtime": 8.5823,
            "eval_samples_per_second": 846.396,
            "eval_steps_per_second": 26.45,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.752494752407074,
            "eval_neg_f1": 0.766847915636843,
            "eval_neg_precision": 0.7434504792332268,
            "eval_neg_recall": 0.7917659067710106,
            "eval_neu_f1": 0.5297709923664122,
            "eval_neu_precision": 0.530040733197556,
            "eval_neu_recall": 0.529501525940997,
            "eval_pos_f1": 0.7396776330315743,
            "eval_pos_precision": 0.771889400921659,
            "eval_pos_recall": 0.7100466299279355,
            "eval_micro_f1": 0.6942455947136564,
            "eval_macro_f1": 0.6787655353546143,
            "eval_macro_precision": 0.6817935109138489,
            "eval_macro_recall": 0.677104651927948,
            "eval_acc": 0.6942455947136564,
            "eval_runtime": 8.5484,
            "eval_samples_per_second": 849.749,
            "eval_steps_per_second": 26.555,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.650973916053772,
            "eval_neg_f1": 0.7257793541161098,
            "eval_neg_precision": 0.8039702233250621,
            "eval_neg_recall": 0.6614494726097312,
            "eval_neu_f1": 0.5399872040946897,
            "eval_neu_precision": 0.4649283878075652,
            "eval_neu_recall": 0.6439471007121058,
            "eval_pos_f1": 0.7336010709504684,
            "eval_pos_precision": 0.7743758831841734,
            "eval_pos_recall": 0.6969054684188215,
            "eval_micro_f1": 0.6682268722466961,
            "eval_macro_f1": 0.6664559245109558,
            "eval_macro_precision": 0.6810914874076843,
            "eval_macro_recall": 0.66743403673172,
            "eval_acc": 0.6682268722466961,
            "eval_runtime": 8.5526,
            "eval_samples_per_second": 849.336,
            "eval_steps_per_second": 26.542,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.6322158575057983,
            "eval_others_f1": 0.7539779681762546,
            "eval_others_precision": 0.7633209417596035,
            "eval_others_recall": 0.7448609431680774,
            "eval_joy_f1": 0.6551264980026632,
            "eval_joy_precision": 0.6323907455012854,
            "eval_joy_recall": 0.6795580110497238,
            "eval_sadness_f1": 0.75,
            "eval_sadness_precision": 0.746268656716418,
            "eval_sadness_recall": 0.7537688442211056,
            "eval_anger_f1": 0.6174142480211081,
            "eval_anger_precision": 0.5598086124401914,
            "eval_anger_recall": 0.6882352941176471,
            "eval_surprise_f1": 0.34285714285714286,
            "eval_surprise_precision": 0.4864864864864865,
            "eval_surprise_recall": 0.2647058823529412,
            "eval_disgust_f1": 0.0,
            "eval_disgust_precision": 0.0,
            "eval_disgust_recall": 0.0,
            "eval_fear_f1": 0.5531914893617021,
            "eval_fear_precision": 0.4482758620689655,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.691711389385808,
            "eval_macro_f1": 0.5246524810791016,
            "eval_macro_precision": 0.5195073485374451,
            "eval_macro_recall": 0.5504787564277649,
            "eval_acc": 0.691711389385808,
            "eval_runtime": 3.476,
            "eval_samples_per_second": 482.445,
            "eval_steps_per_second": 30.207,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.6855864524841309,
            "eval_others_f1": 0.7669724770642202,
            "eval_others_precision": 0.775990099009901,
            "eval_others_recall": 0.7581620314389359,
            "eval_joy_f1": 0.6901217861975644,
            "eval_joy_precision": 0.6763925729442971,
            "eval_joy_recall": 0.7044198895027625,
            "eval_sadness_f1": 0.7635467980295566,
            "eval_sadness_precision": 0.748792270531401,
            "eval_sadness_recall": 0.7788944723618091,
            "eval_anger_f1": 0.6174863387978142,
            "eval_anger_precision": 0.576530612244898,
            "eval_anger_recall": 0.6647058823529411,
            "eval_surprise_f1": 0.3636363636363637,
            "eval_surprise_precision": 0.47619047619047616,
            "eval_surprise_recall": 0.29411764705882354,
            "eval_disgust_f1": 0.08333333333333333,
            "eval_disgust_precision": 0.13333333333333333,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.4800000000000001,
            "eval_fear_precision": 0.375,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.7060226595110316,
            "eval_macro_f1": 0.5378710031509399,
            "eval_macro_precision": 0.5374613404273987,
            "eval_macro_recall": 0.5610818266868591,
            "eval_acc": 0.7060226595110316,
            "eval_runtime": 3.4778,
            "eval_samples_per_second": 482.199,
            "eval_steps_per_second": 30.191,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.7436879873275757,
            "eval_others_f1": 0.7574626865671642,
            "eval_others_precision": 0.7797695262483995,
            "eval_others_recall": 0.7363966142684402,
            "eval_joy_f1": 0.6814621409921671,
            "eval_joy_precision": 0.6460396039603961,
            "eval_joy_recall": 0.7209944751381215,
            "eval_sadness_f1": 0.7638190954773869,
            "eval_sadness_precision": 0.7638190954773869,
            "eval_sadness_recall": 0.7638190954773869,
            "eval_anger_f1": 0.6005221932114883,
            "eval_anger_precision": 0.539906103286385,
            "eval_anger_recall": 0.6764705882352942,
            "eval_surprise_f1": 0.37037037037037035,
            "eval_surprise_precision": 0.5,
            "eval_surprise_recall": 0.29411764705882354,
            "eval_disgust_f1": 0.08888888888888888,
            "eval_disgust_precision": 0.16666666666666666,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.5652173913043479,
            "eval_fear_precision": 0.4642857142857143,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.6988670244484197,
            "eval_macro_f1": 0.5468204021453857,
            "eval_macro_precision": 0.5514980554580688,
            "eval_macro_recall": 0.5678038001060486,
            "eval_acc": 0.6988670244484197,
            "eval_runtime": 3.4775,
            "eval_samples_per_second": 482.243,
            "eval_steps_per_second": 30.194,
            "epoch": 5.0
        }
    ],
    "model_name": "models/beto-uncased-1000/"
}