{
    "context_hate": [
        {
            "eval_loss": 0.3822495937347412,
            "eval_calls_f1": 0.0,
            "eval_women_f1": 0.0,
            "eval_lgbti_f1": 0.0,
            "eval_racism_f1": 0.0,
            "eval_class_f1": 0.0,
            "eval_politics_f1": 0.0,
            "eval_disabled_f1": 0.0,
            "eval_appearance_f1": 0.0,
            "eval_criminal_f1": 0.0,
            "eval_mean_f1": 0.0,
            "eval_mean_precision": 0.0,
            "eval_mean_recall": 0.0,
            "eval_hate_precision": 0.0,
            "eval_hate_recall": 0.0,
            "eval_hate_f1": 0.0,
            "eval_runtime": 1.5166,
            "eval_samples_per_second": 329.682,
            "eval_steps_per_second": 21.1
        },
        {
            "eval_loss": 0.3559109568595886,
            "eval_calls_f1": 0.0,
            "eval_women_f1": 0.0,
            "eval_lgbti_f1": 0.0,
            "eval_racism_f1": 0.0,
            "eval_class_f1": 0.0,
            "eval_politics_f1": 0.0,
            "eval_disabled_f1": 0.0,
            "eval_appearance_f1": 0.0,
            "eval_criminal_f1": 0.0,
            "eval_mean_f1": 0.0,
            "eval_mean_precision": 0.0,
            "eval_mean_recall": 0.0,
            "eval_hate_precision": 0.0,
            "eval_hate_recall": 0.0,
            "eval_hate_f1": 0.0,
            "eval_runtime": 1.5216,
            "eval_samples_per_second": 328.602,
            "eval_steps_per_second": 21.03
        }
    ],
    "hate": [
        {
            "eval_loss": 0.5812305212020874,
            "eval_ok_f1": 0.7889908256880734,
            "eval_ok_precision": 0.8242811501597445,
            "eval_ok_recall": 0.7565982404692082,
            "eval_hateful_f1": 0.6011560693641619,
            "eval_hateful_precision": 0.5561497326203209,
            "eval_hateful_recall": 0.6540880503144654,
            "eval_micro_f1": 0.724,
            "eval_macro_f1": 0.6950734853744507,
            "eval_macro_precision": 0.6902154684066772,
            "eval_macro_recall": 0.7053431272506714,
            "eval_acc": 0.724,
            "eval_runtime": 0.7169,
            "eval_samples_per_second": 697.401,
            "eval_steps_per_second": 44.634,
            "epoch": 2.0
        },
        {
            "eval_loss": 0.6007808446884155,
            "eval_ok_f1": 0.7957957957957957,
            "eval_ok_precision": 0.8153846153846154,
            "eval_ok_recall": 0.7771260997067448,
            "eval_hateful_f1": 0.592814371257485,
            "eval_hateful_precision": 0.5657142857142857,
            "eval_hateful_recall": 0.6226415094339622,
            "eval_micro_f1": 0.728,
            "eval_macro_f1": 0.6943050622940063,
            "eval_macro_precision": 0.6905494928359985,
            "eval_macro_recall": 0.6998838186264038,
            "eval_acc": 0.728,
            "eval_runtime": 0.7719,
            "eval_samples_per_second": 647.794,
            "eval_steps_per_second": 41.459,
            "epoch": 2.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 0.9266363978385925,
            "eval_neg_f1": 0.684759916492693,
            "eval_neg_precision": 0.5714285714285714,
            "eval_neg_recall": 0.8541666666666666,
            "eval_neu_f1": 0.10989010989010987,
            "eval_neu_precision": 0.5,
            "eval_neu_recall": 0.06172839506172839,
            "eval_pos_f1": 0.6312684365781711,
            "eval_pos_precision": 0.5544041450777202,
            "eval_pos_recall": 0.7328767123287672,
            "eval_micro_f1": 0.562,
            "eval_macro_f1": 0.4753061532974243,
            "eval_macro_precision": 0.5419442057609558,
            "eval_macro_recall": 0.5495905876159668,
            "eval_acc": 0.562,
            "eval_runtime": 0.634,
            "eval_samples_per_second": 788.597,
            "eval_steps_per_second": 50.47,
            "epoch": 2.0
        },
        {
            "eval_loss": 0.9211617708206177,
            "eval_neg_f1": 0.6950959488272922,
            "eval_neg_precision": 0.5884476534296029,
            "eval_neg_recall": 0.8489583333333334,
            "eval_neu_f1": 0.12154696132596685,
            "eval_neu_precision": 0.5789473684210527,
            "eval_neu_recall": 0.06790123456790123,
            "eval_pos_f1": 0.6114285714285714,
            "eval_pos_precision": 0.5245098039215687,
            "eval_pos_recall": 0.7328767123287672,
            "eval_micro_f1": 0.562,
            "eval_macro_f1": 0.4760238230228424,
            "eval_macro_precision": 0.5639682412147522,
            "eval_macro_recall": 0.5499120950698853,
            "eval_acc": 0.562,
            "eval_runtime": 0.718,
            "eval_samples_per_second": 696.397,
            "eval_steps_per_second": 44.569,
            "epoch": 2.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.9113014936447144,
            "eval_others_f1": 0.4932975871313673,
            "eval_others_precision": 0.5822784810126582,
            "eval_others_recall": 0.42790697674418604,
            "eval_joy_f1": 0.36363636363636365,
            "eval_joy_precision": 0.5909090909090909,
            "eval_joy_recall": 0.26262626262626265,
            "eval_sadness_f1": 0.451063829787234,
            "eval_sadness_precision": 0.3464052287581699,
            "eval_sadness_recall": 0.6463414634146342,
            "eval_anger_f1": 0.21951219512195122,
            "eval_anger_precision": 0.32142857142857145,
            "eval_anger_recall": 0.16666666666666666,
            "eval_surprise_f1": 0.09523809523809523,
            "eval_surprise_precision": 0.2,
            "eval_surprise_recall": 0.0625,
            "eval_disgust_f1": 0.017241379310344827,
            "eval_disgust_precision": 0.009345794392523364,
            "eval_disgust_recall": 0.1111111111111111,
            "eval_fear_f1": 0.0,
            "eval_fear_precision": 0.0,
            "eval_fear_recall": 0.0,
            "eval_micro_f1": 0.366,
            "eval_macro_f1": 0.2342842072248459,
            "eval_macro_precision": 0.2929095923900604,
            "eval_macro_recall": 0.23959319293498993,
            "eval_acc": 0.366,
            "eval_runtime": 1.1472,
            "eval_samples_per_second": 435.825,
            "eval_steps_per_second": 27.893,
            "epoch": 2.0
        },
        {
            "eval_loss": 1.7949028015136719,
            "eval_others_f1": 0.2857142857142857,
            "eval_others_precision": 0.7450980392156863,
            "eval_others_recall": 0.17674418604651163,
            "eval_joy_f1": 0.44571428571428573,
            "eval_joy_precision": 0.5131578947368421,
            "eval_joy_recall": 0.3939393939393939,
            "eval_sadness_f1": 0.6224489795918368,
            "eval_sadness_precision": 0.5350877192982456,
            "eval_sadness_recall": 0.7439024390243902,
            "eval_anger_f1": 0.3769633507853403,
            "eval_anger_precision": 0.26277372262773724,
            "eval_anger_recall": 0.6666666666666666,
            "eval_surprise_f1": 0.21739130434782608,
            "eval_surprise_precision": 0.16666666666666666,
            "eval_surprise_recall": 0.3125,
            "eval_disgust_f1": 0.028169014084507043,
            "eval_disgust_precision": 0.016129032258064516,
            "eval_disgust_recall": 0.1111111111111111,
            "eval_fear_f1": 0.0,
            "eval_fear_precision": 0.0,
            "eval_fear_recall": 0.0,
            "eval_micro_f1": 0.37,
            "eval_macro_f1": 0.2823430597782135,
            "eval_macro_precision": 0.31984472274780273,
            "eval_macro_recall": 0.34355196356773376,
            "eval_acc": 0.37,
            "eval_runtime": 1.1846,
            "eval_samples_per_second": 422.101,
            "eval_steps_per_second": 27.014,
            "epoch": 2.0
        }
    ],
    "model_name": "dccuchile/bert-base-spanish-wwm-uncased"
}