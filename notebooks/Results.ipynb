{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bertin\n",
      "beto-cased-10000\n",
      "beto-cased-20000\n",
      "beto-cased-2500\n",
      "beto-cased-5000\n",
      "beto-cased\n",
      "beto-uncased-10000\n",
      "beto-uncased-20000\n",
      "beto-uncased-2500\n",
      "beto-uncased-5000\n",
      "beto-uncased\n",
      "roberta-bne\n",
      "robertuito-cased\n",
      "robertuito-deacc\n",
      "robertuito-uncased-200k\n",
      "robertuito-uncased\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "outs = {}\n",
    "\n",
    "\n",
    "for filename in sorted([f for f in glob.glob(\"../output/*.json\") if \"test\" not in f]): \n",
    "    model_name = os.path.basename(filename).split(\".\")[0]\n",
    "    print(model_name)\n",
    "    with open(filename) as f:\n",
    "        outs[model_name] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"beto-uncased\", \"beto-uncased-2500\", \"beto-uncased-5000\", \"beto-uncased-10000\", \"beto-uncased-20000\",\n",
    "    \"beto-cased\", \"\"\n",
    "]\n",
    "task_metrics = {\n",
    "    \"context_hate\": [\"eval_mean_f1\"],\n",
    "    \"hate\": [\"eval_macro_f1\"],\n",
    "    \"sentiment\": [\"eval_macro_f1\"],\n",
    "    \"emotion\": [\"eval_macro_f1\"],\n",
    "    \"irony\": [\"eval_macro_f1\"],\n",
    "}\n",
    "\n",
    "for model in \n",
    "for task in task_metrics:\n",
    "    task_df = pd.DataFrame()\n",
    "    for metric in task_metrics[task]:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>case</th>\n",
       "      <th>task</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beto-cased</td>\n",
       "      <td>cased</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.582463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beto-cased</td>\n",
       "      <td>cased</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.591472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beto-cased</td>\n",
       "      <td>cased</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.576967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beto-cased</td>\n",
       "      <td>cased</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.582129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beto-cased</td>\n",
       "      <td>cased</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.584909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>uncased</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.708376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>uncased</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.700625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>uncased</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.706693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>uncased</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.710184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>uncased</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.701374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model     case          task     score\n",
       "0            beto-cased    cased  context_hate  0.582463\n",
       "1            beto-cased    cased  context_hate  0.591472\n",
       "2            beto-cased    cased  context_hate  0.576967\n",
       "3            beto-cased    cased  context_hate  0.582129\n",
       "4            beto-cased    cased  context_hate  0.584909\n",
       "..                  ...      ...           ...       ...\n",
       "445  beto-uncased-20000  uncased         irony  0.708376\n",
       "446  beto-uncased-20000  uncased         irony  0.700625\n",
       "447  beto-uncased-20000  uncased         irony  0.706693\n",
       "448  beto-uncased-20000  uncased         irony  0.710184\n",
       "449  beto-uncased-20000  uncased         irony  0.701374\n",
       "\n",
       "[450 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_df = df.melt(id_vars=[\"model\", \"case\"], var_name=\"task\", value_name=\"score\")\n",
    "\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beto-cased-2500</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.582009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beto-cased-2500</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.584450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beto-cased-2500</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.571173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beto-cased-2500</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.581049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beto-cased-2500</td>\n",
       "      <td>context_hate</td>\n",
       "      <td>0.586048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.708376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.700625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.706693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.710184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>beto-uncased-20000</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.701374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model      variable     value\n",
       "0       beto-cased-2500  context_hate  0.582009\n",
       "1       beto-cased-2500  context_hate  0.584450\n",
       "2       beto-cased-2500  context_hate  0.571173\n",
       "3       beto-cased-2500  context_hate  0.581049\n",
       "4       beto-cased-2500  context_hate  0.586048\n",
       "..                  ...           ...       ...\n",
       "395  beto-uncased-20000         irony  0.708376\n",
       "396  beto-uncased-20000         irony  0.700625\n",
       "397  beto-uncased-20000         irony  0.706693\n",
       "398  beto-uncased-20000         irony  0.710184\n",
       "399  beto-uncased-20000         irony  0.701374\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.melt(id_vars=[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/finetune-vs-scratch-gHiQbun3-py3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/finetune-vs-scratch-gHiQbun3-py3.7/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/finetune-vs-scratch-gHiQbun3-py3.7/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'variable'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_314211/927085543.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcased_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-cased\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"variable\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"hate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m sns.barplot(\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/finetune-vs-scratch-gHiQbun3-py3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3453\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3454\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3455\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/finetune-vs-scratch-gHiQbun3-py3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'variable'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_hate mean_f1</th>\n",
       "      <th>hate macro_f1</th>\n",
       "      <th>sentiment macro_f1</th>\n",
       "      <th>emotion macro_f1</th>\n",
       "      <th>irony macro_f1</th>\n",
       "      <th>score</th>\n",
       "      <th>score2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto-uncased</th>\n",
       "      <td>0.590 +- 0.006</td>\n",
       "      <td>0.756 +- 0.011</td>\n",
       "      <td>0.648 +- 0.005</td>\n",
       "      <td>0.520 +- 0.006</td>\n",
       "      <td>0.703 +- 0.007</td>\n",
       "      <td>0.643285</td>\n",
       "      <td>0.656722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.558 +- 0.008</td>\n",
       "      <td>0.766 +- 0.005</td>\n",
       "      <td>0.664 +- 0.003</td>\n",
       "      <td>0.517 +- 0.011</td>\n",
       "      <td>0.715 +- 0.008</td>\n",
       "      <td>0.644139</td>\n",
       "      <td>0.665697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased</th>\n",
       "      <td>0.584 +- 0.005</td>\n",
       "      <td>0.765 +- 0.010</td>\n",
       "      <td>0.665 +- 0.003</td>\n",
       "      <td>0.526 +- 0.008</td>\n",
       "      <td>0.707 +- 0.007</td>\n",
       "      <td>0.649226</td>\n",
       "      <td>0.665636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-bne</th>\n",
       "      <td>0.578 +- 0.004</td>\n",
       "      <td>0.767 +- 0.015</td>\n",
       "      <td>0.667 +- 0.007</td>\n",
       "      <td>0.535 +- 0.012</td>\n",
       "      <td>0.723 +- 0.016</td>\n",
       "      <td>0.654161</td>\n",
       "      <td>0.673217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-5000</th>\n",
       "      <td>0.576 +- 0.002</td>\n",
       "      <td>0.783 +- 0.010</td>\n",
       "      <td>0.677 +- 0.004</td>\n",
       "      <td>0.524 +- 0.015</td>\n",
       "      <td>0.723 +- 0.008</td>\n",
       "      <td>0.656472</td>\n",
       "      <td>0.676619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-10000</th>\n",
       "      <td>0.589 +- 0.003</td>\n",
       "      <td>0.772 +- 0.017</td>\n",
       "      <td>0.680 +- 0.004</td>\n",
       "      <td>0.553 +- 0.008</td>\n",
       "      <td>0.716 +- 0.006</td>\n",
       "      <td>0.661718</td>\n",
       "      <td>0.679986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-cased</th>\n",
       "      <td>0.590 +- 0.005</td>\n",
       "      <td>0.789 +- 0.014</td>\n",
       "      <td>0.700 +- 0.012</td>\n",
       "      <td>0.521 +- 0.032</td>\n",
       "      <td>0.722 +- 0.021</td>\n",
       "      <td>0.664466</td>\n",
       "      <td>0.683070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-deacc</th>\n",
       "      <td>0.594 +- 0.006</td>\n",
       "      <td>0.800 +- 0.008</td>\n",
       "      <td>0.702 +- 0.004</td>\n",
       "      <td>0.545 +- 0.013</td>\n",
       "      <td>0.739 +- 0.005</td>\n",
       "      <td>0.675947</td>\n",
       "      <td>0.696315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-uncased</th>\n",
       "      <td>0.592 +- 0.005</td>\n",
       "      <td>0.800 +- 0.008</td>\n",
       "      <td>0.707 +- 0.005</td>\n",
       "      <td>0.546 +- 0.011</td>\n",
       "      <td>0.737 +- 0.009</td>\n",
       "      <td>0.676655</td>\n",
       "      <td>0.697717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   context_hate mean_f1   hate macro_f1 sentiment macro_f1  \\\n",
       "model                                                                        \n",
       "beto-uncased             0.590 +- 0.006  0.756 +- 0.011     0.648 +- 0.005   \n",
       "bertin                   0.558 +- 0.008  0.766 +- 0.005     0.664 +- 0.003   \n",
       "beto-cased               0.584 +- 0.005  0.765 +- 0.010     0.665 +- 0.003   \n",
       "roberta-bne              0.578 +- 0.004  0.767 +- 0.015     0.667 +- 0.007   \n",
       "beto-cased-5000          0.576 +- 0.002  0.783 +- 0.010     0.677 +- 0.004   \n",
       "beto-uncased-10000       0.589 +- 0.003  0.772 +- 0.017     0.680 +- 0.004   \n",
       "robertuito-cased         0.590 +- 0.005  0.789 +- 0.014     0.700 +- 0.012   \n",
       "robertuito-deacc         0.594 +- 0.006  0.800 +- 0.008     0.702 +- 0.004   \n",
       "robertuito-uncased       0.592 +- 0.005  0.800 +- 0.008     0.707 +- 0.005   \n",
       "\n",
       "                   emotion macro_f1  irony macro_f1     score    score2  \n",
       "model                                                                    \n",
       "beto-uncased         0.520 +- 0.006  0.703 +- 0.007  0.643285  0.656722  \n",
       "bertin               0.517 +- 0.011  0.715 +- 0.008  0.644139  0.665697  \n",
       "beto-cased           0.526 +- 0.008  0.707 +- 0.007  0.649226  0.665636  \n",
       "roberta-bne          0.535 +- 0.012  0.723 +- 0.016  0.654161  0.673217  \n",
       "beto-cased-5000      0.524 +- 0.015  0.723 +- 0.008  0.656472  0.676619  \n",
       "beto-uncased-10000   0.553 +- 0.008  0.716 +- 0.006  0.661718  0.679986  \n",
       "robertuito-cased     0.521 +- 0.032  0.722 +- 0.021  0.664466  0.683070  \n",
       "robertuito-deacc     0.545 +- 0.013  0.739 +- 0.005  0.675947  0.696315  \n",
       "robertuito-uncased   0.546 +- 0.011  0.737 +- 0.009  0.676655  0.697717  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "resume = []\n",
    "mean_resume = []\n",
    "task_metrics = {\n",
    "    \"context_hate\": [\"eval_mean_f1\", \"eval_hate_f1\"],\n",
    "    \"hate\": [\"eval_hateful_f1\", \"eval_macro_f1\"],\n",
    "    \"sentiment\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"emotion\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"irony\": [\"eval_ironic_f1\", \"eval_macro_f1\"],\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, output in outs.items():\n",
    "    line = {\n",
    "        \"model\": model_name, \n",
    "    }\n",
    "\n",
    "    mean_line = {\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "\n",
    "    for task, metrics in task_metrics.items():\n",
    "        try:\n",
    "            for metric in metrics:\n",
    "                arr = np.array([evaluation[metric] for evaluation in output[task]])\n",
    "                metric_name = metric.replace(\"eval_\", \"\")\n",
    "                mean_line[task+\" \"+metric_name] = arr.mean()\n",
    "                line[task+\" \"+metric_name] = f\"{arr.mean():.3f} +- {arr.std():.3f}\"\n",
    "        except KeyError as e:\n",
    "            print(e, \"not in \", model_name)\n",
    "            continue\n",
    "    resume.append(line)\n",
    "    mean_resume.append(mean_line)\n",
    "\n",
    "order = [\n",
    "    \"bertin\",\n",
    "    \"roberta-bne\",\n",
    "    \"beto-uncased\",\n",
    "    # Nos quedamos con uncased-10000 que es el mejor\n",
    "    #\"beto-uncased-2500\",\n",
    "    #\"beto-uncased-5000\",\n",
    "    \"beto-uncased-10000\",\n",
    "    #\"beto-uncased-20000\",\n",
    "    \"robertuito-uncased\",\n",
    "    #\"robertuito-deacc-288k\",\n",
    "    #\"robertuito-deacc-344k\",\n",
    "    #\"robertuito-deacc-400k\",\n",
    "    #\"robertuito-deacc-440k\",\n",
    "    #\"robertuito-deacc-490k\",\n",
    "    #\"robertuito-deacc-510k\",\n",
    "    #\"robertuito-deacc-540k\",\n",
    "    #\"robertuito-deacc-576k\",\n",
    "    #\"robertuito-deacc-592k\",\n",
    "    \"robertuito-deacc\",\n",
    "    #\"checkpoint-46k\",\n",
    "    #\"checkpoint-62k\",\n",
    "    #\"checkpoint-87k\",\n",
    "    #\"checkpoint-100k\",\n",
    "    #\"checkpoint-124k\",\n",
    "    #\"robertuito-uncased-200k\",\n",
    "    \"beto-cased\",\n",
    "    #\"beto-cased-2500\",\n",
    "    \"beto-cased-5000\",\n",
    "    #\"beto-cased-10000\",\n",
    "    #\"beto-cased-20000\",\n",
    "    \"robertuito-cased\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(resume)\n",
    "df.set_index(\"model\", inplace=True)\n",
    "\n",
    "df_mean = pd.DataFrame(mean_resume).set_index(\"model\")\n",
    "score_cols = [\"context_hate mean_f1\", \"hate macro_f1\", \"sentiment macro_f1\", \"emotion macro_f1\", \"irony macro_f1\"]\n",
    "score_without_chate_cols = [\"hate macro_f1\", \"sentiment macro_f1\", \"emotion macro_f1\", \"irony macro_f1\"]\n",
    "\n",
    "df.loc[order, \"score\"] = df_mean.loc[order, score_cols].mean(axis=1)\n",
    "df.loc[order, \"score2\"] = df_mean.loc[order, score_without_chate_cols].mean(axis=1)\n",
    "columns = [c for c in df.columns if \"micro\" not in c and \"score\" not in c] + [\"score\", \"score2\" ]\n",
    "\n",
    "df.loc[order, score_cols + [\"score\", \"score2\"]].sort_values(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllr}\n",
      "\\toprule\n",
      "{} & context\\_hate mean\\_f1 &   hate macro\\_f1 & sentiment macro\\_f1 & emotion macro\\_f1 &  irony macro\\_f1 &     score \\\\\n",
      "model              &                      &                 &                    &                  &                 &           \\\\\n",
      "\\midrule\n",
      "beto-uncased       &       0.590 +- 0.006 &  0.756 +- 0.011 &     0.648 +- 0.005 &   0.520 +- 0.006 &  0.703 +- 0.007 &  0.643285 \\\\\n",
      "bertin             &       0.558 +- 0.008 &  0.766 +- 0.005 &     0.664 +- 0.003 &   0.517 +- 0.011 &  0.715 +- 0.008 &  0.644139 \\\\\n",
      "beto-cased         &       0.584 +- 0.005 &  0.765 +- 0.010 &     0.665 +- 0.003 &   0.526 +- 0.008 &  0.707 +- 0.007 &  0.649226 \\\\\n",
      "roberta-bne        &       0.578 +- 0.004 &  0.767 +- 0.015 &     0.667 +- 0.007 &   0.535 +- 0.012 &  0.723 +- 0.016 &  0.654161 \\\\\n",
      "beto-cased-5000    &       0.576 +- 0.002 &  0.783 +- 0.010 &     0.677 +- 0.004 &   0.524 +- 0.015 &  0.723 +- 0.008 &  0.656472 \\\\\n",
      "beto-uncased-10000 &       0.589 +- 0.003 &  0.772 +- 0.017 &     0.680 +- 0.004 &   0.553 +- 0.008 &  0.716 +- 0.006 &  0.661718 \\\\\n",
      "robertuito-cased   &       0.590 +- 0.005 &  0.789 +- 0.014 &     0.700 +- 0.012 &   0.521 +- 0.032 &  0.722 +- 0.021 &  0.664466 \\\\\n",
      "robertuito-deacc   &       0.594 +- 0.006 &  0.800 +- 0.008 &     0.702 +- 0.004 &   0.545 +- 0.013 &  0.739 +- 0.005 &  0.675947 \\\\\n",
      "robertuito-uncased &       0.592 +- 0.005 &  0.800 +- 0.008 &     0.707 +- 0.005 &   0.546 +- 0.011 &  0.737 +- 0.009 &  0.676655 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[order, score_cols + [\"score\"]].sort_values(\"score\").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_hate mean_f1</th>\n",
       "      <th>context_hate hate_f1</th>\n",
       "      <th>hate hateful_f1</th>\n",
       "      <th>hate macro_f1</th>\n",
       "      <th>sentiment macro_f1</th>\n",
       "      <th>emotion macro_f1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertin</th>\n",
       "      <td>0.5443 +- 0.005</td>\n",
       "      <td>0.6613 +- 0.009</td>\n",
       "      <td>0.7270 +- 0.013</td>\n",
       "      <td>0.7539 +- 0.013</td>\n",
       "      <td>0.6650 +- 0.002</td>\n",
       "      <td>0.5245 +- 0.026</td>\n",
       "      <td>0.615193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased</th>\n",
       "      <td>0.5870 +- 0.007</td>\n",
       "      <td>0.6884 +- 0.005</td>\n",
       "      <td>0.7408 +- 0.013</td>\n",
       "      <td>0.7554 +- 0.021</td>\n",
       "      <td>0.6617 +- 0.005</td>\n",
       "      <td>0.5246 +- 0.016</td>\n",
       "      <td>0.628539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased</th>\n",
       "      <td>0.5906 +- 0.004</td>\n",
       "      <td>0.6856 +- 0.006</td>\n",
       "      <td>0.7305 +- 0.006</td>\n",
       "      <td>0.7455 +- 0.014</td>\n",
       "      <td>0.6517 +- 0.002</td>\n",
       "      <td>0.5250 +- 0.014</td>\n",
       "      <td>0.624442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-ft-1000</th>\n",
       "      <td>0.5857 +- 0.003</td>\n",
       "      <td>0.6861 +- 0.002</td>\n",
       "      <td>0.7552 +- 0.011</td>\n",
       "      <td>0.7786 +- 0.012</td>\n",
       "      <td>0.6721 +- 0.001</td>\n",
       "      <td>0.5335 +- 0.012</td>\n",
       "      <td>0.636610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-ft-2000</th>\n",
       "      <td>0.5848 +- 0.005</td>\n",
       "      <td>0.6865 +- 0.003</td>\n",
       "      <td>0.7486 +- 0.003</td>\n",
       "      <td>0.7691 +- 0.010</td>\n",
       "      <td>0.6751 +- 0.005</td>\n",
       "      <td>0.5257 +- 0.010</td>\n",
       "      <td>0.633550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-1000</th>\n",
       "      <td>0.5950 +- 0.003</td>\n",
       "      <td>0.6934 +- 0.002</td>\n",
       "      <td>0.7451 +- 0.004</td>\n",
       "      <td>0.7703 +- 0.004</td>\n",
       "      <td>0.6717 +- 0.005</td>\n",
       "      <td>0.5364 +- 0.009</td>\n",
       "      <td>0.637067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-2000</th>\n",
       "      <td>0.5989 +- 0.004</td>\n",
       "      <td>0.6954 +- 0.002</td>\n",
       "      <td>0.7575 +- 0.009</td>\n",
       "      <td>0.7729 +- 0.015</td>\n",
       "      <td>0.6812 +- 0.001</td>\n",
       "      <td>0.5354 +- 0.005</td>\n",
       "      <td>0.643223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000</th>\n",
       "      <td>0.5788 +- 0.001</td>\n",
       "      <td>0.6775 +- 0.004</td>\n",
       "      <td>0.7623 +- 0.002</td>\n",
       "      <td>0.7854 +- 0.000</td>\n",
       "      <td>0.6748 +- 0.004</td>\n",
       "      <td>0.5399 +- 0.006</td>\n",
       "      <td>0.638945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000-grito</th>\n",
       "      <td>0.5848 +- 0.008</td>\n",
       "      <td>0.6866 +- 0.009</td>\n",
       "      <td>0.7615 +- 0.006</td>\n",
       "      <td>0.7738 +- 0.010</td>\n",
       "      <td>0.6865 +- 0.005</td>\n",
       "      <td>0.5522 +- 0.003</td>\n",
       "      <td>0.646247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-4000-tpu</th>\n",
       "      <td>0.5884 +- 0.001</td>\n",
       "      <td>0.6875 +- 0.005</td>\n",
       "      <td>0.7522 +- 0.009</td>\n",
       "      <td>0.7666 +- 0.006</td>\n",
       "      <td>0.6829 +- 0.001</td>\n",
       "      <td>0.5344 +- 0.008</td>\n",
       "      <td>0.639484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-5000-tpu</th>\n",
       "      <td>0.5853 +- 0.003</td>\n",
       "      <td>0.6835 +- 0.002</td>\n",
       "      <td>0.7468 +- 0.014</td>\n",
       "      <td>0.7619 +- 0.014</td>\n",
       "      <td>0.6726 +- 0.009</td>\n",
       "      <td>0.5563 +- 0.009</td>\n",
       "      <td>0.640264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-15000</th>\n",
       "      <td>0.5854 +- 0.002</td>\n",
       "      <td>0.6833 +- 0.004</td>\n",
       "      <td>0.7628 +- 0.006</td>\n",
       "      <td>0.7798 +- 0.006</td>\n",
       "      <td>0.6840 +- 0.006</td>\n",
       "      <td>0.5571 +- 0.003</td>\n",
       "      <td>0.647335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-uncased-15000-last</th>\n",
       "      <td>0.5775 +- 0.010</td>\n",
       "      <td>0.6827 +- 0.013</td>\n",
       "      <td>0.7414 +- 0.012</td>\n",
       "      <td>0.7624 +- 0.014</td>\n",
       "      <td>0.6847 +- 0.002</td>\n",
       "      <td>0.5454 +- 0.005</td>\n",
       "      <td>0.637237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-cased-15000</th>\n",
       "      <td>0.5800 +- 0.004</td>\n",
       "      <td>0.6813 +- 0.003</td>\n",
       "      <td>0.7566 +- 0.012</td>\n",
       "      <td>0.7750 +- 0.012</td>\n",
       "      <td>0.6860 +- 0.005</td>\n",
       "      <td>0.5338 +- 0.003</td>\n",
       "      <td>0.639121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        context_hate mean_f1 context_hate hate_f1  \\\n",
       "model                                                               \n",
       "bertin                       0.5443 +- 0.005      0.6613 +- 0.009   \n",
       "beto-cased                   0.5870 +- 0.007      0.6884 +- 0.005   \n",
       "beto-uncased                 0.5906 +- 0.004      0.6856 +- 0.006   \n",
       "beto-ft-1000                 0.5857 +- 0.003      0.6861 +- 0.002   \n",
       "beto-ft-2000                 0.5848 +- 0.005      0.6865 +- 0.003   \n",
       "beto-uncased-1000            0.5950 +- 0.003      0.6934 +- 0.002   \n",
       "beto-uncased-2000            0.5989 +- 0.004      0.6954 +- 0.002   \n",
       "beto-uncased-5000            0.5788 +- 0.001      0.6775 +- 0.004   \n",
       "beto-uncased-5000-grito      0.5848 +- 0.008      0.6866 +- 0.009   \n",
       "beto-uncased-4000-tpu        0.5884 +- 0.001      0.6875 +- 0.005   \n",
       "beto-uncased-5000-tpu        0.5853 +- 0.003      0.6835 +- 0.002   \n",
       "beto-uncased-15000           0.5854 +- 0.002      0.6833 +- 0.004   \n",
       "beto-uncased-15000-last      0.5775 +- 0.010      0.6827 +- 0.013   \n",
       "beto-cased-15000             0.5800 +- 0.004      0.6813 +- 0.003   \n",
       "\n",
       "                         hate hateful_f1    hate macro_f1 sentiment macro_f1  \\\n",
       "model                                                                          \n",
       "bertin                   0.7270 +- 0.013  0.7539 +- 0.013    0.6650 +- 0.002   \n",
       "beto-cased               0.7408 +- 0.013  0.7554 +- 0.021    0.6617 +- 0.005   \n",
       "beto-uncased             0.7305 +- 0.006  0.7455 +- 0.014    0.6517 +- 0.002   \n",
       "beto-ft-1000             0.7552 +- 0.011  0.7786 +- 0.012    0.6721 +- 0.001   \n",
       "beto-ft-2000             0.7486 +- 0.003  0.7691 +- 0.010    0.6751 +- 0.005   \n",
       "beto-uncased-1000        0.7451 +- 0.004  0.7703 +- 0.004    0.6717 +- 0.005   \n",
       "beto-uncased-2000        0.7575 +- 0.009  0.7729 +- 0.015    0.6812 +- 0.001   \n",
       "beto-uncased-5000        0.7623 +- 0.002  0.7854 +- 0.000    0.6748 +- 0.004   \n",
       "beto-uncased-5000-grito  0.7615 +- 0.006  0.7738 +- 0.010    0.6865 +- 0.005   \n",
       "beto-uncased-4000-tpu    0.7522 +- 0.009  0.7666 +- 0.006    0.6829 +- 0.001   \n",
       "beto-uncased-5000-tpu    0.7468 +- 0.014  0.7619 +- 0.014    0.6726 +- 0.009   \n",
       "beto-uncased-15000       0.7628 +- 0.006  0.7798 +- 0.006    0.6840 +- 0.006   \n",
       "beto-uncased-15000-last  0.7414 +- 0.012  0.7624 +- 0.014    0.6847 +- 0.002   \n",
       "beto-cased-15000         0.7566 +- 0.012  0.7750 +- 0.012    0.6860 +- 0.005   \n",
       "\n",
       "                        emotion macro_f1     score  \n",
       "model                                               \n",
       "bertin                   0.5245 +- 0.026  0.615193  \n",
       "beto-cased               0.5246 +- 0.016  0.628539  \n",
       "beto-uncased             0.5250 +- 0.014  0.624442  \n",
       "beto-ft-1000             0.5335 +- 0.012  0.636610  \n",
       "beto-ft-2000             0.5257 +- 0.010  0.633550  \n",
       "beto-uncased-1000        0.5364 +- 0.009  0.637067  \n",
       "beto-uncased-2000        0.5354 +- 0.005  0.643223  \n",
       "beto-uncased-5000        0.5399 +- 0.006  0.638945  \n",
       "beto-uncased-5000-grito  0.5522 +- 0.003  0.646247  \n",
       "beto-uncased-4000-tpu    0.5344 +- 0.008  0.639484  \n",
       "beto-uncased-5000-tpu    0.5563 +- 0.009  0.640264  \n",
       "beto-uncased-15000       0.5571 +- 0.003  0.647335  \n",
       "beto-uncased-15000-last  0.5454 +- 0.005  0.637237  \n",
       "beto-cased-15000         0.5338 +- 0.003  0.639121  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "resume = []\n",
    "mean_resume = []\n",
    "task_metrics = {\n",
    "    \"context_hate\": [\"eval_mean_f1\", \"eval_hate_f1\"],\n",
    "    \"hate\": [\"eval_hateful_f1\", \"eval_macro_f1\"],\n",
    "    \"sentiment\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "    \"emotion\": [\"eval_macro_f1\", \"eval_micro_f1\"],\n",
    "}\n",
    "\n",
    "    \n",
    "for model_name, output in outs.items():\n",
    "    line = {\n",
    "        \"model\": model_name, \n",
    "    }\n",
    "\n",
    "    mean_line = {\n",
    "        \"model\": model_name,\n",
    "    }\n",
    "\n",
    "    for task, metrics in task_metrics.items():\n",
    "        try:\n",
    "            for metric in metrics:\n",
    "                arr = np.array([evaluation[metric] for evaluation in output[task]])\n",
    "                metric_name = metric.replace(\"eval_\", \"\")\n",
    "                mean_line[task+\" \"+metric_name] = arr.mean()\n",
    "                line[task+\" \"+metric_name] = f\"{arr.mean():.4f} +- {arr.std():.3f}\"\n",
    "        except KeyError as e:\n",
    "            print(e, \"not in \", model_name)\n",
    "            continue\n",
    "    resume.append(line)\n",
    "    mean_resume.append(mean_line)\n",
    "\n",
    "order = [\n",
    "    \"bertin\",\n",
    "    \"beto-cased\",\n",
    "    \"beto-uncased\",\n",
    "    \"beto-ft-1000\",\n",
    "    \"beto-ft-2000\",\n",
    "    \"beto-uncased-1000\",\n",
    "    \"beto-uncased-2000\",\n",
    "    \"beto-uncased-5000\",\n",
    "    \"beto-uncased-5000-grito\",\n",
    "    \"beto-uncased-4000-tpu\",\n",
    "    \"beto-uncased-5000-tpu\",\n",
    "    \"beto-uncased-15000\",\n",
    "    \"beto-uncased-15000-last\",\n",
    "    \"beto-cased-15000\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(resume)\n",
    "df.set_index(\"model\", inplace=True)\n",
    "\n",
    "df_mean = pd.DataFrame(mean_resume).set_index(\"model\")\n",
    "score_cols = [\"context_hate mean_f1\", \"hate hateful_f1\", \"sentiment macro_f1\", \"emotion macro_f1\"]\n",
    "\n",
    "df.loc[order, \"score\"] = df_mean.loc[order, score_cols].mean(axis=1)\n",
    "columns = [c for c in df.columns if \"micro\" not in c]\n",
    "\n",
    "df.loc[order, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"last\" es usando los mismos parámetros que en el paper de finetuning\n",
    "\n",
    "No parecen ser los mejores!\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d66fee0d28bd4ff973cb40954a12724f872a5e358c3d085cba51304a5945a0f3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('finetune-vs-scratch-gHiQbun3-py3.7': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
