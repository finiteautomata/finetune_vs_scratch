{
    "context_hate": [
        {
            "eval_loss": 0.08116602897644043,
            "eval_calls_f1": 0.6596858638743456,
            "eval_women_f1": 0.3844492440604752,
            "eval_lgbti_f1": 0.45180722891566266,
            "eval_racism_f1": 0.6875631951466127,
            "eval_class_f1": 0.4794007490636705,
            "eval_politics_f1": 0.5757575757575757,
            "eval_disabled_f1": 0.5517241379310344,
            "eval_appearance_f1": 0.7351778656126483,
            "eval_criminal_f1": 0.6337209302325582,
            "eval_mean_f1": 0.5732540488243103,
            "eval_mean_precision": 0.594822108745575,
            "eval_mean_recall": 0.5614497661590576,
            "eval_hate_precision": 0.694526191877575,
            "eval_hate_recall": 0.6566499721758486,
            "eval_hate_f1": 0.6750572082379862,
            "eval_runtime": 40.1411,
            "eval_samples_per_second": 282.578,
            "eval_steps_per_second": 17.663
        },
        {
            "eval_loss": 0.0825808048248291,
            "eval_calls_f1": 0.6666666666666666,
            "eval_women_f1": 0.4152542372881356,
            "eval_lgbti_f1": 0.4636871508379888,
            "eval_racism_f1": 0.6990099009900991,
            "eval_class_f1": 0.461038961038961,
            "eval_politics_f1": 0.5886178861788618,
            "eval_disabled_f1": 0.5323741007194245,
            "eval_appearance_f1": 0.7275064267352186,
            "eval_criminal_f1": 0.648876404494382,
            "eval_mean_f1": 0.5781146287918091,
            "eval_mean_precision": 0.5755687355995178,
            "eval_mean_recall": 0.5855668783187866,
            "eval_hate_precision": 0.6907968574635241,
            "eval_hate_recall": 0.6850306065664997,
            "eval_hate_f1": 0.687901648505169,
            "eval_runtime": 39.876,
            "eval_samples_per_second": 284.457,
            "eval_steps_per_second": 17.78
        },
        {
            "eval_loss": 0.07999677211046219,
            "eval_calls_f1": 0.6876090750436299,
            "eval_women_f1": 0.3991130820399113,
            "eval_lgbti_f1": 0.45697329376854595,
            "eval_racism_f1": 0.6785009861932938,
            "eval_class_f1": 0.46366782006920415,
            "eval_politics_f1": 0.5973154362416108,
            "eval_disabled_f1": 0.5433962264150943,
            "eval_appearance_f1": 0.7447916666666666,
            "eval_criminal_f1": 0.6192468619246864,
            "eval_mean_f1": 0.5767349004745483,
            "eval_mean_precision": 0.5923780798912048,
            "eval_mean_recall": 0.5683358907699585,
            "eval_hate_precision": 0.69002849002849,
            "eval_hate_recall": 0.6739009460211464,
            "eval_hate_f1": 0.6818693693693694,
            "eval_runtime": 40.0176,
            "eval_samples_per_second": 283.45,
            "eval_steps_per_second": 17.717
        },
        {
            "eval_loss": 0.08187060058116913,
            "eval_calls_f1": 0.6703096539162114,
            "eval_women_f1": 0.4024144869215292,
            "eval_lgbti_f1": 0.45977011494252873,
            "eval_racism_f1": 0.6832174776564052,
            "eval_class_f1": 0.4536082474226804,
            "eval_politics_f1": 0.617241379310345,
            "eval_disabled_f1": 0.5104895104895105,
            "eval_appearance_f1": 0.7358974358974358,
            "eval_criminal_f1": 0.6491228070175439,
            "eval_mean_f1": 0.575785756111145,
            "eval_mean_precision": 0.5862653851509094,
            "eval_mean_recall": 0.5698086023330688,
            "eval_hate_precision": 0.6873576309794989,
            "eval_hate_recall": 0.6716750139120757,
            "eval_hate_f1": 0.6794258373205742,
            "eval_runtime": 40.1964,
            "eval_samples_per_second": 282.19,
            "eval_steps_per_second": 17.638
        },
        {
            "eval_loss": 0.08125391602516174,
            "eval_calls_f1": 0.6619718309859154,
            "eval_women_f1": 0.4156378600823046,
            "eval_lgbti_f1": 0.443213296398892,
            "eval_racism_f1": 0.6737657308809294,
            "eval_class_f1": 0.49019607843137253,
            "eval_politics_f1": 0.6222961730449251,
            "eval_disabled_f1": 0.5448028673835126,
            "eval_appearance_f1": 0.7313237221494102,
            "eval_criminal_f1": 0.6383561643835617,
            "eval_mean_f1": 0.5801737308502197,
            "eval_mean_precision": 0.5777497291564941,
            "eval_mean_recall": 0.5860016345977783,
            "eval_hate_precision": 0.6755290287574607,
            "eval_hate_recall": 0.6928213689482471,
            "eval_hate_f1": 0.684065934065934,
            "eval_runtime": 39.9866,
            "eval_samples_per_second": 283.67,
            "eval_steps_per_second": 17.731
        }
    ],
    "hate": [
        {
            "eval_loss": 1.2840995788574219,
            "eval_ok_f1": 0.7868080094228503,
            "eval_ok_precision": 0.8812664907651715,
            "eval_ok_recall": 0.7106382978723405,
            "eval_hateful_f1": 0.7589880159786953,
            "eval_hateful_precision": 0.6769596199524941,
            "eval_hateful_recall": 0.8636363636363636,
            "eval_micro_f1": 0.77375,
            "eval_macro_f1": 0.7728980183601379,
            "eval_macro_precision": 0.7791130542755127,
            "eval_macro_recall": 0.7871373295783997,
            "eval_acc": 0.77375,
            "eval_runtime": 3.4737,
            "eval_samples_per_second": 460.598,
            "eval_steps_per_second": 28.787,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0565892457962036,
            "eval_ok_f1": 0.7883295194508009,
            "eval_ok_precision": 0.8527227722772277,
            "eval_ok_recall": 0.7329787234042553,
            "eval_hateful_f1": 0.7451790633608815,
            "eval_hateful_precision": 0.6830808080808081,
            "eval_hateful_recall": 0.8196969696969697,
            "eval_micro_f1": 0.76875,
            "eval_macro_f1": 0.7667542695999146,
            "eval_macro_precision": 0.7679017782211304,
            "eval_macro_recall": 0.7763378620147705,
            "eval_acc": 0.76875,
            "eval_runtime": 3.6857,
            "eval_samples_per_second": 434.11,
            "eval_steps_per_second": 27.132,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1923025846481323,
            "eval_ok_f1": 0.784795321637427,
            "eval_ok_precision": 0.8714285714285714,
            "eval_ok_recall": 0.7138297872340426,
            "eval_hateful_f1": 0.7530201342281879,
            "eval_hateful_precision": 0.6759036144578313,
            "eval_hateful_recall": 0.85,
            "eval_micro_f1": 0.7699999999999999,
            "eval_macro_f1": 0.7689077258110046,
            "eval_macro_precision": 0.7736660838127136,
            "eval_macro_recall": 0.7819149494171143,
            "eval_acc": 0.77,
            "eval_runtime": 3.5125,
            "eval_samples_per_second": 455.513,
            "eval_steps_per_second": 28.47,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2315306663513184,
            "eval_ok_f1": 0.8002225932109069,
            "eval_ok_precision": 0.838973162193699,
            "eval_ok_recall": 0.7648936170212766,
            "eval_hateful_f1": 0.744119743406985,
            "eval_hateful_precision": 0.702557200538358,
            "eval_hateful_recall": 0.7909090909090909,
            "eval_micro_f1": 0.775625,
            "eval_macro_f1": 0.772171139717102,
            "eval_macro_precision": 0.7707651853561401,
            "eval_macro_recall": 0.7779013514518738,
            "eval_acc": 0.775625,
            "eval_runtime": 3.5478,
            "eval_samples_per_second": 450.989,
            "eval_steps_per_second": 28.187,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.5158213973045349,
            "eval_ok_f1": 0.7759119861030689,
            "eval_ok_precision": 0.8513341804320204,
            "eval_ok_recall": 0.7127659574468085,
            "eval_hateful_f1": 0.7372708757637474,
            "eval_hateful_precision": 0.6678966789667896,
            "eval_hateful_recall": 0.8227272727272728,
            "eval_micro_f1": 0.758125,
            "eval_macro_f1": 0.7565914392471313,
            "eval_macro_precision": 0.759615421295166,
            "eval_macro_recall": 0.7677465677261353,
            "eval_acc": 0.758125,
            "eval_runtime": 3.5142,
            "eval_samples_per_second": 455.297,
            "eval_steps_per_second": 28.456,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 0.7349411845207214,
            "eval_neg_f1": 0.767038626609442,
            "eval_neg_precision": 0.774081774081774,
            "eval_neg_recall": 0.7601224906430759,
            "eval_neu_f1": 0.5503709021296961,
            "eval_neu_precision": 0.5196565747853592,
            "eval_neu_recall": 0.5849440488301119,
            "eval_pos_f1": 0.7422634836427939,
            "eval_pos_precision": 0.7755196304849884,
            "eval_pos_recall": 0.7117422636710471,
            "eval_micro_f1": 0.6969988986784141,
            "eval_macro_f1": 0.6865577101707458,
            "eval_macro_precision": 0.6897526383399963,
            "eval_macro_recall": 0.6856029629707336,
            "eval_acc": 0.6969988986784141,
            "eval_runtime": 10.3706,
            "eval_samples_per_second": 700.439,
            "eval_steps_per_second": 43.777,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7747382521629333,
            "eval_neg_f1": 0.7302717900656046,
            "eval_neg_precision": 0.8130217028380634,
            "eval_neg_recall": 0.6628104797550187,
            "eval_neu_f1": 0.5533807829181495,
            "eval_neu_precision": 0.491699604743083,
            "eval_neu_recall": 0.6327568667344863,
            "eval_pos_f1": 0.7468596976793699,
            "eval_pos_precision": 0.7502138579982891,
            "eval_pos_recall": 0.7435353963543875,
            "eval_micro_f1": 0.6808920704845814,
            "eval_macro_f1": 0.6768374443054199,
            "eval_macro_precision": 0.6849784255027771,
            "eval_macro_recall": 0.6797009110450745,
            "eval_acc": 0.6808920704845814,
            "eval_runtime": 10.4925,
            "eval_samples_per_second": 692.306,
            "eval_steps_per_second": 43.269,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7393357157707214,
            "eval_neg_f1": 0.7107721639656815,
            "eval_neg_precision": 0.808326105810928,
            "eval_neg_recall": 0.6342293297039809,
            "eval_neu_f1": 0.5612695861791883,
            "eval_neu_precision": 0.4638114209827357,
            "eval_neu_recall": 0.7105798575788402,
            "eval_pos_f1": 0.7317073170731707,
            "eval_pos_precision": 0.8093525179856115,
            "eval_pos_recall": 0.6676557863501483,
            "eval_micro_f1": 0.6657488986784141,
            "eval_macro_f1": 0.6679163575172424,
            "eval_macro_precision": 0.6938300132751465,
            "eval_macro_recall": 0.6708216667175293,
            "eval_acc": 0.6657488986784141,
            "eval_runtime": 10.5721,
            "eval_samples_per_second": 687.091,
            "eval_steps_per_second": 42.943,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.588620901107788,
            "eval_neg_f1": 0.7388073228203733,
            "eval_neg_precision": 0.7905352986811481,
            "eval_neg_recall": 0.6934331405239877,
            "eval_neu_f1": 0.5377697841726617,
            "eval_neu_precision": 0.48186946011281223,
            "eval_neu_recall": 0.6083418107833164,
            "eval_pos_f1": 0.7416173570019724,
            "eval_pos_precision": 0.7676950998185118,
            "eval_pos_recall": 0.7172530733361594,
            "eval_micro_f1": 0.6781387665198237,
            "eval_macro_f1": 0.6727314591407776,
            "eval_macro_precision": 0.680033266544342,
            "eval_macro_recall": 0.6730093955993652,
            "eval_acc": 0.6781387665198237,
            "eval_runtime": 10.4601,
            "eval_samples_per_second": 694.446,
            "eval_steps_per_second": 43.403,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7186976075172424,
            "eval_neg_f1": 0.7460992907801418,
            "eval_neg_precision": 0.7789707515734913,
            "eval_neg_recall": 0.7158897584212317,
            "eval_neu_f1": 0.5580246913580246,
            "eval_neu_precision": 0.4993973483326637,
            "eval_neu_recall": 0.6322482197355036,
            "eval_pos_f1": 0.736747123843898,
            "eval_pos_precision": 0.787367405978785,
            "eval_pos_recall": 0.692242475625265,
            "eval_micro_f1": 0.6855726872246696,
            "eval_macro_f1": 0.6802904009819031,
            "eval_macro_precision": 0.6885785460472107,
            "eval_macro_recall": 0.6801268458366394,
            "eval_acc": 0.6855726872246696,
            "eval_runtime": 10.5449,
            "eval_samples_per_second": 688.862,
            "eval_steps_per_second": 43.054,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.7200772762298584,
            "eval_others_f1": 0.7490774907749077,
            "eval_others_precision": 0.7622027534418022,
            "eval_others_recall": 0.7363966142684402,
            "eval_joy_f1": 0.6640522875816992,
            "eval_joy_precision": 0.630272952853598,
            "eval_joy_recall": 0.7016574585635359,
            "eval_sadness_f1": 0.7368421052631577,
            "eval_sadness_precision": 0.735,
            "eval_sadness_recall": 0.7386934673366834,
            "eval_anger_f1": 0.5737704918032788,
            "eval_anger_precision": 0.5357142857142857,
            "eval_anger_recall": 0.6176470588235294,
            "eval_surprise_f1": 0.32432432432432434,
            "eval_surprise_precision": 0.4186046511627907,
            "eval_surprise_recall": 0.2647058823529412,
            "eval_disgust_f1": 0.045454545454545456,
            "eval_disgust_precision": 0.09090909090909091,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.46511627906976744,
            "eval_fear_precision": 0.4,
            "eval_fear_recall": 0.5555555555555556,
            "eval_micro_f1": 0.6821705426356589,
            "eval_macro_f1": 0.5083767771720886,
            "eval_macro_precision": 0.5103861689567566,
            "eval_macro_recall": 0.520708441734314,
            "eval_acc": 0.6821705426356589,
            "eval_runtime": 4.7241,
            "eval_samples_per_second": 354.988,
            "eval_steps_per_second": 22.226,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.5971027612686157,
            "eval_others_f1": 0.7694189602446483,
            "eval_others_precision": 0.7784653465346535,
            "eval_others_recall": 0.7605804111245466,
            "eval_joy_f1": 0.6739130434782609,
            "eval_joy_precision": 0.6631016042780749,
            "eval_joy_recall": 0.6850828729281768,
            "eval_sadness_f1": 0.7555555555555555,
            "eval_sadness_precision": 0.7427184466019418,
            "eval_sadness_recall": 0.7688442211055276,
            "eval_anger_f1": 0.5910290237467019,
            "eval_anger_precision": 0.5358851674641149,
            "eval_anger_recall": 0.6588235294117647,
            "eval_surprise_f1": 0.32727272727272727,
            "eval_surprise_precision": 0.42857142857142855,
            "eval_surprise_recall": 0.2647058823529412,
            "eval_disgust_f1": 0.08888888888888888,
            "eval_disgust_precision": 0.16666666666666666,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.5,
            "eval_fear_precision": 0.4230769230769231,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6994633273703041,
            "eval_macro_f1": 0.5294397473335266,
            "eval_macro_precision": 0.5340693593025208,
            "eval_macro_recall": 0.5442506074905396,
            "eval_acc": 0.6994633273703041,
            "eval_runtime": 4.6928,
            "eval_samples_per_second": 357.355,
            "eval_steps_per_second": 22.375,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.614508032798767,
            "eval_others_f1": 0.7603513174404015,
            "eval_others_precision": 0.7900912646675359,
            "eval_others_recall": 0.7327690447400241,
            "eval_joy_f1": 0.6794871794871796,
            "eval_joy_precision": 0.6339712918660287,
            "eval_joy_recall": 0.7320441988950276,
            "eval_sadness_f1": 0.7648456057007126,
            "eval_sadness_precision": 0.7252252252252253,
            "eval_sadness_recall": 0.8090452261306532,
            "eval_anger_f1": 0.5842696629213483,
            "eval_anger_precision": 0.5591397849462365,
            "eval_anger_recall": 0.611764705882353,
            "eval_surprise_f1": 0.3793103448275862,
            "eval_surprise_precision": 0.4583333333333333,
            "eval_surprise_recall": 0.3235294117647059,
            "eval_disgust_f1": 0.047619047619047616,
            "eval_disgust_precision": 0.1111111111111111,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.5333333333333333,
            "eval_fear_precision": 0.4444444444444444,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6982707215265355,
            "eval_macro_f1": 0.5356023907661438,
            "eval_macro_precision": 0.53175950050354,
            "eval_macro_recall": 0.5580174922943115,
            "eval_acc": 0.6982707215265355,
            "eval_runtime": 4.9144,
            "eval_samples_per_second": 341.242,
            "eval_steps_per_second": 21.366,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.6551430225372314,
            "eval_others_f1": 0.7670559311616473,
            "eval_others_precision": 0.78,
            "eval_others_recall": 0.75453446191052,
            "eval_joy_f1": 0.6738836265223275,
            "eval_joy_precision": 0.6604774535809018,
            "eval_joy_recall": 0.6878453038674033,
            "eval_sadness_f1": 0.7469879518072289,
            "eval_sadness_precision": 0.7175925925925926,
            "eval_sadness_recall": 0.7788944723618091,
            "eval_anger_f1": 0.5905292479108634,
            "eval_anger_precision": 0.5608465608465608,
            "eval_anger_recall": 0.6235294117647059,
            "eval_surprise_f1": 0.36507936507936506,
            "eval_surprise_precision": 0.39655172413793105,
            "eval_surprise_recall": 0.3382352941176471,
            "eval_disgust_f1": 0.04444444444444444,
            "eval_disgust_precision": 0.08333333333333333,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.41860465116279066,
            "eval_fear_precision": 0.36,
            "eval_fear_recall": 0.5,
            "eval_micro_f1": 0.6958855098389982,
            "eval_macro_f1": 0.5152264833450317,
            "eval_macro_precision": 0.5084002614021301,
            "eval_macro_recall": 0.5304774045944214,
            "eval_acc": 0.6958855098389982,
            "eval_runtime": 4.8004,
            "eval_samples_per_second": 349.349,
            "eval_steps_per_second": 21.873,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.676775574684143,
            "eval_others_f1": 0.7686703096539163,
            "eval_others_precision": 0.7719512195121951,
            "eval_others_recall": 0.7654171704957679,
            "eval_joy_f1": 0.6729222520107239,
            "eval_joy_precision": 0.6536458333333334,
            "eval_joy_recall": 0.6933701657458563,
            "eval_sadness_f1": 0.774025974025974,
            "eval_sadness_precision": 0.8010752688172043,
            "eval_sadness_recall": 0.7487437185929648,
            "eval_anger_f1": 0.61455525606469,
            "eval_anger_precision": 0.5671641791044776,
            "eval_anger_recall": 0.6705882352941176,
            "eval_surprise_f1": 0.31034482758620696,
            "eval_surprise_precision": 0.375,
            "eval_surprise_recall": 0.2647058823529412,
            "eval_disgust_f1": 0.05128205128205128,
            "eval_disgust_precision": 0.16666666666666666,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.52,
            "eval_fear_precision": 0.40625,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.7030411449016101,
            "eval_macro_f1": 0.5302572250366211,
            "eval_macro_precision": 0.5345361828804016,
            "eval_macro_recall": 0.5564786195755005,
            "eval_acc": 0.7030411449016101,
            "eval_runtime": 4.819,
            "eval_samples_per_second": 348.0,
            "eval_steps_per_second": 21.789,
            "epoch": 5.0
        }
    ],
    "model_name": "models/beto-cased-2500/",
    "irony": [
        {
            "eval_loss": 1.2815017700195312,
            "eval_not ironic_f1": 0.8147843942505133,
            "eval_not ironic_precision": 0.8038897893030794,
            "eval_not ironic_recall": 0.8259783513738551,
            "eval_ironic_f1": 0.6128755364806867,
            "eval_ironic_precision": 0.6307420494699647,
            "eval_ironic_recall": 0.5959933222036727,
            "eval_micro_f1": 0.7494444444444444,
            "eval_macro_f1": 0.7138299942016602,
            "eval_macro_precision": 0.7173159122467041,
            "eval_macro_recall": 0.7109858393669128,
            "eval_acc": 0.7494444444444445,
            "eval_runtime": 4.6809,
            "eval_samples_per_second": 384.544,
            "eval_steps_per_second": 24.141,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.549339234828949,
            "eval_not ironic_f1": 0.804159445407279,
            "eval_not ironic_precision": 0.8383017163504969,
            "eval_not ironic_recall": 0.7726894254787677,
            "eval_ironic_f1": 0.65015479876161,
            "eval_ironic_precision": 0.6060606060606061,
            "eval_ironic_recall": 0.7011686143572621,
            "eval_micro_f1": 0.7488888888888889,
            "eval_macro_f1": 0.7271571159362793,
            "eval_macro_precision": 0.7221812009811401,
            "eval_macro_recall": 0.7369289994239807,
            "eval_acc": 0.7488888888888889,
            "eval_runtime": 4.5007,
            "eval_samples_per_second": 399.933,
            "eval_steps_per_second": 25.107,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.5481140613555908,
            "eval_not ironic_f1": 0.811106436684897,
            "eval_not ironic_precision": 0.8197278911564626,
            "eval_not ironic_recall": 0.8026644462947544,
            "eval_ironic_f1": 0.6328699918233852,
            "eval_ironic_precision": 0.6201923076923077,
            "eval_ironic_recall": 0.6460767946577629,
            "eval_micro_f1": 0.7505555555555554,
            "eval_macro_f1": 0.7219882011413574,
            "eval_macro_precision": 0.71996009349823,
            "eval_macro_recall": 0.7243705987930298,
            "eval_acc": 0.7505555555555555,
            "eval_runtime": 4.8486,
            "eval_samples_per_second": 371.238,
            "eval_steps_per_second": 23.305,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.3233457803726196,
            "eval_not ironic_f1": 0.8150572831423896,
            "eval_not ironic_precision": 0.8012872083668544,
            "eval_not ironic_recall": 0.829308909242298,
            "eval_ironic_f1": 0.6089965397923875,
            "eval_ironic_precision": 0.6319569120287253,
            "eval_ironic_recall": 0.5876460767946577,
            "eval_micro_f1": 0.7488888888888889,
            "eval_macro_f1": 0.7120268940925598,
            "eval_macro_precision": 0.7166221141815186,
            "eval_macro_recall": 0.7084774971008301,
            "eval_acc": 0.7488888888888889,
            "eval_runtime": 4.8334,
            "eval_samples_per_second": 372.407,
            "eval_steps_per_second": 23.379,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.5278351902961731,
            "eval_not ironic_f1": 0.8264858396489829,
            "eval_not ironic_precision": 0.7932618683001531,
            "eval_not ironic_recall": 0.8626144879267277,
            "eval_ironic_f1": 0.6020128087831657,
            "eval_ironic_precision": 0.6659919028340081,
            "eval_ironic_recall": 0.5492487479131887,
            "eval_micro_f1": 0.7583333333333333,
            "eval_macro_f1": 0.714249312877655,
            "eval_macro_precision": 0.7296268939971924,
            "eval_macro_recall": 0.7059316635131836,
            "eval_acc": 0.7583333333333333,
            "eval_runtime": 4.6545,
            "eval_samples_per_second": 386.721,
            "eval_steps_per_second": 24.277,
            "epoch": 5.0
        }
    ]
}