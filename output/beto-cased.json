{
    "context_hate": [
        {
            "eval_loss": 0.07624775916337967,
            "eval_calls_f1": 0.6265486725663717,
            "eval_women_f1": 0.4795081967213115,
            "eval_lgbti_f1": 0.47368421052631576,
            "eval_racism_f1": 0.6883525708289612,
            "eval_class_f1": 0.5342960288808665,
            "eval_politics_f1": 0.5833333333333334,
            "eval_disabled_f1": 0.5735294117647058,
            "eval_appearance_f1": 0.7463087248322147,
            "eval_criminal_f1": 0.6638176638176637,
            "eval_mean_f1": 0.5965976119041443,
            "eval_mean_precision": 0.623717188835144,
            "eval_mean_recall": 0.5749574899673462,
            "eval_hate_precision": 0.7218181818181818,
            "eval_hate_recall": 0.662771285475793,
            "eval_hate_f1": 0.6910356832027851,
            "eval_runtime": 37.6832,
            "eval_samples_per_second": 301.01,
            "eval_steps_per_second": 18.815
        },
        {
            "eval_loss": 0.07776889204978943,
            "eval_calls_f1": 0.6358792184724689,
            "eval_women_f1": 0.4126315789473684,
            "eval_lgbti_f1": 0.4645161290322581,
            "eval_racism_f1": 0.7028753993610224,
            "eval_class_f1": 0.5,
            "eval_politics_f1": 0.5724508050089445,
            "eval_disabled_f1": 0.5703422053231939,
            "eval_appearance_f1": 0.747638326585695,
            "eval_criminal_f1": 0.6620879120879121,
            "eval_mean_f1": 0.5853801965713501,
            "eval_mean_precision": 0.6250842213630676,
            "eval_mean_recall": 0.5573597550392151,
            "eval_hate_precision": 0.7312693498452012,
            "eval_hate_recall": 0.6572064552031163,
            "eval_hate_f1": 0.6922626025791324,
            "eval_runtime": 37.5856,
            "eval_samples_per_second": 301.792,
            "eval_steps_per_second": 18.864
        },
        {
            "eval_loss": 0.08134716749191284,
            "eval_calls_f1": 0.6221441124780317,
            "eval_women_f1": 0.41745730550284627,
            "eval_lgbti_f1": 0.4727272727272727,
            "eval_racism_f1": 0.6693386773547093,
            "eval_class_f1": 0.48797250859106533,
            "eval_politics_f1": 0.5745062836624776,
            "eval_disabled_f1": 0.5787545787545788,
            "eval_appearance_f1": 0.7293519695044473,
            "eval_criminal_f1": 0.6594885598923285,
            "eval_mean_f1": 0.5790823698043823,
            "eval_mean_precision": 0.5867422819137573,
            "eval_mean_recall": 0.5763569474220276,
            "eval_hate_precision": 0.6820712694877505,
            "eval_hate_recall": 0.6816917084028937,
            "eval_hate_f1": 0.6818814361258001,
            "eval_runtime": 37.559,
            "eval_samples_per_second": 302.005,
            "eval_steps_per_second": 18.877
        }
    ],
    "sentiment": [
        {
            "eval_loss": 1.6850090026855469,
            "eval_neg_f1": 0.7331879316612141,
            "eval_neg_precision": 0.7869683964104565,
            "eval_neg_recall": 0.6862878530112283,
            "eval_neu_f1": 0.5400406045567335,
            "eval_neu_precision": 0.4852047020672882,
            "eval_neu_recall": 0.6088504577822991,
            "eval_pos_f1": 0.730677117352493,
            "eval_pos_precision": 0.7511190689346464,
            "eval_pos_recall": 0.7113183552352692,
            "eval_micro_f1": 0.6734581497797357,
            "eval_macro_f1": 0.6679685711860657,
            "eval_macro_precision": 0.674430787563324,
            "eval_macro_recall": 0.6688189506530762,
            "eval_acc": 0.6734581497797357,
            "eval_runtime": 9.0346,
            "eval_samples_per_second": 804.024,
            "eval_steps_per_second": 25.126,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0342159271240234,
            "eval_neg_f1": 0.7363288052943225,
            "eval_neg_precision": 0.754191937210132,
            "eval_neg_recall": 0.7192922762844505,
            "eval_neu_f1": 0.5300834431269215,
            "eval_neu_precision": 0.4663833075734158,
            "eval_neu_recall": 0.6139369277721262,
            "eval_pos_f1": 0.7032136105860113,
            "eval_pos_precision": 0.794447410571276,
            "eval_pos_recall": 0.6307757524374735,
            "eval_micro_f1": 0.6620319383259912,
            "eval_macro_f1": 0.6565420031547546,
            "eval_macro_precision": 0.6716742515563965,
            "eval_macro_recall": 0.6546683311462402,
            "eval_acc": 0.6620319383259912,
            "eval_runtime": 9.0327,
            "eval_samples_per_second": 804.187,
            "eval_steps_per_second": 25.131,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.028230905532837,
            "eval_neg_f1": 0.7344078486334968,
            "eval_neg_precision": 0.7569519682195739,
            "eval_neg_recall": 0.7131677441306566,
            "eval_neu_f1": 0.527260489118241,
            "eval_neu_precision": 0.4716981132075472,
            "eval_neu_recall": 0.5976602238046795,
            "eval_pos_f1": 0.7196882878753152,
            "eval_pos_precision": 0.783433133732535,
            "eval_pos_recall": 0.665536244171259,
            "eval_micro_f1": 0.6664372246696035,
            "eval_macro_f1": 0.6604521870613098,
            "eval_macro_precision": 0.6706944108009338,
            "eval_macro_recall": 0.6587880253791809,
            "eval_acc": 0.6664372246696035,
            "eval_runtime": 9.0621,
            "eval_samples_per_second": 801.582,
            "eval_steps_per_second": 25.049,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.2652240991592407,
            "eval_others_f1": 0.700760193503801,
            "eval_others_precision": 0.817741935483871,
            "eval_others_recall": 0.6130592503022975,
            "eval_joy_f1": 0.6658986175115208,
            "eval_joy_precision": 0.5711462450592886,
            "eval_joy_recall": 0.7983425414364641,
            "eval_sadness_f1": 0.7730673316708229,
            "eval_sadness_precision": 0.7673267326732673,
            "eval_sadness_recall": 0.7788944723618091,
            "eval_anger_f1": 0.5699208443271768,
            "eval_anger_precision": 0.5167464114832536,
            "eval_anger_recall": 0.6352941176470588,
            "eval_surprise_f1": 0.38961038961038963,
            "eval_surprise_precision": 0.3488372093023256,
            "eval_surprise_recall": 0.4411764705882353,
            "eval_disgust_f1": 0.11764705882352942,
            "eval_disgust_precision": 0.16666666666666666,
            "eval_disgust_recall": 0.09090909090909091,
            "eval_fear_f1": 0.40740740740740744,
            "eval_fear_precision": 0.3055555555555556,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6577221228384019,
            "eval_macro_f1": 0.5177587866783142,
            "eval_macro_precision": 0.49914583563804626,
            "eval_macro_recall": 0.5669695734977722,
            "eval_acc": 0.6577221228384019,
            "eval_runtime": 4.4565,
            "eval_samples_per_second": 376.308,
            "eval_steps_per_second": 23.561,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.647907018661499,
            "eval_others_f1": 0.762138905961893,
            "eval_others_precision": 0.775,
            "eval_others_recall": 0.7496977025392987,
            "eval_joy_f1": 0.6684782608695652,
            "eval_joy_precision": 0.6577540106951871,
            "eval_joy_recall": 0.6795580110497238,
            "eval_sadness_f1": 0.7493796526054591,
            "eval_sadness_precision": 0.7401960784313726,
            "eval_sadness_recall": 0.7587939698492462,
            "eval_anger_f1": 0.5602094240837697,
            "eval_anger_precision": 0.5047169811320755,
            "eval_anger_recall": 0.6294117647058823,
            "eval_surprise_f1": 0.32075471698113206,
            "eval_surprise_precision": 0.4473684210526316,
            "eval_surprise_recall": 0.25,
            "eval_disgust_f1": 0.041666666666666664,
            "eval_disgust_precision": 0.06666666666666667,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.46153846153846156,
            "eval_fear_precision": 0.35294117647058826,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6881335718545021,
            "eval_macro_f1": 0.5091665983200073,
            "eval_macro_precision": 0.506377637386322,
            "eval_macro_recall": 0.5377758741378784,
            "eval_acc": 0.6881335718545021,
            "eval_runtime": 4.4555,
            "eval_samples_per_second": 376.391,
            "eval_steps_per_second": 23.567,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.6752921342849731,
            "eval_others_f1": 0.7524875621890547,
            "eval_others_precision": 0.7746478873239436,
            "eval_others_recall": 0.7315598548972189,
            "eval_joy_f1": 0.6666666666666667,
            "eval_joy_precision": 0.635,
            "eval_joy_recall": 0.7016574585635359,
            "eval_sadness_f1": 0.7506172839506173,
            "eval_sadness_precision": 0.7378640776699029,
            "eval_sadness_recall": 0.7638190954773869,
            "eval_anger_f1": 0.5937499999999999,
            "eval_anger_precision": 0.5327102803738317,
            "eval_anger_recall": 0.6705882352941176,
            "eval_surprise_f1": 0.3773584905660377,
            "eval_surprise_precision": 0.5263157894736842,
            "eval_surprise_recall": 0.29411764705882354,
            "eval_disgust_f1": 0.14634146341463414,
            "eval_disgust_precision": 0.375,
            "eval_disgust_recall": 0.09090909090909091,
            "eval_fear_f1": 0.5416666666666666,
            "eval_fear_precision": 0.43333333333333335,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.6923076923076923,
            "eval_macro_f1": 0.5469840168952942,
            "eval_macro_precision": 0.5735530257225037,
            "eval_macro_recall": 0.5678390860557556,
            "eval_acc": 0.6923076923076923,
            "eval_runtime": 4.4691,
            "eval_samples_per_second": 375.246,
            "eval_steps_per_second": 23.495,
            "epoch": 5.0
        }
    ],
    "model_name": "dccuchile/bert-base-spanish-wwm-cased"
}