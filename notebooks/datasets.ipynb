{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch.utils.data.dataset import IterableDataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class MyCustomDataset:\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_path in self.files:\n",
    "            with open(file_path) as f:\n",
    "                for line in f:\n",
    "                    yield line.strip(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from glob import glob\n",
    "\n",
    "tweet_files = glob(\"../data/filtered_tweets/*.txt\")[:1]\n",
    "my_ds = MyCustomDataset(\n",
    "    files=tweet_files\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from tqdm.auto import tqdm\n",
    "for x in tqdm(my_ds):\n",
    "    pass"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b209d0b63b6545a0946bb0961dc5444b"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=tweet_files)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default-574c5e67937ee6f5\n",
      "Reusing dataset text (/home/jmperez/.cache/huggingface/datasets/text/default-574c5e67937ee6f5/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tqdm.auto import tqdm\n",
    "for x in tqdm(dataset[\"train\"]):\n",
    "    pass"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/5233769 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbf6ff3fd4914352bad2b7ced7e41a4d"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es impresionante. Anda muy mal de la otra forma. Y con más datos es todavía peor\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "4 / 118"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.03389830508474576"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ese es el ratio"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Con transformación"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/twerto-base-uncased\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos qué pasa con la paralelización\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "tweets = [\"@usuario este es un tweet sarasa\"] * 500_000\n",
    "\n",
    "for tw in tqdm(tweets):\n",
    "    tokenizer(tw)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af6b4e0d017546d2ba3a3efcc833ea02"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "%%time\n",
    "\n",
    "tokenizer(tweets); None"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 10.5 s, sys: 3.92 s, total: 14.5 s\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "class NaiveProcessedDataset:\n",
    "    def __init__(self, files, batch_size=1024):\n",
    "        self.files = files\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_path in self.files:\n",
    "            with open(file_path) as f:\n",
    "                for line in f:\n",
    "                    yield tokenizer(line.strip(\"\\n\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "my_ds = NaiveProcessedDataset(\n",
    "    files=tweet_files\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "for x in tqdm(my_ds):\n",
    "    pass"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c8330b236a540549529330d1734bcfc"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "tokenizer.model_max_length = 128\n",
    "\n",
    "def tokenize(batch, padding='max_length'):\n",
    "    return tokenizer(batch['text'], padding=padding, truncation=True, return_special_tokens_mask=True)\n",
    "\n",
    "dataset[\"train\"].set_transform(tokenize)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "class BatchProcessedDataset(IterableDataset):\n",
    "    def __init__(self, files, batch_size=1024):\n",
    "        self.files = files\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_path in self.files:\n",
    "            with open(file_path) as f:\n",
    "\n",
    "                next_batch = [x.strip(\"\\n\") for _, x in zip(range(self.batch_size), f)]\n",
    "                \n",
    "                while next_batch:\n",
    "                    tokenized_batch = tokenizer(next_batch, padding='max_length', truncation=True, return_special_tokens_mask=True)\n",
    "                    for encoding in tokenized_batch.encodings:\n",
    "                        yield {\n",
    "                            \"input_ids\": encoding.ids,\n",
    "                            \"token_type_ids\": encoding.type_ids,\n",
    "                            \"attention_mask\": encoding.attention_mask,\n",
    "                            \"special_tokens_mask\": encoding.special_tokens_mask\n",
    "                        }\n",
    "                    next_batch = [x.strip(\"\\n\") for _, x in zip(range(self.batch_size), f)]\n",
    "my_ds = BatchProcessedDataset(\n",
    "    files=tweet_files,\n",
    "    batch_size=1024,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "my_ds = BatchProcessedDataset(\n",
    "    files=tweet_files,\n",
    "    batch_size=1024,\n",
    ")\n",
    "for x in tqdm(my_ds):\n",
    "    pass"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57dca0f3ca564ba7b4ce8f8cae83b0ff"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "con 1024 (hice algunas pruebas) parece tener la mejor performance\n",
    "\n",
    "Veamos si podemos engancharlo en el trainer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok, tenemos que emular esto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "encoding = (next(iter(my_ds)))\n",
    "\n",
    "encoding"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "\n",
    "ret = {\n",
    "    \"input_ids\": encoding.ids,\n",
    "    \"token_type_ids\": encoding.type_ids,\n",
    "    \"attention_mask\": encoding.attention_mask,\n",
    "    \"special_tokens_mask\": encoding.special_tokens_mask\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "ds_ex = dataset[\"train\"][0]\n",
    "\n",
    "{k:(ret[k] == ds_ex[k]) for k in ds_ex}"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': True,\n",
       " 'token_type_ids': True,\n",
       " 'attention_mask': True,\n",
       " 'special_tokens_mask': True}"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## set_transform vs custom"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "my_ds = BatchProcessedDataset(\n",
    "    files=tweet_files,\n",
    "    batch_size=1024,\n",
    ")\n",
    "for x in tqdm(my_ds):\n",
    "    pass"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50c451adb1f8402ea1de2cb0fce2c5fd"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for ex in tqdm(dataset[\"train\"]):\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Todo indica que tarda ḿucho más (al menos 3 veces más!)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15,\n",
    ")\n",
    "\n",
    "my_dataloader = DataLoader(\n",
    "    my_ds,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "ds_dataloader = DataLoader(\n",
    "    dataset[\"train\"],\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "from tqdm.auto import tqdm\n",
    "for batch in tqdm(zip(my_dataloader, range(500))): #total is aprox\n",
    "    pass"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "399c73079c0d4ab6a5d02fb927198d79"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "from tqdm.auto import tqdm\n",
    "for batch in tqdm(zip(ds_dataloader, range(500))): #total is aprox\n",
    "    pass"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ef31bcf28eb4db8a72ffcde55b5f415"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bueno, pareciera andar *mucho* mejor nuestro dataset... habrá que probar en el finetuning a ver qué onda"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python385jvsc74a57bd028c1932dff7617228923490e32f133f79d588eb74ca6c2b1f196ab0fdc858ed2",
   "display_name": "Python 3.8.5 64-bit ('finetune-vs-scratch-gHiQbun3-py3.8': poetry)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}