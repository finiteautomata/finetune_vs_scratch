{
    "context_hate": [
        {
            "eval_loss": 0.07961498200893402,
            "eval_calls_f1": 0.6773618538324421,
            "eval_women_f1": 0.4358974358974359,
            "eval_lgbti_f1": 0.463768115942029,
            "eval_racism_f1": 0.6606606606606606,
            "eval_class_f1": 0.5092250922509225,
            "eval_politics_f1": 0.6315789473684211,
            "eval_disabled_f1": 0.5622775800711745,
            "eval_appearance_f1": 0.7038413878562578,
            "eval_criminal_f1": 0.6020558002936859,
            "eval_mean_f1": 0.5829629898071289,
            "eval_mean_precision": 0.6025390028953552,
            "eval_mean_recall": 0.5714422464370728,
            "eval_hate_precision": 0.6897538637664568,
            "eval_hate_recall": 0.6705620478575404,
            "eval_hate_f1": 0.6800225733634311,
            "eval_runtime": 35.7256,
            "eval_samples_per_second": 317.504,
            "eval_steps_per_second": 19.846
        },
        {
            "eval_loss": 0.07969018816947937,
            "eval_calls_f1": 0.676056338028169,
            "eval_women_f1": 0.42677824267782427,
            "eval_lgbti_f1": 0.4827586206896552,
            "eval_racism_f1": 0.6640624999999999,
            "eval_class_f1": 0.5121107266435987,
            "eval_politics_f1": 0.6169491525423729,
            "eval_disabled_f1": 0.535593220338983,
            "eval_appearance_f1": 0.7215980024968788,
            "eval_criminal_f1": 0.6246418338108882,
            "eval_mean_f1": 0.5845053791999817,
            "eval_mean_precision": 0.5835273861885071,
            "eval_mean_recall": 0.5906878709793091,
            "eval_hate_precision": 0.6673877771768524,
            "eval_hate_recall": 0.6867000556483027,
            "eval_hate_f1": 0.6769061985737794,
            "eval_runtime": 35.0942,
            "eval_samples_per_second": 323.216,
            "eval_steps_per_second": 20.203
        },
        {
            "eval_loss": 0.07719607651233673,
            "eval_calls_f1": 0.6597938144329897,
            "eval_women_f1": 0.46520874751491054,
            "eval_lgbti_f1": 0.42651296829971175,
            "eval_racism_f1": 0.6698656429942419,
            "eval_class_f1": 0.5252525252525253,
            "eval_politics_f1": 0.6216216216216216,
            "eval_disabled_f1": 0.5190311418685121,
            "eval_appearance_f1": 0.7244283995186522,
            "eval_criminal_f1": 0.6388140161725068,
            "eval_mean_f1": 0.5833921432495117,
            "eval_mean_precision": 0.5737569332122803,
            "eval_mean_recall": 0.5988019704818726,
            "eval_hate_precision": 0.6718332442544094,
            "eval_hate_recall": 0.6994991652754591,
            "eval_hate_f1": 0.6853871319520174,
            "eval_runtime": 35.4842,
            "eval_samples_per_second": 319.663,
            "eval_steps_per_second": 19.981
        },
        {
            "eval_loss": 0.07892778515815735,
            "eval_calls_f1": 0.6962699822380107,
            "eval_women_f1": 0.4178498985801217,
            "eval_lgbti_f1": 0.45045045045045046,
            "eval_racism_f1": 0.6646825396825397,
            "eval_class_f1": 0.5277777777777777,
            "eval_politics_f1": 0.6185567010309279,
            "eval_disabled_f1": 0.5347222222222222,
            "eval_appearance_f1": 0.735,
            "eval_criminal_f1": 0.6481223922114047,
            "eval_mean_f1": 0.5881591439247131,
            "eval_mean_precision": 0.595129132270813,
            "eval_mean_recall": 0.5874654054641724,
            "eval_hate_precision": 0.6904895891952729,
            "eval_hate_recall": 0.6828046744574291,
            "eval_hate_f1": 0.6866256295467265,
            "eval_runtime": 35.2532,
            "eval_samples_per_second": 321.758,
            "eval_steps_per_second": 20.112
        },
        {
            "eval_loss": 0.08059178292751312,
            "eval_calls_f1": 0.6468531468531469,
            "eval_women_f1": 0.4214876033057851,
            "eval_lgbti_f1": 0.45045045045045046,
            "eval_racism_f1": 0.6612244897959183,
            "eval_class_f1": 0.5085910652920963,
            "eval_politics_f1": 0.6218487394957982,
            "eval_disabled_f1": 0.5121107266435986,
            "eval_appearance_f1": 0.7121951219512196,
            "eval_criminal_f1": 0.6446043165467625,
            "eval_mean_f1": 0.5754850506782532,
            "eval_mean_precision": 0.5835016965866089,
            "eval_mean_recall": 0.5747073888778687,
            "eval_hate_precision": 0.6798418972332015,
            "eval_hate_recall": 0.6700055648302726,
            "eval_hate_f1": 0.6748878923766816,
            "eval_runtime": 35.3212,
            "eval_samples_per_second": 321.138,
            "eval_steps_per_second": 20.073
        }
    ],
    "hate": [
        {
            "eval_loss": 1.0899684429168701,
            "eval_ok_f1": 0.8061926605504589,
            "eval_ok_precision": 0.8743781094527363,
            "eval_ok_recall": 0.747872340425532,
            "eval_hateful_f1": 0.7678571428571429,
            "eval_hateful_precision": 0.7022613065326633,
            "eval_hateful_recall": 0.8469696969696969,
            "eval_micro_f1": 0.7887499999999998,
            "eval_macro_f1": 0.7870248556137085,
            "eval_macro_precision": 0.7883197069168091,
            "eval_macro_recall": 0.7974210381507874,
            "eval_acc": 0.78875,
            "eval_runtime": 3.2368,
            "eval_samples_per_second": 494.32,
            "eval_steps_per_second": 30.895,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1265815496444702,
            "eval_ok_f1": 0.8059701492537313,
            "eval_ok_precision": 0.8753117206982544,
            "eval_ok_recall": 0.7468085106382979,
            "eval_hateful_f1": 0.7681755829903977,
            "eval_hateful_precision": 0.7017543859649122,
            "eval_hateful_recall": 0.8484848484848485,
            "eval_micro_f1": 0.7887499999999998,
            "eval_macro_f1": 0.7870728969573975,
            "eval_macro_precision": 0.788533091545105,
            "eval_macro_recall": 0.797646701335907,
            "eval_acc": 0.78875,
            "eval_runtime": 3.2683,
            "eval_samples_per_second": 489.552,
            "eval_steps_per_second": 30.597,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0603867769241333,
            "eval_ok_f1": 0.8038879359634077,
            "eval_ok_precision": 0.8689740420271941,
            "eval_ok_recall": 0.747872340425532,
            "eval_hateful_f1": 0.7636113025499655,
            "eval_hateful_precision": 0.7003792667509482,
            "eval_hateful_recall": 0.8393939393939394,
            "eval_micro_f1": 0.7856250000000001,
            "eval_macro_f1": 0.7837496399879456,
            "eval_macro_precision": 0.7846766710281372,
            "eval_macro_recall": 0.7936331033706665,
            "eval_acc": 0.785625,
            "eval_runtime": 3.2596,
            "eval_samples_per_second": 490.855,
            "eval_steps_per_second": 30.678,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.5999783277511597,
            "eval_ok_f1": 0.8033898305084746,
            "eval_ok_precision": 0.8566265060240964,
            "eval_ok_recall": 0.7563829787234042,
            "eval_hateful_f1": 0.7566433566433566,
            "eval_hateful_precision": 0.7025974025974026,
            "eval_hateful_recall": 0.8196969696969697,
            "eval_micro_f1": 0.7825,
            "eval_macro_f1": 0.7800166010856628,
            "eval_macro_precision": 0.7796119451522827,
            "eval_macro_recall": 0.7880399823188782,
            "eval_acc": 0.7825,
            "eval_runtime": 3.2141,
            "eval_samples_per_second": 497.809,
            "eval_steps_per_second": 31.113,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.6556044220924377,
            "eval_ok_f1": 0.7914991384261917,
            "eval_ok_precision": 0.8601747815230961,
            "eval_ok_recall": 0.7329787234042553,
            "eval_hateful_f1": 0.7511994516792323,
            "eval_hateful_precision": 0.685857321652065,
            "eval_hateful_recall": 0.8303030303030303,
            "eval_micro_f1": 0.7731250000000001,
            "eval_macro_f1": 0.771349310874939,
            "eval_macro_precision": 0.7730160355567932,
            "eval_macro_recall": 0.781640887260437,
            "eval_acc": 0.773125,
            "eval_runtime": 3.2861,
            "eval_samples_per_second": 486.892,
            "eval_steps_per_second": 30.431,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 0.7463095188140869,
            "eval_neg_f1": 0.7725573077548366,
            "eval_neg_precision": 0.7397260273972602,
            "eval_neg_recall": 0.8084382443007826,
            "eval_neu_f1": 0.5221932114882507,
            "eval_neu_precision": 0.5364806866952789,
            "eval_neu_recall": 0.508646998982706,
            "eval_pos_f1": 0.7521442709478777,
            "eval_pos_precision": 0.7815356489945156,
            "eval_pos_recall": 0.7248834251801611,
            "eval_micro_f1": 0.7001651982378855,
            "eval_macro_f1": 0.6822982430458069,
            "eval_macro_precision": 0.6859140992164612,
            "eval_macro_recall": 0.6806562542915344,
            "eval_acc": 0.7001651982378855,
            "eval_runtime": 10.1148,
            "eval_samples_per_second": 718.154,
            "eval_steps_per_second": 44.885,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.4665523767471313,
            "eval_neg_f1": 0.7521126760563381,
            "eval_neg_precision": 0.7792776358993069,
            "eval_neg_recall": 0.7267778155835318,
            "eval_neu_f1": 0.5358369590107626,
            "eval_neu_precision": 0.4872969596001666,
            "eval_neu_recall": 0.595116988809766,
            "eval_pos_f1": 0.7462619950903816,
            "eval_pos_precision": 0.7879359095193214,
            "eval_pos_recall": 0.708774904620602,
            "eval_micro_f1": 0.6852973568281938,
            "eval_macro_f1": 0.6780705451965332,
            "eval_macro_precision": 0.6848368644714355,
            "eval_macro_recall": 0.6768898963928223,
            "eval_acc": 0.6852973568281938,
            "eval_runtime": 10.2109,
            "eval_samples_per_second": 711.398,
            "eval_steps_per_second": 44.462,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8053088784217834,
            "eval_neg_f1": 0.7640252454417953,
            "eval_neg_precision": 0.7880650994575045,
            "eval_neg_recall": 0.7414086423953726,
            "eval_neu_f1": 0.5441781650931977,
            "eval_neu_precision": 0.5191685912240185,
            "eval_neu_recall": 0.5717192268565615,
            "eval_pos_f1": 0.7585766034519497,
            "eval_pos_precision": 0.7626392459297343,
            "eval_pos_recall": 0.7545570156846121,
            "eval_micro_f1": 0.6997522026431718,
            "eval_macro_f1": 0.6889266967773438,
            "eval_macro_precision": 0.6899576187133789,
            "eval_macro_recall": 0.6892282962799072,
            "eval_acc": 0.6997522026431718,
            "eval_runtime": 10.1329,
            "eval_samples_per_second": 716.876,
            "eval_steps_per_second": 44.805,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8080645203590393,
            "eval_neg_f1": 0.7621786197564274,
            "eval_neg_precision": 0.7578203834510595,
            "eval_neg_recall": 0.7665872745831915,
            "eval_neu_f1": 0.555235775957494,
            "eval_neu_precision": 0.4915719325754606,
            "eval_neu_recall": 0.6378433367243134,
            "eval_pos_f1": 0.7148084898755794,
            "eval_pos_precision": 0.8419540229885057,
            "eval_pos_recall": 0.6210258584145825,
            "eval_micro_f1": 0.6844713656387665,
            "eval_macro_f1": 0.6774075627326965,
            "eval_macro_precision": 0.697115421295166,
            "eval_macro_recall": 0.6751521229743958,
            "eval_acc": 0.6844713656387665,
            "eval_runtime": 10.151,
            "eval_samples_per_second": 715.595,
            "eval_steps_per_second": 44.725,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.3342567682266235,
            "eval_neg_f1": 0.7481706228805997,
            "eval_neg_precision": 0.7867867867867868,
            "eval_neg_recall": 0.7131677441306566,
            "eval_neu_f1": 0.5382538253825382,
            "eval_neu_precision": 0.4826472962066182,
            "eval_neu_recall": 0.6083418107833164,
            "eval_pos_f1": 0.7431376924793571,
            "eval_pos_precision": 0.7846371347785108,
            "eval_pos_recall": 0.7058075455701568,
            "eval_micro_f1": 0.6824063876651982,
            "eval_macro_f1": 0.6765206456184387,
            "eval_macro_precision": 0.6846904158592224,
            "eval_macro_recall": 0.6757723689079285,
            "eval_acc": 0.6824063876651982,
            "eval_runtime": 10.1738,
            "eval_samples_per_second": 713.993,
            "eval_steps_per_second": 44.625,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.6254771947860718,
            "eval_others_f1": 0.7686658506731947,
            "eval_others_precision": 0.7781908302354399,
            "eval_others_recall": 0.7593712212817413,
            "eval_joy_f1": 0.6593406593406593,
            "eval_joy_precision": 0.6557377049180327,
            "eval_joy_recall": 0.6629834254143646,
            "eval_sadness_f1": 0.7721822541966428,
            "eval_sadness_precision": 0.7385321100917431,
            "eval_sadness_recall": 0.8090452261306532,
            "eval_anger_f1": 0.6038781163434903,
            "eval_anger_precision": 0.5706806282722513,
            "eval_anger_recall": 0.6411764705882353,
            "eval_surprise_f1": 0.3739837398373984,
            "eval_surprise_precision": 0.41818181818181815,
            "eval_surprise_recall": 0.3382352941176471,
            "eval_disgust_f1": 0.043478260869565216,
            "eval_disgust_precision": 0.07692307692307693,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.5777777777777777,
            "eval_fear_precision": 0.48148148148148145,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.7006559332140727,
            "eval_macro_f1": 0.5427581071853638,
            "eval_macro_precision": 0.5313896536827087,
            "eval_macro_recall": 0.5661910176277161,
            "eval_acc": 0.7006559332140727,
            "eval_runtime": 3.8775,
            "eval_samples_per_second": 432.494,
            "eval_steps_per_second": 27.079,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.4387133121490479,
            "eval_others_f1": 0.7576142131979695,
            "eval_others_precision": 0.7970627503337784,
            "eval_others_recall": 0.7218863361547763,
            "eval_joy_f1": 0.6799468791500664,
            "eval_joy_precision": 0.6547314578005116,
            "eval_joy_recall": 0.7071823204419889,
            "eval_sadness_f1": 0.7523809523809524,
            "eval_sadness_precision": 0.7149321266968326,
            "eval_sadness_recall": 0.7939698492462312,
            "eval_anger_f1": 0.5770308123249298,
            "eval_anger_precision": 0.5508021390374331,
            "eval_anger_recall": 0.6058823529411764,
            "eval_surprise_f1": 0.4117647058823529,
            "eval_surprise_precision": 0.4117647058823529,
            "eval_surprise_recall": 0.4117647058823529,
            "eval_disgust_f1": 0.13333333333333333,
            "eval_disgust_precision": 0.14814814814814814,
            "eval_disgust_recall": 0.12121212121212122,
            "eval_fear_f1": 0.5384615384615384,
            "eval_fear_precision": 0.4117647058823529,
            "eval_fear_recall": 0.7777777777777778,
            "eval_micro_f1": 0.691711389385808,
            "eval_macro_f1": 0.5500760674476624,
            "eval_macro_precision": 0.5270294547080994,
            "eval_macro_recall": 0.5913822054862976,
            "eval_acc": 0.691711389385808,
            "eval_runtime": 3.9528,
            "eval_samples_per_second": 424.257,
            "eval_steps_per_second": 26.564,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.6429394483566284,
            "eval_others_f1": 0.7679012345679012,
            "eval_others_precision": 0.7843631778058008,
            "eval_others_recall": 0.7521160822249093,
            "eval_joy_f1": 0.6756393001345895,
            "eval_joy_precision": 0.6587926509186351,
            "eval_joy_recall": 0.6933701657458563,
            "eval_sadness_f1": 0.7536231884057971,
            "eval_sadness_precision": 0.7255813953488373,
            "eval_sadness_recall": 0.7839195979899497,
            "eval_anger_f1": 0.6233062330623306,
            "eval_anger_precision": 0.5778894472361809,
            "eval_anger_recall": 0.6764705882352942,
            "eval_surprise_f1": 0.3770491803278689,
            "eval_surprise_precision": 0.42592592592592593,
            "eval_surprise_recall": 0.3382352941176471,
            "eval_disgust_f1": 0.13333333333333333,
            "eval_disgust_precision": 0.25,
            "eval_disgust_recall": 0.09090909090909091,
            "eval_fear_f1": 0.6341463414634146,
            "eval_fear_precision": 0.5652173913043478,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.7054263565891473,
            "eval_macro_f1": 0.5664284229278564,
            "eval_macro_precision": 0.5696814656257629,
            "eval_macro_recall": 0.5796061158180237,
            "eval_acc": 0.7054263565891473,
            "eval_runtime": 3.7236,
            "eval_samples_per_second": 450.371,
            "eval_steps_per_second": 28.199,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.4791988134384155,
            "eval_others_f1": 0.7533460803059273,
            "eval_others_precision": 0.7964959568733153,
            "eval_others_recall": 0.7146311970979444,
            "eval_joy_f1": 0.6805194805194806,
            "eval_joy_precision": 0.6421568627450981,
            "eval_joy_recall": 0.7237569060773481,
            "eval_sadness_f1": 0.7777777777777777,
            "eval_sadness_precision": 0.7488372093023256,
            "eval_sadness_recall": 0.8090452261306532,
            "eval_anger_f1": 0.5243243243243242,
            "eval_anger_precision": 0.485,
            "eval_anger_recall": 0.5705882352941176,
            "eval_surprise_f1": 0.3652173913043478,
            "eval_surprise_precision": 0.44680851063829785,
            "eval_surprise_recall": 0.3088235294117647,
            "eval_disgust_f1": 0.16901408450704225,
            "eval_disgust_precision": 0.15789473684210525,
            "eval_disgust_recall": 0.18181818181818182,
            "eval_fear_f1": 0.5333333333333333,
            "eval_fear_precision": 0.4444444444444444,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6857483601669648,
            "eval_macro_f1": 0.5433617830276489,
            "eval_macro_precision": 0.5316625237464905,
            "eval_macro_recall": 0.5679042935371399,
            "eval_acc": 0.6857483601669648,
            "eval_runtime": 3.8334,
            "eval_samples_per_second": 437.47,
            "eval_steps_per_second": 27.391,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.651352047920227,
            "eval_others_f1": 0.7786732796032237,
            "eval_others_precision": 0.7989821882951654,
            "eval_others_recall": 0.7593712212817413,
            "eval_joy_f1": 0.6939313984168866,
            "eval_joy_precision": 0.6641414141414141,
            "eval_joy_recall": 0.7265193370165746,
            "eval_sadness_f1": 0.7753086419753086,
            "eval_sadness_precision": 0.7621359223300971,
            "eval_sadness_recall": 0.7889447236180904,
            "eval_anger_f1": 0.6428571428571429,
            "eval_anger_precision": 0.6030927835051546,
            "eval_anger_recall": 0.6882352941176471,
            "eval_surprise_f1": 0.3966942148760331,
            "eval_surprise_precision": 0.4528301886792453,
            "eval_surprise_recall": 0.35294117647058826,
            "eval_disgust_f1": 0.18181818181818182,
            "eval_disgust_precision": 0.36363636363636365,
            "eval_disgust_recall": 0.12121212121212122,
            "eval_fear_f1": 0.4897959183673469,
            "eval_fear_precision": 0.3870967741935484,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.7185450208706022,
            "eval_macro_f1": 0.5655826330184937,
            "eval_macro_precision": 0.5759879350662231,
            "eval_macro_recall": 0.5862700343132019,
            "eval_acc": 0.7185450208706022,
            "eval_runtime": 3.6568,
            "eval_samples_per_second": 458.595,
            "eval_steps_per_second": 28.713,
            "epoch": 5.0
        }
    ],
    "model_name": "models/beto-uncased-10000/"
}