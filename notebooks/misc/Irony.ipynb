{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "sorted(glob.glob(\"../../data/irony/*.csv\"))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../../data/irony/irosva.cu.test.csv',\n",
       " '../../data/irony/irosva.cu.test.truth.csv',\n",
       " '../../data/irony/irosva.cu.training.csv',\n",
       " '../../data/irony/irosva.es.test.csv',\n",
       " '../../data/irony/irosva.es.test.truth.csv',\n",
       " '../../data/irony/irosva.es.training.csv',\n",
       " '../../data/irony/irosva.mx.test.csv',\n",
       " '../../data/irony/irosva.mx.test.truth.csv',\n",
       " '../../data/irony/irosva.mx.training.csv']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs_train = []\n",
    "mapping = {\n",
    "    \"ID\": \"id\",\n",
    "    \"TOPIC\": \"topic\",\n",
    "    \"IS_IRONIC\": \"is_ironic\",\n",
    "    \"MESSAGE\": \"text\"\n",
    "}\n",
    "\n",
    "\n",
    "for lang in {\"cu\", \"es\", \"mx\"}:\n",
    "    name = f\"../../data/irony/irosva.{lang}.training.csv\"\n",
    "    print(name)\n",
    "    df = pd.read_csv(name).rename(columns=mapping).set_index(\"id\")\n",
    "\n",
    "    df[\"lang\"] = lang\n",
    "    dfs_train.append(df)\n",
    "\n",
    "df_train = pd.concat(dfs_train)\n",
    "df_train[\"split\"] = \"train\"\n",
    "\n",
    "df_train"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "../../data/irony/irosva.cu.training.csv\n",
      "../../data/irony/irosva.mx.training.csv\n",
      "../../data/irony/irosva.es.training.csv\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>is_ironic</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4fdfed6e794a4c1c1550a2996803ba6e</th>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>magnifico</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64dc97da772a5d70b62c2c124e12705d</th>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>VIVA EL PAQUETE. Mas pelis clásicas por favor....</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d66fc3e9a7353a1495a889f34e6371af</th>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>gracias una y mil veces por la programación de...</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b303e9eeb0c1ca5c2ec80047dff519b</th>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>LA TV DIGITAL ESTA SIENDO MUY EFICIENTE.</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd8a327fe8d642851db4b702069df1f0</th>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>O sea que los trabajadores de salario medio, l...</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c7d8c96599d6bb80f5a20b7745247ce3</th>\n",
       "      <td>PAÑALESIGLESIAS</td>\n",
       "      <td>0</td>\n",
       "      <td>Si @Pablo_Iglesias_  está preparado para ser p...</td>\n",
       "      <td>es</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b02956bf2e807712d878915f2e30391</th>\n",
       "      <td>PAÑALESIGLESIAS</td>\n",
       "      <td>0</td>\n",
       "      <td>La soberbia de @Pablo_Iglesias_ no tiene límit...</td>\n",
       "      <td>es</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c54463386b8e7f957428f4bc52a69cde</th>\n",
       "      <td>PAÑALESIGLESIAS</td>\n",
       "      <td>0</td>\n",
       "      <td>@Pablo_Iglesias_ dice que lleva tres meses cam...</td>\n",
       "      <td>es</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>082a73375a735a5c53f88a64146d2799</th>\n",
       "      <td>PAÑALESIGLESIAS</td>\n",
       "      <td>0</td>\n",
       "      <td>@CristinaSegui_ @Pablo_Iglesias_ Yo cambié pañ...</td>\n",
       "      <td>es</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73fa4d829d976828eb31d11235c902e0</th>\n",
       "      <td>PAÑALESIGLESIAS</td>\n",
       "      <td>0</td>\n",
       "      <td>@Pablo_Iglesias_ Tu a tus pañales ese debe ser...</td>\n",
       "      <td>es</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              topic  \\\n",
       "id                                                                                    \n",
       "4fdfed6e794a4c1c1550a2996803ba6e  TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...   \n",
       "64dc97da772a5d70b62c2c124e12705d  TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...   \n",
       "d66fc3e9a7353a1495a889f34e6371af  TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...   \n",
       "7b303e9eeb0c1ca5c2ec80047dff519b  TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...   \n",
       "fd8a327fe8d642851db4b702069df1f0  TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...   \n",
       "...                                                                             ...   \n",
       "c7d8c96599d6bb80f5a20b7745247ce3                                    PAÑALESIGLESIAS   \n",
       "0b02956bf2e807712d878915f2e30391                                    PAÑALESIGLESIAS   \n",
       "c54463386b8e7f957428f4bc52a69cde                                    PAÑALESIGLESIAS   \n",
       "082a73375a735a5c53f88a64146d2799                                    PAÑALESIGLESIAS   \n",
       "73fa4d829d976828eb31d11235c902e0                                    PAÑALESIGLESIAS   \n",
       "\n",
       "                                  is_ironic  \\\n",
       "id                                            \n",
       "4fdfed6e794a4c1c1550a2996803ba6e          1   \n",
       "64dc97da772a5d70b62c2c124e12705d          1   \n",
       "d66fc3e9a7353a1495a889f34e6371af          1   \n",
       "7b303e9eeb0c1ca5c2ec80047dff519b          1   \n",
       "fd8a327fe8d642851db4b702069df1f0          1   \n",
       "...                                     ...   \n",
       "c7d8c96599d6bb80f5a20b7745247ce3          0   \n",
       "0b02956bf2e807712d878915f2e30391          0   \n",
       "c54463386b8e7f957428f4bc52a69cde          0   \n",
       "082a73375a735a5c53f88a64146d2799          0   \n",
       "73fa4d829d976828eb31d11235c902e0          0   \n",
       "\n",
       "                                                                               text  \\\n",
       "id                                                                                    \n",
       "4fdfed6e794a4c1c1550a2996803ba6e                                          magnifico   \n",
       "64dc97da772a5d70b62c2c124e12705d  VIVA EL PAQUETE. Mas pelis clásicas por favor....   \n",
       "d66fc3e9a7353a1495a889f34e6371af  gracias una y mil veces por la programación de...   \n",
       "7b303e9eeb0c1ca5c2ec80047dff519b           LA TV DIGITAL ESTA SIENDO MUY EFICIENTE.   \n",
       "fd8a327fe8d642851db4b702069df1f0  O sea que los trabajadores de salario medio, l...   \n",
       "...                                                                             ...   \n",
       "c7d8c96599d6bb80f5a20b7745247ce3  Si @Pablo_Iglesias_  está preparado para ser p...   \n",
       "0b02956bf2e807712d878915f2e30391  La soberbia de @Pablo_Iglesias_ no tiene límit...   \n",
       "c54463386b8e7f957428f4bc52a69cde  @Pablo_Iglesias_ dice que lleva tres meses cam...   \n",
       "082a73375a735a5c53f88a64146d2799  @CristinaSegui_ @Pablo_Iglesias_ Yo cambié pañ...   \n",
       "73fa4d829d976828eb31d11235c902e0  @Pablo_Iglesias_ Tu a tus pañales ese debe ser...   \n",
       "\n",
       "                                 lang  split  \n",
       "id                                            \n",
       "4fdfed6e794a4c1c1550a2996803ba6e   cu  train  \n",
       "64dc97da772a5d70b62c2c124e12705d   cu  train  \n",
       "d66fc3e9a7353a1495a889f34e6371af   cu  train  \n",
       "7b303e9eeb0c1ca5c2ec80047dff519b   cu  train  \n",
       "fd8a327fe8d642851db4b702069df1f0   cu  train  \n",
       "...                               ...    ...  \n",
       "c7d8c96599d6bb80f5a20b7745247ce3   es  train  \n",
       "0b02956bf2e807712d878915f2e30391   es  train  \n",
       "c54463386b8e7f957428f4bc52a69cde   es  train  \n",
       "082a73375a735a5c53f88a64146d2799   es  train  \n",
       "73fa4d829d976828eb31d11235c902e0   es  train  \n",
       "\n",
       "[7200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "dfs_test = []\n",
    "\n",
    "for lang in {\"cu\", \"es\", \"mx\"}:\n",
    "    name = f\"../../data/irony/irosva.{lang}.test.csv\"\n",
    "    gold_name = f\"../../data/irony/irosva.{lang}.test.truth.csv\"\n",
    "    print(name)\n",
    "    df = pd.read_csv(name).rename(columns=mapping)\n",
    "    del df[\"is_ironic\"]\n",
    "    df_gold = pd.read_csv(gold_name).rename(columns=mapping)\n",
    "\n",
    "    df = df.merge(df_gold.loc[:, [\"id\", \"is_ironic\"]], on=\"id\")\n",
    "\n",
    "    df[\"lang\"] = lang\n",
    "    dfs_test.append(df)\n",
    "\n",
    "df_test = pd.concat(dfs_test).set_index(\"id\")\n",
    "df_test[\"split\"] = \"test\"\n",
    "df_test"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "../../data/irony/irosva.cu.test.csv\n",
      "../../data/irony/irosva.mx.test.csv\n",
      "../../data/irony/irosva.es.test.csv\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>is_ironic</th>\n",
       "      <th>lang</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00466090f558ec4d1a4b312284aee502</th>\n",
       "      <td>ECONOMÍA. TURISMOS, HOTELES</td>\n",
       "      <td>La oferta es 90 por persona por noche la habit...</td>\n",
       "      <td>0</td>\n",
       "      <td>cu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0069480d19db6f82600e0d34501281d2</th>\n",
       "      <td>TRANSPORTE, BOTEROS, CHOFERES, ÓMNIBUS, RUTAS</td>\n",
       "      <td>Si vamos a hacer la denuncia, hacedla con todo...</td>\n",
       "      <td>0</td>\n",
       "      <td>cu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0097b7f8824cf7465f7963aa0b85c98c</th>\n",
       "      <td>ETECSA,  CALIDAD, SERVICIOS</td>\n",
       "      <td>?Creo q es una falta d repeto los precios q ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>cu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00d1e2079fc31d88e7a7f5f743e321ea</th>\n",
       "      <td>NUEVAS TECNOLOGÍAS, INFORMATIZACIÓN DE LA SOCI...</td>\n",
       "      <td>muy buen articulo, espero que nuestra red siga...</td>\n",
       "      <td>0</td>\n",
       "      <td>cu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00f2c9d7f54f25dba6d0deb88a6fe404</th>\n",
       "      <td>ETECSA,  CALIDAD, SERVICIOS</td>\n",
       "      <td>Yo pagaria los 15 cuc, por algo se empieza, ah...</td>\n",
       "      <td>1</td>\n",
       "      <td>cu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fea7cf900843088ae903e4edd0210327</th>\n",
       "      <td>PAÑALESIGLESIAS</td>\n",
       "      <td>@jemayfe @CristinaSegui_ @Pablo_Iglesias_ Pero...</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fed227d47401c5177ad6f8ad89425e36</th>\n",
       "      <td>VENACENAR</td>\n",
       "      <td>#VenACenar289\\nEn los anuncios a Zidane le da ...</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff275a1c87a34cf9dd5a957e9c64ff1a</th>\n",
       "      <td>TIERRAPLANISTAS</td>\n",
       "      <td>Por qué hay un documental de la tierra es plan...</td>\n",
       "      <td>0</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd197f7ab7498cf6d719d655db1262a</th>\n",
       "      <td>LIBROSÁNCHEZ</td>\n",
       "      <td>@JosPastr Ojalá se cumpla Sr. Sánchez y su lib...</td>\n",
       "      <td>0</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffbf194de686f0718f79c4ccc975609</th>\n",
       "      <td>YOCONALBERT</td>\n",
       "      <td>#YoConAlbert \\nMassssss lameculismo https://t....</td>\n",
       "      <td>0</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              topic  \\\n",
       "id                                                                                    \n",
       "00466090f558ec4d1a4b312284aee502                        ECONOMÍA. TURISMOS, HOTELES   \n",
       "0069480d19db6f82600e0d34501281d2      TRANSPORTE, BOTEROS, CHOFERES, ÓMNIBUS, RUTAS   \n",
       "0097b7f8824cf7465f7963aa0b85c98c                        ETECSA,  CALIDAD, SERVICIOS   \n",
       "00d1e2079fc31d88e7a7f5f743e321ea  NUEVAS TECNOLOGÍAS, INFORMATIZACIÓN DE LA SOCI...   \n",
       "00f2c9d7f54f25dba6d0deb88a6fe404                        ETECSA,  CALIDAD, SERVICIOS   \n",
       "...                                                                             ...   \n",
       "fea7cf900843088ae903e4edd0210327                                    PAÑALESIGLESIAS   \n",
       "fed227d47401c5177ad6f8ad89425e36                                          VENACENAR   \n",
       "ff275a1c87a34cf9dd5a957e9c64ff1a                                    TIERRAPLANISTAS   \n",
       "ffd197f7ab7498cf6d719d655db1262a                                       LIBROSÁNCHEZ   \n",
       "fffbf194de686f0718f79c4ccc975609                                        YOCONALBERT   \n",
       "\n",
       "                                                                               text  \\\n",
       "id                                                                                    \n",
       "00466090f558ec4d1a4b312284aee502  La oferta es 90 por persona por noche la habit...   \n",
       "0069480d19db6f82600e0d34501281d2  Si vamos a hacer la denuncia, hacedla con todo...   \n",
       "0097b7f8824cf7465f7963aa0b85c98c  ?Creo q es una falta d repeto los precios q ti...   \n",
       "00d1e2079fc31d88e7a7f5f743e321ea  muy buen articulo, espero que nuestra red siga...   \n",
       "00f2c9d7f54f25dba6d0deb88a6fe404  Yo pagaria los 15 cuc, por algo se empieza, ah...   \n",
       "...                                                                             ...   \n",
       "fea7cf900843088ae903e4edd0210327  @jemayfe @CristinaSegui_ @Pablo_Iglesias_ Pero...   \n",
       "fed227d47401c5177ad6f8ad89425e36  #VenACenar289\\nEn los anuncios a Zidane le da ...   \n",
       "ff275a1c87a34cf9dd5a957e9c64ff1a  Por qué hay un documental de la tierra es plan...   \n",
       "ffd197f7ab7498cf6d719d655db1262a  @JosPastr Ojalá se cumpla Sr. Sánchez y su lib...   \n",
       "fffbf194de686f0718f79c4ccc975609  #YoConAlbert \\nMassssss lameculismo https://t....   \n",
       "\n",
       "                                  is_ironic lang split  \n",
       "id                                                      \n",
       "00466090f558ec4d1a4b312284aee502          0   cu  test  \n",
       "0069480d19db6f82600e0d34501281d2          0   cu  test  \n",
       "0097b7f8824cf7465f7963aa0b85c98c          0   cu  test  \n",
       "00d1e2079fc31d88e7a7f5f743e321ea          0   cu  test  \n",
       "00f2c9d7f54f25dba6d0deb88a6fe404          1   cu  test  \n",
       "...                                     ...  ...   ...  \n",
       "fea7cf900843088ae903e4edd0210327          1   es  test  \n",
       "fed227d47401c5177ad6f8ad89425e36          1   es  test  \n",
       "ff275a1c87a34cf9dd5a957e9c64ff1a          0   es  test  \n",
       "ffd197f7ab7498cf6d719d655db1262a          0   es  test  \n",
       "fffbf194de686f0718f79c4ccc975609          0   es  test  \n",
       "\n",
       "[1800 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "df = pd.concat([df_train, df_test])\n",
    "\n",
    "df.to_csv(\"../../data/irony/irosva_dataset.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reload"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "df = pd.read_csv(\"../../data/irony/irosva_dataset.csv\")\n",
    "\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "      <th>is_ironic</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fdfed6e794a4c1c1550a2996803ba6e</td>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>magnifico</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64dc97da772a5d70b62c2c124e12705d</td>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>VIVA EL PAQUETE. Mas pelis clásicas por favor....</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d66fc3e9a7353a1495a889f34e6371af</td>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>gracias una y mil veces por la programación de...</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7b303e9eeb0c1ca5c2ec80047dff519b</td>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>LA TV DIGITAL ESTA SIENDO MUY EFICIENTE.</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fd8a327fe8d642851db4b702069df1f0</td>\n",
       "      <td>TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...</td>\n",
       "      <td>1</td>\n",
       "      <td>O sea que los trabajadores de salario medio, l...</td>\n",
       "      <td>cu</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>fea7cf900843088ae903e4edd0210327</td>\n",
       "      <td>PAÑALESIGLESIAS</td>\n",
       "      <td>1</td>\n",
       "      <td>@jemayfe @CristinaSegui_ @Pablo_Iglesias_ Pero...</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>fed227d47401c5177ad6f8ad89425e36</td>\n",
       "      <td>VENACENAR</td>\n",
       "      <td>1</td>\n",
       "      <td>#VenACenar289\\nEn los anuncios a Zidane le da ...</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>ff275a1c87a34cf9dd5a957e9c64ff1a</td>\n",
       "      <td>TIERRAPLANISTAS</td>\n",
       "      <td>0</td>\n",
       "      <td>Por qué hay un documental de la tierra es plan...</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>ffd197f7ab7498cf6d719d655db1262a</td>\n",
       "      <td>LIBROSÁNCHEZ</td>\n",
       "      <td>0</td>\n",
       "      <td>@JosPastr Ojalá se cumpla Sr. Sánchez y su lib...</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>fffbf194de686f0718f79c4ccc975609</td>\n",
       "      <td>YOCONALBERT</td>\n",
       "      <td>0</td>\n",
       "      <td>#YoConAlbert \\nMassssss lameculismo https://t....</td>\n",
       "      <td>es</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0     4fdfed6e794a4c1c1550a2996803ba6e   \n",
       "1     64dc97da772a5d70b62c2c124e12705d   \n",
       "2     d66fc3e9a7353a1495a889f34e6371af   \n",
       "3     7b303e9eeb0c1ca5c2ec80047dff519b   \n",
       "4     fd8a327fe8d642851db4b702069df1f0   \n",
       "...                                ...   \n",
       "8995  fea7cf900843088ae903e4edd0210327   \n",
       "8996  fed227d47401c5177ad6f8ad89425e36   \n",
       "8997  ff275a1c87a34cf9dd5a957e9c64ff1a   \n",
       "8998  ffd197f7ab7498cf6d719d655db1262a   \n",
       "8999  fffbf194de686f0718f79c4ccc975609   \n",
       "\n",
       "                                                  topic  is_ironic  \\\n",
       "0     TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...          1   \n",
       "1     TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...          1   \n",
       "2     TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...          1   \n",
       "3     TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...          1   \n",
       "4     TELEVISIÓN DIGITAL, CAJAS DECODIFICADORAS, TEL...          1   \n",
       "...                                                 ...        ...   \n",
       "8995                                    PAÑALESIGLESIAS          1   \n",
       "8996                                          VENACENAR          1   \n",
       "8997                                    TIERRAPLANISTAS          0   \n",
       "8998                                       LIBROSÁNCHEZ          0   \n",
       "8999                                        YOCONALBERT          0   \n",
       "\n",
       "                                                   text lang  split  \n",
       "0                                             magnifico   cu  train  \n",
       "1     VIVA EL PAQUETE. Mas pelis clásicas por favor....   cu  train  \n",
       "2     gracias una y mil veces por la programación de...   cu  train  \n",
       "3              LA TV DIGITAL ESTA SIENDO MUY EFICIENTE.   cu  train  \n",
       "4     O sea que los trabajadores de salario medio, l...   cu  train  \n",
       "...                                                 ...  ...    ...  \n",
       "8995  @jemayfe @CristinaSegui_ @Pablo_Iglesias_ Pero...   es   test  \n",
       "8996  #VenACenar289\\nEn los anuncios a Zidane le da ...   es   test  \n",
       "8997  Por qué hay un documental de la tierra es plan...   es   test  \n",
       "8998  @JosPastr Ojalá se cumpla Sr. Sánchez y su lib...   es   test  \n",
       "8999  #YoConAlbert \\nMassssss lameculismo https://t....   es   test  \n",
       "\n",
       "[9000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "df[\"split\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "train    7200\n",
       "test     1800\n",
       "Name: split, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from finetune_vs_scratch.irony import load_datasets, run\n",
    "\n",
    "run(\"dccuchile/bert-base-spanish-wwm-cased\", \"cuda\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running Irony Detection experiments\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "064124aafd944903b05a38c79bd2566c"
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfc002c31a444affad79f19afeb297fd"
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64acc5787402472f81cab4c913dd8f52"
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running training *****\n",
      "  Num examples = 5400\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 845\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='845' max='845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [845/845 09:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Not ironic F1</th>\n",
       "      <th>Not ironic Precision</th>\n",
       "      <th>Not ironic Recall</th>\n",
       "      <th>Ironic F1</th>\n",
       "      <th>Ironic Precision</th>\n",
       "      <th>Ironic Recall</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.547006</td>\n",
       "      <td>0.779976</td>\n",
       "      <td>0.756460</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.514693</td>\n",
       "      <td>0.552581</td>\n",
       "      <td>0.481667</td>\n",
       "      <td>0.697222</td>\n",
       "      <td>0.647334</td>\n",
       "      <td>0.654521</td>\n",
       "      <td>0.643333</td>\n",
       "      <td>0.697222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.561596</td>\n",
       "      <td>0.818430</td>\n",
       "      <td>0.770022</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.552454</td>\n",
       "      <td>0.653759</td>\n",
       "      <td>0.478333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.685442</td>\n",
       "      <td>0.711890</td>\n",
       "      <td>0.675833</td>\n",
       "      <td>0.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.676256</td>\n",
       "      <td>0.819976</td>\n",
       "      <td>0.793453</td>\n",
       "      <td>0.848333</td>\n",
       "      <td>0.599821</td>\n",
       "      <td>0.647969</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.709898</td>\n",
       "      <td>0.720711</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.751667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>1.091675</td>\n",
       "      <td>0.826070</td>\n",
       "      <td>0.794005</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>0.604186</td>\n",
       "      <td>0.665331</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.715128</td>\n",
       "      <td>0.729668</td>\n",
       "      <td>0.707083</td>\n",
       "      <td>0.758333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>1.337918</td>\n",
       "      <td>0.817004</td>\n",
       "      <td>0.794488</td>\n",
       "      <td>0.840833</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.639623</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.748889</td>\n",
       "      <td>0.708502</td>\n",
       "      <td>0.717055</td>\n",
       "      <td>0.702917</td>\n",
       "      <td>0.748889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp1clcygha/checkpoint-169\n",
      "Configuration saved in /tmp/tmp1clcygha/checkpoint-169/config.json\n",
      "Model weights saved in /tmp/tmp1clcygha/checkpoint-169/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp1clcygha/checkpoint-338\n",
      "Configuration saved in /tmp/tmp1clcygha/checkpoint-338/config.json\n",
      "Model weights saved in /tmp/tmp1clcygha/checkpoint-338/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp1clcygha/checkpoint-507\n",
      "Configuration saved in /tmp/tmp1clcygha/checkpoint-507/config.json\n",
      "Model weights saved in /tmp/tmp1clcygha/checkpoint-507/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp1clcygha/checkpoint-676\n",
      "Configuration saved in /tmp/tmp1clcygha/checkpoint-676/config.json\n",
      "Model weights saved in /tmp/tmp1clcygha/checkpoint-676/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp1clcygha/checkpoint-845\n",
      "Configuration saved in /tmp/tmp1clcygha/checkpoint-845/config.json\n",
      "Model weights saved in /tmp/tmp1clcygha/checkpoint-845/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp/tmp1clcygha/checkpoint-676 (score: 0.7151275873184204).\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='113' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/113 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'eval_loss': 1.169751524925232,\n",
       " 'eval_not ironic_f1': 0.8225486304088924,\n",
       " 'eval_not ironic_precision': 0.7860394537177542,\n",
       " 'eval_not ironic_recall': 0.8626144879267277,\n",
       " 'eval_ironic_f1': 0.5864939870490287,\n",
       " 'eval_ironic_precision': 0.6576763485477178,\n",
       " 'eval_ironic_recall': 0.5292153589315526,\n",
       " 'eval_micro_f1': 0.7516666666666667,\n",
       " 'eval_macro_f1': 0.7045212984085083,\n",
       " 'eval_macro_precision': 0.7218579053878784,\n",
       " 'eval_macro_recall': 0.6959149241447449,\n",
       " 'eval_acc': 0.7516666666666667,\n",
       " 'eval_runtime': 14.6906,\n",
       " 'eval_samples_per_second': 122.528,\n",
       " 'eval_steps_per_second': 7.692,\n",
       " 'epoch': 5.0}"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from finetune_vs_scratch.irony import load_datasets, run\n",
    "\n",
    "run(\"finiteautomata/robertuito-base-uncased\", \"cuda\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Running Irony Detection experiments\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "loading configuration file https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/config.json from cache at /home/jmperez/.cache/huggingface/transformers/92f6f34cd163729c9e82ba3ae40b67f62634aef8756d6fa2fb5045fa367d43a9.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/jmperez/.cache/huggingface/transformers/tmph1zqq_0f\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a371592642ef46d3af0e7116d8752c63"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "storing https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/pytorch_model.bin in cache at /home/jmperez/.cache/huggingface/transformers/4ddff60a034e84904c1e7014236df570dde5fb393f52a84f496de5f9812d6ba3.a3b8a5feefc007b9002baf4811f8864279a25953ea96bf3657abe97f877831d6\n",
      "creating metadata file for /home/jmperez/.cache/huggingface/transformers/4ddff60a034e84904c1e7014236df570dde5fb393f52a84f496de5f9812d6ba3.a3b8a5feefc007b9002baf4811f8864279a25953ea96bf3657abe97f877831d6\n",
      "loading weights file https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/pytorch_model.bin from cache at /home/jmperez/.cache/huggingface/transformers/4ddff60a034e84904c1e7014236df570dde5fb393f52a84f496de5f9812d6ba3.a3b8a5feefc007b9002baf4811f8864279a25953ea96bf3657abe97f877831d6\n",
      "Some weights of the model checkpoint at finiteautomata/robertuito-base-uncased were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/robertuito-base-uncased and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /home/jmperez/.cache/huggingface/transformers/tmpzil3g2a9\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c61505ca7f74fa493dbf61be507e3f4"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/323 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "storing https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/tokenizer_config.json in cache at /home/jmperez/.cache/huggingface/transformers/142c0ee4e3f67f7b3267937fd6f5ad937be37312f9a322443e9c7ab69af879db.dee0dc8e8c4faa7c1ddf41f39d8e9c2de137a25062f44be5343911543b88278a\n",
      "creating metadata file for /home/jmperez/.cache/huggingface/transformers/142c0ee4e3f67f7b3267937fd6f5ad937be37312f9a322443e9c7ab69af879db.dee0dc8e8c4faa7c1ddf41f39d8e9c2de137a25062f44be5343911543b88278a\n",
      "https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /home/jmperez/.cache/huggingface/transformers/tmpnevv7uat\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0ee00c77fb3413ba613a0d054eab6f2"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "storing https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/special_tokens_map.json in cache at /home/jmperez/.cache/huggingface/transformers/286f3a8c6d5bcb53cbeadac7af8bb0cb578bd36e9a595a81079d35404f16f198.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "creating metadata file for /home/jmperez/.cache/huggingface/transformers/286f3a8c6d5bcb53cbeadac7af8bb0cb578bd36e9a595a81079d35404f16f198.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /home/jmperez/.cache/huggingface/transformers/tmpt9w4yb85\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b27d297f128d44d99582efb9f199b594"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/858k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "storing https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/tokenizer.json in cache at /home/jmperez/.cache/huggingface/transformers/c9abec70e4003c416eb48574805427aae3d55183aab482f184c7c3b3f403de46.c61b8b3a1d74525441ce91bdaf6f074e6da7f13a7df188bdb21f7d03eef018b0\n",
      "creating metadata file for /home/jmperez/.cache/huggingface/transformers/c9abec70e4003c416eb48574805427aae3d55183aab482f184c7c3b3f403de46.c61b8b3a1d74525441ce91bdaf6f074e6da7f13a7df188bdb21f7d03eef018b0\n",
      "loading file https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/special_tokens_map.json from cache at /home/jmperez/.cache/huggingface/transformers/286f3a8c6d5bcb53cbeadac7af8bb0cb578bd36e9a595a81079d35404f16f198.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/tokenizer_config.json from cache at /home/jmperez/.cache/huggingface/transformers/142c0ee4e3f67f7b3267937fd6f5ad937be37312f9a322443e9c7ab69af879db.dee0dc8e8c4faa7c1ddf41f39d8e9c2de137a25062f44be5343911543b88278a\n",
      "loading file https://huggingface.co/finiteautomata/robertuito-base-uncased/resolve/main/tokenizer.json from cache at /home/jmperez/.cache/huggingface/transformers/c9abec70e4003c416eb48574805427aae3d55183aab482f184c7c3b3f403de46.c61b8b3a1d74525441ce91bdaf6f074e6da7f13a7df188bdb21f7d03eef018b0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "976917037cd24342b3779161abd65cf5"
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67da3fc8502f471786b6fc480b201fb3"
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0647ab663538481e9644701f4acace4c"
      },
      "text/plain": [
       "  0%|          | 0/113 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running training *****\n",
      "  Num examples = 5400\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 845\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='845' max='845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [845/845 03:08, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Not ironic F1</th>\n",
       "      <th>Not ironic Precision</th>\n",
       "      <th>Not ironic Recall</th>\n",
       "      <th>Ironic F1</th>\n",
       "      <th>Ironic Precision</th>\n",
       "      <th>Ironic Recall</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493949</td>\n",
       "      <td>0.817292</td>\n",
       "      <td>0.800319</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.638686</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.751111</td>\n",
       "      <td>0.713524</td>\n",
       "      <td>0.719503</td>\n",
       "      <td>0.709167</td>\n",
       "      <td>0.751111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.569316</td>\n",
       "      <td>0.839717</td>\n",
       "      <td>0.758227</td>\n",
       "      <td>0.940833</td>\n",
       "      <td>0.526894</td>\n",
       "      <td>0.771704</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.760556</td>\n",
       "      <td>0.683305</td>\n",
       "      <td>0.764966</td>\n",
       "      <td>0.670417</td>\n",
       "      <td>0.760556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.628251</td>\n",
       "      <td>0.828079</td>\n",
       "      <td>0.835454</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.665029</td>\n",
       "      <td>0.653784</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.772778</td>\n",
       "      <td>0.746554</td>\n",
       "      <td>0.744619</td>\n",
       "      <td>0.748750</td>\n",
       "      <td>0.772778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.870694</td>\n",
       "      <td>0.828595</td>\n",
       "      <td>0.831376</td>\n",
       "      <td>0.825833</td>\n",
       "      <td>0.660596</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>0.744596</td>\n",
       "      <td>0.743813</td>\n",
       "      <td>0.745417</td>\n",
       "      <td>0.772222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.988231</td>\n",
       "      <td>0.835261</td>\n",
       "      <td>0.801071</td>\n",
       "      <td>0.872500</td>\n",
       "      <td>0.622141</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.770556</td>\n",
       "      <td>0.728701</td>\n",
       "      <td>0.745363</td>\n",
       "      <td>0.719583</td>\n",
       "      <td>0.770556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp6m_j7vbd/checkpoint-169\n",
      "Configuration saved in /tmp/tmp6m_j7vbd/checkpoint-169/config.json\n",
      "Model weights saved in /tmp/tmp6m_j7vbd/checkpoint-169/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp6m_j7vbd/checkpoint-338\n",
      "Configuration saved in /tmp/tmp6m_j7vbd/checkpoint-338/config.json\n",
      "Model weights saved in /tmp/tmp6m_j7vbd/checkpoint-338/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp6m_j7vbd/checkpoint-507\n",
      "Configuration saved in /tmp/tmp6m_j7vbd/checkpoint-507/config.json\n",
      "Model weights saved in /tmp/tmp6m_j7vbd/checkpoint-507/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp6m_j7vbd/checkpoint-676\n",
      "Configuration saved in /tmp/tmp6m_j7vbd/checkpoint-676/config.json\n",
      "Model weights saved in /tmp/tmp6m_j7vbd/checkpoint-676/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /tmp/tmp6m_j7vbd/checkpoint-845\n",
      "Configuration saved in /tmp/tmp6m_j7vbd/checkpoint-845/config.json\n",
      "Model weights saved in /tmp/tmp6m_j7vbd/checkpoint-845/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp/tmp6m_j7vbd/checkpoint-507 (score: 0.746553897857666).\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text, lang.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1800\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='113' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/113 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6851121783256531,\n",
       " 'eval_not ironic_f1': 0.8102220360284876,\n",
       " 'eval_not ironic_precision': 0.815345699831366,\n",
       " 'eval_not ironic_recall': 0.8051623646960866,\n",
       " 'eval_ironic_f1': 0.6265457543281122,\n",
       " 'eval_ironic_precision': 0.6188925081433225,\n",
       " 'eval_ironic_recall': 0.6343906510851419,\n",
       " 'eval_micro_f1': 0.7483333333333333,\n",
       " 'eval_macro_f1': 0.7183839082717896,\n",
       " 'eval_macro_precision': 0.7171190977096558,\n",
       " 'eval_macro_recall': 0.7197765111923218,\n",
       " 'eval_acc': 0.7483333333333333,\n",
       " 'eval_runtime': 4.3691,\n",
       " 'eval_samples_per_second': 411.986,\n",
       " 'eval_steps_per_second': 25.864,\n",
       " 'epoch': 5.0}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('finetune-vs-scratch-gHiQbun3-py3.8': poetry)"
  },
  "interpreter": {
   "hash": "28c1932dff7617228923490e32f133f79d588eb74ca6c2b1f196ab0fdc858ed2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}