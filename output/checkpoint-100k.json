{
    "context_hate": [
        {
            "eval_loss": 0.08069831877946854,
            "eval_calls_f1": 0.6359143327841845,
            "eval_women_f1": 0.41404805914972276,
            "eval_lgbti_f1": 0.45429362880886426,
            "eval_racism_f1": 0.6427947598253275,
            "eval_class_f1": 0.42172523961661335,
            "eval_politics_f1": 0.6158631415241058,
            "eval_disabled_f1": 0.5114754098360655,
            "eval_appearance_f1": 0.7102342786683107,
            "eval_criminal_f1": 0.6138107416879796,
            "eval_mean_f1": 0.557795524597168,
            "eval_mean_precision": 0.5236599445343018,
            "eval_mean_recall": 0.6022738814353943,
            "eval_hate_precision": 0.6435443037974684,
            "eval_hate_recall": 0.7072899276572064,
            "eval_hate_f1": 0.6739130434782609,
            "eval_runtime": 34.166,
            "eval_samples_per_second": 331.996,
            "eval_steps_per_second": 20.752
        },
        {
            "eval_loss": 0.08321724832057953,
            "eval_calls_f1": 0.6051779935275081,
            "eval_women_f1": 0.4320297951582868,
            "eval_lgbti_f1": 0.46,
            "eval_racism_f1": 0.6305329719963866,
            "eval_class_f1": 0.3837209302325581,
            "eval_politics_f1": 0.5905044510385756,
            "eval_disabled_f1": 0.5106382978723404,
            "eval_appearance_f1": 0.7002457002457002,
            "eval_criminal_f1": 0.591861898890259,
            "eval_mean_f1": 0.5449680089950562,
            "eval_mean_precision": 0.5028878450393677,
            "eval_mean_recall": 0.5972234010696411,
            "eval_hate_precision": 0.6347914547304171,
            "eval_hate_recall": 0.6944908180300501,
            "eval_hate_f1": 0.6633005580653734,
            "eval_runtime": 33.9131,
            "eval_samples_per_second": 334.473,
            "eval_steps_per_second": 20.906
        },
        {
            "eval_loss": 0.08145271986722946,
            "eval_calls_f1": 0.5980392156862745,
            "eval_women_f1": 0.4133099824868652,
            "eval_lgbti_f1": 0.48677248677248675,
            "eval_racism_f1": 0.6481149012567325,
            "eval_class_f1": 0.38006230529595014,
            "eval_politics_f1": 0.6161137440758293,
            "eval_disabled_f1": 0.5486111111111112,
            "eval_appearance_f1": 0.6990291262135923,
            "eval_criminal_f1": 0.5940337224383917,
            "eval_mean_f1": 0.5537874102592468,
            "eval_mean_precision": 0.5176445841789246,
            "eval_mean_recall": 0.597539484500885,
            "eval_hate_precision": 0.6377912867274569,
            "eval_hate_recall": 0.7006121313299944,
            "eval_hate_f1": 0.667727393264386,
            "eval_runtime": 34.742,
            "eval_samples_per_second": 326.493,
            "eval_steps_per_second": 20.408
        },
        {
            "eval_loss": 0.07969623059034348,
            "eval_calls_f1": 0.6175438596491228,
            "eval_women_f1": 0.4252252252252252,
            "eval_lgbti_f1": 0.48000000000000004,
            "eval_racism_f1": 0.6379468377635197,
            "eval_class_f1": 0.38730158730158737,
            "eval_politics_f1": 0.6038338658146966,
            "eval_disabled_f1": 0.5190311418685121,
            "eval_appearance_f1": 0.7048567870485679,
            "eval_criminal_f1": 0.5597667638483965,
            "eval_mean_f1": 0.5483896136283875,
            "eval_mean_precision": 0.5296950936317444,
            "eval_mean_recall": 0.5721047520637512,
            "eval_hate_precision": 0.6531165311653117,
            "eval_hate_recall": 0.6705620478575404,
            "eval_hate_f1": 0.6617243272926964,
            "eval_runtime": 35.0137,
            "eval_samples_per_second": 323.959,
            "eval_steps_per_second": 20.249
        },
        {
            "eval_loss": 0.08091045171022415,
            "eval_calls_f1": 0.6146496815286624,
            "eval_women_f1": 0.4256120527306968,
            "eval_lgbti_f1": 0.46276595744680854,
            "eval_racism_f1": 0.6440366972477065,
            "eval_class_f1": 0.3888888888888889,
            "eval_politics_f1": 0.62015503875969,
            "eval_disabled_f1": 0.5152542372881356,
            "eval_appearance_f1": 0.7192118226600986,
            "eval_criminal_f1": 0.5876288659793814,
            "eval_mean_f1": 0.5531336665153503,
            "eval_mean_precision": 0.5185533165931702,
            "eval_mean_recall": 0.5959596633911133,
            "eval_hate_precision": 0.653125,
            "eval_hate_recall": 0.6978297161936561,
            "eval_hate_f1": 0.6747376916868442,
            "eval_runtime": 34.7043,
            "eval_samples_per_second": 326.847,
            "eval_steps_per_second": 20.43
        }
    ],
    "hate": [
        {
            "eval_loss": 0.7612051367759705,
            "eval_ok_f1": 0.8170731707317074,
            "eval_ok_precision": 0.8530092592592593,
            "eval_ok_recall": 0.7840425531914894,
            "eval_hateful_f1": 0.7636103151862464,
            "eval_hateful_precision": 0.7241847826086957,
            "eval_hateful_recall": 0.8075757575757576,
            "eval_micro_f1": 0.79375,
            "eval_macro_f1": 0.7903417348861694,
            "eval_macro_precision": 0.788597047328949,
            "eval_macro_recall": 0.7958091497421265,
            "eval_acc": 0.79375,
            "eval_runtime": 3.4376,
            "eval_samples_per_second": 465.436,
            "eval_steps_per_second": 29.09,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7189295887947083,
            "eval_ok_f1": 0.7888823181549378,
            "eval_ok_precision": 0.8881491344873502,
            "eval_ok_recall": 0.7095744680851064,
            "eval_hateful_f1": 0.7634194831013916,
            "eval_hateful_precision": 0.6784452296819788,
            "eval_hateful_recall": 0.8727272727272727,
            "eval_micro_f1": 0.776875,
            "eval_macro_f1": 0.7761509418487549,
            "eval_macro_precision": 0.7832971811294556,
            "eval_macro_recall": 0.7911508679389954,
            "eval_acc": 0.776875,
            "eval_runtime": 3.3538,
            "eval_samples_per_second": 477.077,
            "eval_steps_per_second": 29.817,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7718445062637329,
            "eval_ok_f1": 0.7896287566293458,
            "eval_ok_precision": 0.8850726552179656,
            "eval_ok_recall": 0.7127659574468085,
            "eval_hateful_f1": 0.7624750499001997,
            "eval_hateful_precision": 0.6797153024911032,
            "eval_hateful_recall": 0.8681818181818182,
            "eval_micro_f1": 0.776875,
            "eval_macro_f1": 0.7760518789291382,
            "eval_macro_precision": 0.7823939323425293,
            "eval_macro_recall": 0.7904738783836365,
            "eval_acc": 0.776875,
            "eval_runtime": 3.5469,
            "eval_samples_per_second": 451.093,
            "eval_steps_per_second": 28.193,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7535107135772705,
            "eval_ok_f1": 0.8144846796657381,
            "eval_ok_precision": 0.8549707602339182,
            "eval_ok_recall": 0.7776595744680851,
            "eval_hateful_f1": 0.7629893238434163,
            "eval_hateful_precision": 0.7194630872483222,
            "eval_hateful_recall": 0.8121212121212121,
            "eval_micro_f1": 0.791875,
            "eval_macro_f1": 0.7887369990348816,
            "eval_macro_precision": 0.7872169017791748,
            "eval_macro_recall": 0.7948904037475586,
            "eval_acc": 0.791875,
            "eval_runtime": 3.4817,
            "eval_samples_per_second": 459.549,
            "eval_steps_per_second": 28.722,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7029995918273926,
            "eval_ok_f1": 0.7863849765258215,
            "eval_ok_precision": 0.8769633507853403,
            "eval_ok_recall": 0.7127659574468085,
            "eval_hateful_f1": 0.7566844919786095,
            "eval_hateful_precision": 0.6770334928229665,
            "eval_hateful_recall": 0.8575757575757575,
            "eval_micro_f1": 0.7725000000000001,
            "eval_macro_f1": 0.7715347409248352,
            "eval_macro_precision": 0.7769984006881714,
            "eval_macro_recall": 0.78517085313797,
            "eval_acc": 0.7725,
            "eval_runtime": 3.4717,
            "eval_samples_per_second": 460.865,
            "eval_steps_per_second": 28.804,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 0.8520897626876831,
            "eval_neg_f1": 0.7542553191489361,
            "eval_neg_precision": 0.7874861162532395,
            "eval_neg_recall": 0.7237155495066349,
            "eval_neu_f1": 0.5491383325570564,
            "eval_neu_precision": 0.5064432989690721,
            "eval_neu_recall": 0.5996948118006104,
            "eval_pos_f1": 0.760557248585111,
            "eval_pos_precision": 0.78165548098434,
            "eval_pos_recall": 0.7405680373039424,
            "eval_micro_f1": 0.6956222466960352,
            "eval_macro_f1": 0.6879835724830627,
            "eval_macro_precision": 0.691861629486084,
            "eval_macro_recall": 0.6879927515983582,
            "eval_acc": 0.6956222466960352,
            "eval_runtime": 10.4771,
            "eval_samples_per_second": 693.321,
            "eval_steps_per_second": 43.333,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.714547872543335,
            "eval_neg_f1": 0.7662536071974198,
            "eval_neg_precision": 0.7645663956639567,
            "eval_neg_recall": 0.7679482817284791,
            "eval_neu_f1": 0.5395507812500001,
            "eval_neu_precision": 0.5187793427230047,
            "eval_neu_recall": 0.5620549338758901,
            "eval_pos_f1": 0.7571019599207224,
            "eval_pos_precision": 0.7878093492208983,
            "eval_pos_recall": 0.7286986011021619,
            "eval_micro_f1": 0.6994768722466961,
            "eval_macro_f1": 0.6876354217529297,
            "eval_macro_precision": 0.6903850436210632,
            "eval_macro_recall": 0.6862339973449707,
            "eval_acc": 0.6994768722466961,
            "eval_runtime": 10.2321,
            "eval_samples_per_second": 709.925,
            "eval_steps_per_second": 44.37,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7363595962524414,
            "eval_neg_f1": 0.7580330197053079,
            "eval_neg_precision": 0.7925018559762435,
            "eval_neg_recall": 0.7264375637972099,
            "eval_neu_f1": 0.5612718039302275,
            "eval_neu_precision": 0.49590323839250877,
            "eval_neu_recall": 0.6464903357070193,
            "eval_pos_f1": 0.7540082455336693,
            "eval_pos_precision": 0.8201295465869457,
            "eval_pos_recall": 0.6977532852903773,
            "eval_micro_f1": 0.6954845814977973,
            "eval_macro_f1": 0.6911043524742126,
            "eval_macro_precision": 0.7028448581695557,
            "eval_macro_recall": 0.6902270317077637,
            "eval_acc": 0.6954845814977973,
            "eval_runtime": 10.2443,
            "eval_samples_per_second": 709.076,
            "eval_steps_per_second": 44.317,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8558847904205322,
            "eval_neg_f1": 0.7509306860485729,
            "eval_neg_precision": 0.7838638045891931,
            "eval_neg_recall": 0.720653283429738,
            "eval_neu_f1": 0.5465465465465466,
            "eval_neu_precision": 0.5006347862886161,
            "eval_neu_recall": 0.6017293997965412,
            "eval_pos_f1": 0.7617376042123738,
            "eval_pos_precision": 0.789449749886312,
            "eval_pos_recall": 0.7359050445103857,
            "eval_micro_f1": 0.693419603524229,
            "eval_macro_f1": 0.6864049434661865,
            "eval_macro_precision": 0.6913161277770996,
            "eval_macro_recall": 0.6860958933830261,
            "eval_acc": 0.693419603524229,
            "eval_runtime": 10.8885,
            "eval_samples_per_second": 667.123,
            "eval_steps_per_second": 41.695,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.9922834634780884,
            "eval_neg_f1": 0.7511455763130067,
            "eval_neg_precision": 0.7791590493601462,
            "eval_neg_recall": 0.7250765566519224,
            "eval_neu_f1": 0.5509781357882624,
            "eval_neu_precision": 0.5031525851197982,
            "eval_neu_recall": 0.6088504577822991,
            "eval_pos_f1": 0.7549345752938568,
            "eval_pos_precision": 0.7916279069767442,
            "eval_pos_recall": 0.7214921576939382,
            "eval_micro_f1": 0.6924559471365639,
            "eval_macro_f1": 0.6856861114501953,
            "eval_macro_precision": 0.6913132071495056,
            "eval_macro_recall": 0.6851397156715393,
            "eval_acc": 0.6924559471365639,
            "eval_runtime": 10.5434,
            "eval_samples_per_second": 688.963,
            "eval_steps_per_second": 43.06,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.2051312923431396,
            "eval_others_f1": 0.7433050293925539,
            "eval_others_precision": 0.8082386363636364,
            "eval_others_recall": 0.6880290205562273,
            "eval_joy_f1": 0.663978494623656,
            "eval_joy_precision": 0.6465968586387435,
            "eval_joy_recall": 0.6823204419889503,
            "eval_sadness_f1": 0.7761904761904761,
            "eval_sadness_precision": 0.7375565610859729,
            "eval_sadness_recall": 0.8190954773869347,
            "eval_anger_f1": 0.5643835616438355,
            "eval_anger_precision": 0.5282051282051282,
            "eval_anger_recall": 0.6058823529411764,
            "eval_surprise_f1": 0.3468208092485549,
            "eval_surprise_precision": 0.2857142857142857,
            "eval_surprise_recall": 0.4411764705882353,
            "eval_disgust_f1": 0.12307692307692308,
            "eval_disgust_precision": 0.125,
            "eval_disgust_recall": 0.12121212121212122,
            "eval_fear_f1": 0.35714285714285715,
            "eval_fear_precision": 0.2631578947368421,
            "eval_fear_recall": 0.5555555555555556,
            "eval_micro_f1": 0.6714370900417412,
            "eval_macro_f1": 0.5106997489929199,
            "eval_macro_precision": 0.48492422699928284,
            "eval_macro_recall": 0.5590388178825378,
            "eval_acc": 0.6714370900417412,
            "eval_runtime": 4.5125,
            "eval_samples_per_second": 371.638,
            "eval_steps_per_second": 23.269,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1848198175430298,
            "eval_others_f1": 0.7324128862590401,
            "eval_others_precision": 0.8025936599423631,
            "eval_others_recall": 0.6735187424425635,
            "eval_joy_f1": 0.6675531914893618,
            "eval_joy_precision": 0.6435897435897436,
            "eval_joy_recall": 0.6933701657458563,
            "eval_sadness_f1": 0.7393364928909951,
            "eval_sadness_precision": 0.6995515695067265,
            "eval_sadness_recall": 0.7839195979899497,
            "eval_anger_f1": 0.5882352941176471,
            "eval_anger_precision": 0.5392156862745098,
            "eval_anger_recall": 0.6470588235294118,
            "eval_surprise_f1": 0.33939393939393936,
            "eval_surprise_precision": 0.28865979381443296,
            "eval_surprise_recall": 0.4117647058823529,
            "eval_disgust_f1": 0.09999999999999999,
            "eval_disgust_precision": 0.1111111111111111,
            "eval_disgust_recall": 0.09090909090909091,
            "eval_fear_f1": 0.36666666666666675,
            "eval_fear_precision": 0.2619047619047619,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6654740608228981,
            "eval_macro_f1": 0.5047997832298279,
            "eval_macro_precision": 0.47808948159217834,
            "eval_macro_recall": 0.5588074326515198,
            "eval_acc": 0.6654740608228981,
            "eval_runtime": 4.4059,
            "eval_samples_per_second": 380.623,
            "eval_steps_per_second": 23.831,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1490435600280762,
            "eval_others_f1": 0.7418278852568378,
            "eval_others_precision": 0.8273809523809523,
            "eval_others_recall": 0.6723095525997581,
            "eval_joy_f1": 0.6683738796414853,
            "eval_joy_precision": 0.6229116945107399,
            "eval_joy_recall": 0.7209944751381215,
            "eval_sadness_f1": 0.7465437788018432,
            "eval_sadness_precision": 0.6893617021276596,
            "eval_sadness_recall": 0.8140703517587939,
            "eval_anger_f1": 0.5543478260869564,
            "eval_anger_precision": 0.5151515151515151,
            "eval_anger_recall": 0.6,
            "eval_surprise_f1": 0.3726708074534162,
            "eval_surprise_precision": 0.3225806451612903,
            "eval_surprise_recall": 0.4411764705882353,
            "eval_disgust_f1": 0.06666666666666667,
            "eval_disgust_precision": 0.07407407407407407,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.43137254901960786,
            "eval_fear_precision": 0.3333333333333333,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6702444841979726,
            "eval_macro_f1": 0.5116862058639526,
            "eval_macro_precision": 0.48354196548461914,
            "eval_macro_recall": 0.5600382685661316,
            "eval_acc": 0.6702444841979726,
            "eval_runtime": 4.4063,
            "eval_samples_per_second": 380.594,
            "eval_steps_per_second": 23.83,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1431422233581543,
            "eval_others_f1": 0.7313915857605178,
            "eval_others_precision": 0.786908077994429,
            "eval_others_recall": 0.6831922611850061,
            "eval_joy_f1": 0.664886515353805,
            "eval_joy_precision": 0.6434108527131783,
            "eval_joy_recall": 0.6878453038674033,
            "eval_sadness_f1": 0.7500000000000001,
            "eval_sadness_precision": 0.7188940092165899,
            "eval_sadness_recall": 0.7839195979899497,
            "eval_anger_f1": 0.5706521739130435,
            "eval_anger_precision": 0.5303030303030303,
            "eval_anger_recall": 0.6176470588235294,
            "eval_surprise_f1": 0.37762237762237755,
            "eval_surprise_precision": 0.36,
            "eval_surprise_recall": 0.39705882352941174,
            "eval_disgust_f1": 0.13513513513513514,
            "eval_disgust_precision": 0.12195121951219512,
            "eval_disgust_recall": 0.15151515151515152,
            "eval_fear_f1": 0.37288135593220345,
            "eval_fear_precision": 0.2682926829268293,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6666666666666666,
            "eval_macro_f1": 0.5146527886390686,
            "eval_macro_precision": 0.48996567726135254,
            "eval_macro_recall": 0.5617555975914001,
            "eval_acc": 0.6666666666666666,
            "eval_runtime": 4.5284,
            "eval_samples_per_second": 370.33,
            "eval_steps_per_second": 23.187,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2353227138519287,
            "eval_others_f1": 0.7467700258397933,
            "eval_others_precision": 0.8016643550624133,
            "eval_others_recall": 0.6989117291414753,
            "eval_joy_f1": 0.6657789613848203,
            "eval_joy_precision": 0.6426735218508998,
            "eval_joy_recall": 0.6906077348066298,
            "eval_sadness_f1": 0.7500000000000001,
            "eval_sadness_precision": 0.7188940092165899,
            "eval_sadness_recall": 0.7839195979899497,
            "eval_anger_f1": 0.578125,
            "eval_anger_precision": 0.5186915887850467,
            "eval_anger_recall": 0.6529411764705882,
            "eval_surprise_f1": 0.3576158940397351,
            "eval_surprise_precision": 0.3253012048192771,
            "eval_surprise_recall": 0.39705882352941174,
            "eval_disgust_f1": 0.04081632653061225,
            "eval_disgust_precision": 0.0625,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.4363636363636364,
            "eval_fear_precision": 0.32432432432432434,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6768038163387,
            "eval_macro_f1": 0.5107814073562622,
            "eval_macro_precision": 0.48486414551734924,
            "eval_macro_recall": 0.5600584149360657,
            "eval_acc": 0.6768038163387,
            "eval_runtime": 4.4932,
            "eval_samples_per_second": 373.227,
            "eval_steps_per_second": 23.368,
            "epoch": 5.0
        }
    ],
    "model_name": "models/checkpoint-100000/"
}