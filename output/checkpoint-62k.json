{
    "context_hate": [
        {
            "eval_loss": 0.08760042488574982,
            "eval_calls_f1": 0.5901639344262295,
            "eval_women_f1": 0.393939393939394,
            "eval_lgbti_f1": 0.42077922077922075,
            "eval_racism_f1": 0.6156462585034013,
            "eval_class_f1": 0.41887905604719766,
            "eval_politics_f1": 0.5766312594840668,
            "eval_disabled_f1": 0.437125748502994,
            "eval_appearance_f1": 0.6636259977194983,
            "eval_criminal_f1": 0.5911330049261083,
            "eval_mean_f1": 0.5231027007102966,
            "eval_mean_precision": 0.465586394071579,
            "eval_mean_recall": 0.6015394926071167,
            "eval_hate_precision": 0.6037735849056604,
            "eval_hate_recall": 0.7122982749026154,
            "eval_hate_f1": 0.6535613990298698,
            "eval_runtime": 33.5533,
            "eval_samples_per_second": 338.059,
            "eval_steps_per_second": 21.131
        },
        {
            "eval_loss": 0.08396408706903458,
            "eval_calls_f1": 0.6166134185303516,
            "eval_women_f1": 0.39092495636998253,
            "eval_lgbti_f1": 0.45604395604395603,
            "eval_racism_f1": 0.6177474402730375,
            "eval_class_f1": 0.43624161073825496,
            "eval_politics_f1": 0.5539452495974236,
            "eval_disabled_f1": 0.478688524590164,
            "eval_appearance_f1": 0.65695067264574,
            "eval_criminal_f1": 0.5765765765765766,
            "eval_mean_f1": 0.5315258502960205,
            "eval_mean_precision": 0.49336257576942444,
            "eval_mean_recall": 0.5830540060997009,
            "eval_hate_precision": 0.6107317073170732,
            "eval_hate_recall": 0.6967167501391207,
            "eval_hate_f1": 0.6508968027034052,
            "eval_runtime": 32.9631,
            "eval_samples_per_second": 344.112,
            "eval_steps_per_second": 21.509
        },
        {
            "eval_loss": 0.09828827530145645,
            "eval_calls_f1": 0.5277777777777777,
            "eval_women_f1": 0.339622641509434,
            "eval_lgbti_f1": 0.4297520661157025,
            "eval_racism_f1": 0.5821011673151751,
            "eval_class_f1": 0.3960396039603961,
            "eval_politics_f1": 0.5486725663716815,
            "eval_disabled_f1": 0.30666666666666664,
            "eval_appearance_f1": 0.5963855421686747,
            "eval_criminal_f1": 0.5523590333716917,
            "eval_mean_f1": 0.4754863381385803,
            "eval_mean_precision": 0.38731008768081665,
            "eval_mean_recall": 0.6250038743019104,
            "eval_hate_precision": 0.5213641709133673,
            "eval_hate_recall": 0.7401224262659989,
            "eval_hate_f1": 0.6117755289788408,
            "eval_runtime": 32.5738,
            "eval_samples_per_second": 348.225,
            "eval_steps_per_second": 21.766
        },
        {
            "eval_loss": 0.07772325724363327,
            "eval_calls_f1": 0.6118421052631579,
            "eval_women_f1": 0.3963963963963964,
            "eval_lgbti_f1": 0.41775456919060044,
            "eval_racism_f1": 0.6293333333333333,
            "eval_class_f1": 0.43086816720257237,
            "eval_politics_f1": 0.5795053003533568,
            "eval_disabled_f1": 0.43478260869565216,
            "eval_appearance_f1": 0.6818181818181818,
            "eval_criminal_f1": 0.5830164765525983,
            "eval_mean_f1": 0.5294796824455261,
            "eval_mean_precision": 0.49479490518569946,
            "eval_mean_recall": 0.5756637454032898,
            "eval_hate_precision": 0.6333671399594321,
            "eval_hate_recall": 0.6950473010573177,
            "eval_hate_f1": 0.6627752719554258,
            "eval_runtime": 32.6582,
            "eval_samples_per_second": 347.325,
            "eval_steps_per_second": 21.71
        },
        {
            "eval_loss": 0.08387728035449982,
            "eval_calls_f1": 0.5974842767295597,
            "eval_women_f1": 0.3907637655417407,
            "eval_lgbti_f1": 0.4741144414168938,
            "eval_racism_f1": 0.6167247386759581,
            "eval_class_f1": 0.41250000000000003,
            "eval_politics_f1": 0.5806451612903226,
            "eval_disabled_f1": 0.45222929936305734,
            "eval_appearance_f1": 0.6432374866879659,
            "eval_criminal_f1": 0.5825747724317296,
            "eval_mean_f1": 0.5278082489967346,
            "eval_mean_precision": 0.4850626587867737,
            "eval_mean_recall": 0.5862078070640564,
            "eval_hate_precision": 0.6120481927710844,
            "eval_hate_recall": 0.7067334446299388,
            "eval_hate_f1": 0.6559917355371901,
            "eval_runtime": 33.5835,
            "eval_samples_per_second": 337.755,
            "eval_steps_per_second": 21.112
        }
    ],
    "hate": [
        {
            "eval_loss": 0.7449011206626892,
            "eval_ok_f1": 0.7915234822451317,
            "eval_ok_precision": 0.8573200992555832,
            "eval_ok_recall": 0.7351063829787234,
            "eval_hateful_f1": 0.749656121045392,
            "eval_hateful_precision": 0.6863979848866498,
            "eval_hateful_recall": 0.8257575757575758,
            "eval_micro_f1": 0.7725000000000001,
            "eval_macro_f1": 0.7705898284912109,
            "eval_macro_precision": 0.7718590497970581,
            "eval_macro_recall": 0.7804319858551025,
            "eval_acc": 0.7725,
            "eval_runtime": 3.4265,
            "eval_samples_per_second": 466.955,
            "eval_steps_per_second": 29.185,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7295318841934204,
            "eval_ok_f1": 0.7718880285884455,
            "eval_ok_precision": 0.8768606224627875,
            "eval_ok_recall": 0.6893617021276596,
            "eval_hateful_f1": 0.7481919789612098,
            "eval_hateful_precision": 0.6608594657375145,
            "eval_hateful_recall": 0.8621212121212121,
            "eval_micro_f1": 0.760625,
            "eval_macro_f1": 0.7600399851799011,
            "eval_macro_precision": 0.7688600420951843,
            "eval_macro_recall": 0.775741457939148,
            "eval_acc": 0.760625,
            "eval_runtime": 3.2744,
            "eval_samples_per_second": 488.634,
            "eval_steps_per_second": 30.54,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7170515656471252,
            "eval_ok_f1": 0.8152233866519581,
            "eval_ok_precision": 0.8465063001145475,
            "eval_ok_recall": 0.7861702127659574,
            "eval_hateful_f1": 0.7584715212689258,
            "eval_hateful_precision": 0.7235213204951857,
            "eval_hateful_recall": 0.796969696969697,
            "eval_micro_f1": 0.790625,
            "eval_macro_f1": 0.7868474721908569,
            "eval_macro_precision": 0.7850137948989868,
            "eval_macro_recall": 0.7915699481964111,
            "eval_acc": 0.790625,
            "eval_runtime": 3.4055,
            "eval_samples_per_second": 469.824,
            "eval_steps_per_second": 29.364,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.752825140953064,
            "eval_ok_f1": 0.8004471771939632,
            "eval_ok_precision": 0.8433451118963486,
            "eval_ok_recall": 0.7617021276595745,
            "eval_hateful_f1": 0.7469879518072289,
            "eval_hateful_precision": 0.7017310252996005,
            "eval_hateful_recall": 0.7984848484848485,
            "eval_micro_f1": 0.776875,
            "eval_macro_f1": 0.7737175226211548,
            "eval_macro_precision": 0.7725380659103394,
            "eval_macro_recall": 0.7800934910774231,
            "eval_acc": 0.776875,
            "eval_runtime": 3.4998,
            "eval_samples_per_second": 457.167,
            "eval_steps_per_second": 28.573,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.6942285299301147,
            "eval_ok_f1": 0.7801169590643275,
            "eval_ok_precision": 0.8662337662337662,
            "eval_ok_recall": 0.7095744680851064,
            "eval_hateful_f1": 0.7476510067114094,
            "eval_hateful_precision": 0.6710843373493975,
            "eval_hateful_recall": 0.843939393939394,
            "eval_micro_f1": 0.765,
            "eval_macro_f1": 0.7638839483261108,
            "eval_macro_precision": 0.7686590552330017,
            "eval_macro_recall": 0.7767569422721863,
            "eval_acc": 0.765,
            "eval_runtime": 3.533,
            "eval_samples_per_second": 452.875,
            "eval_steps_per_second": 28.305,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 0.8597620725631714,
            "eval_neg_f1": 0.7485955056179774,
            "eval_neg_precision": 0.773304316285818,
            "eval_neg_recall": 0.7254168084382443,
            "eval_neu_f1": 0.5326213141397724,
            "eval_neu_precision": 0.4899615548910722,
            "eval_neu_recall": 0.5834181078331638,
            "eval_pos_f1": 0.7434254143646409,
            "eval_pos_precision": 0.7765466297322253,
            "eval_pos_recall": 0.7130139889783806,
            "eval_micro_f1": 0.6829570484581498,
            "eval_macro_f1": 0.6748807430267334,
            "eval_macro_precision": 0.6799375414848328,
            "eval_macro_recall": 0.673949658870697,
            "eval_acc": 0.6829570484581498,
            "eval_runtime": 10.7104,
            "eval_samples_per_second": 678.22,
            "eval_steps_per_second": 42.389,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0561126470565796,
            "eval_neg_f1": 0.7417923691215617,
            "eval_neg_precision": 0.7752225519287834,
            "eval_neg_recall": 0.7111262334127254,
            "eval_neu_f1": 0.5292761641309359,
            "eval_neu_precision": 0.4839797639123103,
            "eval_neu_recall": 0.5839267548321465,
            "eval_pos_f1": 0.7437980241492865,
            "eval_pos_precision": 0.7714025500910747,
            "eval_pos_recall": 0.7181008902077152,
            "eval_micro_f1": 0.6789647577092511,
            "eval_macro_f1": 0.6716222167015076,
            "eval_macro_precision": 0.6768682599067688,
            "eval_macro_recall": 0.6710513234138489,
            "eval_acc": 0.6789647577092511,
            "eval_runtime": 9.6434,
            "eval_samples_per_second": 753.265,
            "eval_steps_per_second": 47.079,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7539953589439392,
            "eval_neg_f1": 0.7402358142962417,
            "eval_neg_precision": 0.8071514664523906,
            "eval_neg_recall": 0.6835658387206532,
            "eval_neu_f1": 0.5510862551086255,
            "eval_neu_precision": 0.4774506149832277,
            "eval_neu_recall": 0.6515768056968464,
            "eval_pos_f1": 0.73781172770164,
            "eval_pos_precision": 0.7848948374760994,
            "eval_pos_recall": 0.6960576515472658,
            "eval_micro_f1": 0.6789647577092511,
            "eval_macro_f1": 0.6763779520988464,
            "eval_macro_precision": 0.6898322701454163,
            "eval_macro_recall": 0.6770668029785156,
            "eval_acc": 0.6789647577092511,
            "eval_runtime": 10.0905,
            "eval_samples_per_second": 719.888,
            "eval_steps_per_second": 44.993,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8546912670135498,
            "eval_neg_f1": 0.7531380753138075,
            "eval_neg_precision": 0.7722559885591705,
            "eval_neg_recall": 0.7349438584552569,
            "eval_neu_f1": 0.5412762159750111,
            "eval_neu_precision": 0.48211446740858505,
            "eval_neu_recall": 0.6169888097660223,
            "eval_pos_f1": 0.7354988399071927,
            "eval_pos_precision": 0.8124038954382368,
            "eval_pos_recall": 0.6718948707079271,
            "eval_micro_f1": 0.6825440528634361,
            "eval_macro_f1": 0.6766377091407776,
            "eval_macro_precision": 0.6889247894287109,
            "eval_macro_recall": 0.6746091842651367,
            "eval_acc": 0.6825440528634361,
            "eval_runtime": 9.6474,
            "eval_samples_per_second": 752.95,
            "eval_steps_per_second": 47.059,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0671749114990234,
            "eval_neg_f1": 0.7438981252210825,
            "eval_neg_precision": 0.7745856353591161,
            "eval_neg_recall": 0.7155495066349098,
            "eval_neu_f1": 0.5289217954650625,
            "eval_neu_precision": 0.48514431239388794,
            "eval_neu_recall": 0.5813835198372329,
            "eval_pos_f1": 0.7398945518453428,
            "eval_pos_precision": 0.7678978568171455,
            "eval_pos_recall": 0.7138618058499364,
            "eval_micro_f1": 0.6786894273127754,
            "eval_macro_f1": 0.6709048748016357,
            "eval_macro_precision": 0.6758759617805481,
            "eval_macro_recall": 0.6702649593353271,
            "eval_acc": 0.6786894273127754,
            "eval_runtime": 10.3441,
            "eval_samples_per_second": 702.236,
            "eval_steps_per_second": 43.89,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.1782643795013428,
            "eval_others_f1": 0.7318982387475538,
            "eval_others_precision": 0.7946175637393768,
            "eval_others_recall": 0.6783555018137848,
            "eval_joy_f1": 0.6541049798115748,
            "eval_joy_precision": 0.6377952755905512,
            "eval_joy_recall": 0.6712707182320442,
            "eval_sadness_f1": 0.7599067599067599,
            "eval_sadness_precision": 0.7086956521739131,
            "eval_sadness_recall": 0.8190954773869347,
            "eval_anger_f1": 0.5068119891008175,
            "eval_anger_precision": 0.4720812182741117,
            "eval_anger_recall": 0.5470588235294118,
            "eval_surprise_f1": 0.34210526315789475,
            "eval_surprise_precision": 0.30952380952380953,
            "eval_surprise_recall": 0.38235294117647056,
            "eval_disgust_f1": 0.16666666666666669,
            "eval_disgust_precision": 0.15384615384615385,
            "eval_disgust_recall": 0.18181818181818182,
            "eval_fear_f1": 0.3793103448275862,
            "eval_fear_precision": 0.275,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6577221228384019,
            "eval_macro_f1": 0.5058292150497437,
            "eval_macro_precision": 0.47879424691200256,
            "eval_macro_recall": 0.5558661222457886,
            "eval_acc": 0.6577221228384019,
            "eval_runtime": 4.392,
            "eval_samples_per_second": 381.834,
            "eval_steps_per_second": 23.907,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1860096454620361,
            "eval_others_f1": 0.7312541473125413,
            "eval_others_precision": 0.8102941176470588,
            "eval_others_recall": 0.6662636033857315,
            "eval_joy_f1": 0.6824146981627297,
            "eval_joy_precision": 0.65,
            "eval_joy_recall": 0.7182320441988951,
            "eval_sadness_f1": 0.7428571428571429,
            "eval_sadness_precision": 0.7058823529411765,
            "eval_sadness_recall": 0.7839195979899497,
            "eval_anger_f1": 0.5662337662337662,
            "eval_anger_precision": 0.5069767441860465,
            "eval_anger_recall": 0.6411764705882353,
            "eval_surprise_f1": 0.35802469135802467,
            "eval_surprise_precision": 0.30851063829787234,
            "eval_surprise_recall": 0.4264705882352941,
            "eval_disgust_f1": 0.1379310344827586,
            "eval_disgust_precision": 0.16,
            "eval_disgust_recall": 0.12121212121212122,
            "eval_fear_f1": 0.4,
            "eval_fear_precision": 0.2857142857142857,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6684555754323196,
            "eval_macro_f1": 0.5169593095779419,
            "eval_macro_precision": 0.4896254539489746,
            "eval_macro_recall": 0.5748487114906311,
            "eval_acc": 0.6684555754323196,
            "eval_runtime": 4.399,
            "eval_samples_per_second": 381.222,
            "eval_steps_per_second": 23.869,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.188999056816101,
            "eval_others_f1": 0.7332002661343978,
            "eval_others_precision": 0.8150887573964497,
            "eval_others_recall": 0.6662636033857315,
            "eval_joy_f1": 0.6692810457516339,
            "eval_joy_precision": 0.6352357320099256,
            "eval_joy_recall": 0.7071823204419889,
            "eval_sadness_f1": 0.7577937649880095,
            "eval_sadness_precision": 0.7247706422018348,
            "eval_sadness_recall": 0.7939698492462312,
            "eval_anger_f1": 0.5736842105263158,
            "eval_anger_precision": 0.5190476190476191,
            "eval_anger_recall": 0.6411764705882353,
            "eval_surprise_f1": 0.35928143712574856,
            "eval_surprise_precision": 0.30303030303030304,
            "eval_surprise_recall": 0.4411764705882353,
            "eval_disgust_f1": 0.15625,
            "eval_disgust_precision": 0.16129032258064516,
            "eval_disgust_recall": 0.15151515151515152,
            "eval_fear_f1": 0.44827586206896547,
            "eval_fear_precision": 0.325,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.669051878354204,
            "eval_macro_f1": 0.5282524228096008,
            "eval_macro_precision": 0.4976375997066498,
            "eval_macro_recall": 0.5890722870826721,
            "eval_acc": 0.669051878354204,
            "eval_runtime": 4.3978,
            "eval_samples_per_second": 381.327,
            "eval_steps_per_second": 23.876,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1681199073791504,
            "eval_others_f1": 0.7208672086720868,
            "eval_others_precision": 0.8197226502311248,
            "eval_others_recall": 0.6432889963724304,
            "eval_joy_f1": 0.672566371681416,
            "eval_joy_precision": 0.62004662004662,
            "eval_joy_recall": 0.7348066298342542,
            "eval_sadness_f1": 0.7535545023696681,
            "eval_sadness_precision": 0.7130044843049327,
            "eval_sadness_recall": 0.7989949748743719,
            "eval_anger_f1": 0.552112676056338,
            "eval_anger_precision": 0.5297297297297298,
            "eval_anger_recall": 0.5764705882352941,
            "eval_surprise_f1": 0.3777777777777777,
            "eval_surprise_precision": 0.30357142857142855,
            "eval_surprise_recall": 0.5,
            "eval_disgust_f1": 0.18918918918918917,
            "eval_disgust_precision": 0.17073170731707318,
            "eval_disgust_recall": 0.21212121212121213,
            "eval_fear_f1": 0.42857142857142855,
            "eval_fear_precision": 0.3157894736842105,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6607036374478235,
            "eval_macro_f1": 0.5278056263923645,
            "eval_macro_precision": 0.49608516693115234,
            "eval_macro_recall": 0.5903355479240417,
            "eval_acc": 0.6607036374478235,
            "eval_runtime": 4.4274,
            "eval_samples_per_second": 378.781,
            "eval_steps_per_second": 23.716,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0901495218276978,
            "eval_others_f1": 0.687142857142857,
            "eval_others_precision": 0.8394415357766143,
            "eval_others_recall": 0.5816203143893591,
            "eval_joy_f1": 0.6554621848739496,
            "eval_joy_precision": 0.5796178343949044,
            "eval_joy_recall": 0.7541436464088398,
            "eval_sadness_f1": 0.7656249999999999,
            "eval_sadness_precision": 0.7945945945945946,
            "eval_sadness_recall": 0.7386934673366834,
            "eval_anger_f1": 0.5912596401028278,
            "eval_anger_precision": 0.5251141552511416,
            "eval_anger_recall": 0.6764705882352942,
            "eval_surprise_f1": 0.3274336283185841,
            "eval_surprise_precision": 0.23417721518987342,
            "eval_surprise_recall": 0.5441176470588235,
            "eval_disgust_f1": 0.04444444444444444,
            "eval_disgust_precision": 0.08333333333333333,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.33766233766233766,
            "eval_fear_precision": 0.22033898305084745,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.6362552176505665,
            "eval_macro_f1": 0.4870043098926544,
            "eval_macro_precision": 0.46808820962905884,
            "eval_macro_recall": 0.5782243609428406,
            "eval_acc": 0.6362552176505665,
            "eval_runtime": 4.5258,
            "eval_samples_per_second": 370.543,
            "eval_steps_per_second": 23.2,
            "epoch": 5.0
        }
    ],
    "model_name": "models/checkpoint-62000/"
}