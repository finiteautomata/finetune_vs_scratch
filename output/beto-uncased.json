{
    "context_hate": [
        {
            "eval_loss": 0.07892590016126633,
            "eval_calls_f1": 0.6690140845070423,
            "eval_women_f1": 0.420824295010846,
            "eval_lgbti_f1": 0.45833333333333337,
            "eval_racism_f1": 0.680161943319838,
            "eval_class_f1": 0.46366782006920415,
            "eval_politics_f1": 0.6360424028268552,
            "eval_disabled_f1": 0.5625,
            "eval_appearance_f1": 0.7358490566037735,
            "eval_criminal_f1": 0.6075949367088607,
            "eval_mean_f1": 0.5815541744232178,
            "eval_mean_precision": 0.6115909814834595,
            "eval_mean_recall": 0.5621008276939392,
            "eval_hate_precision": 0.7226006191950465,
            "eval_hate_recall": 0.6494156928213689,
            "eval_hate_f1": 0.6840562719812427,
            "eval_runtime": 34.7676,
            "eval_samples_per_second": 326.252,
            "eval_steps_per_second": 20.393
        },
        {
            "eval_loss": 0.07859750837087631,
            "eval_calls_f1": 0.6690518783542039,
            "eval_women_f1": 0.4094827586206897,
            "eval_lgbti_f1": 0.5059523809523809,
            "eval_racism_f1": 0.6963562753036437,
            "eval_class_f1": 0.5,
            "eval_politics_f1": 0.6203389830508474,
            "eval_disabled_f1": 0.5923076923076923,
            "eval_appearance_f1": 0.7375328083989502,
            "eval_criminal_f1": 0.6288343558282209,
            "eval_mean_f1": 0.5955396294593811,
            "eval_mean_precision": 0.6247296929359436,
            "eval_mean_recall": 0.5742078423500061,
            "eval_hate_precision": 0.7277710109622412,
            "eval_hate_recall": 0.6649972175848636,
            "eval_hate_f1": 0.6949694678685664,
            "eval_runtime": 36.0571,
            "eval_samples_per_second": 314.585,
            "eval_steps_per_second": 19.663
        },
        {
            "eval_loss": 0.07833527773618698,
            "eval_calls_f1": 0.6570397111913358,
            "eval_women_f1": 0.4034334763948498,
            "eval_lgbti_f1": 0.4795640326975477,
            "eval_racism_f1": 0.6852207293666027,
            "eval_class_f1": 0.4899328859060403,
            "eval_politics_f1": 0.620926243567753,
            "eval_disabled_f1": 0.5785714285714285,
            "eval_appearance_f1": 0.7493261455525607,
            "eval_criminal_f1": 0.6066066066066066,
            "eval_mean_f1": 0.5856245756149292,
            "eval_mean_precision": 0.5988237857818604,
            "eval_mean_recall": 0.5781340599060059,
            "eval_hate_precision": 0.6973004020677771,
            "eval_hate_recall": 0.6755703951029494,
            "eval_hate_f1": 0.686263425664217,
            "eval_runtime": 35.5457,
            "eval_samples_per_second": 319.11,
            "eval_steps_per_second": 19.946
        },
        {
            "eval_loss": 0.07711278647184372,
            "eval_calls_f1": 0.6702508960573477,
            "eval_women_f1": 0.4181459566074951,
            "eval_lgbti_f1": 0.5013054830287207,
            "eval_racism_f1": 0.696,
            "eval_class_f1": 0.5107913669064749,
            "eval_politics_f1": 0.6369863013698629,
            "eval_disabled_f1": 0.5928853754940712,
            "eval_appearance_f1": 0.7399741267787839,
            "eval_criminal_f1": 0.5978090766823162,
            "eval_mean_f1": 0.596016526222229,
            "eval_mean_precision": 0.6143434643745422,
            "eval_mean_recall": 0.5817411541938782,
            "eval_hate_precision": 0.7150442477876107,
            "eval_hate_recall": 0.674457429048414,
            "eval_hate_f1": 0.6941580756013745,
            "eval_runtime": 36.0154,
            "eval_samples_per_second": 314.949,
            "eval_steps_per_second": 19.686
        },
        {
            "eval_loss": 0.0787285789847374,
            "eval_calls_f1": 0.6571428571428573,
            "eval_women_f1": 0.39065817409766457,
            "eval_lgbti_f1": 0.504297994269341,
            "eval_racism_f1": 0.6846473029045643,
            "eval_class_f1": 0.5131578947368421,
            "eval_politics_f1": 0.6189683860232944,
            "eval_disabled_f1": 0.5642857142857143,
            "eval_appearance_f1": 0.7477124183006535,
            "eval_criminal_f1": 0.6198473282442748,
            "eval_mean_f1": 0.5889686942100525,
            "eval_mean_precision": 0.6056993007659912,
            "eval_mean_recall": 0.5784374475479126,
            "eval_hate_precision": 0.7210557888422315,
            "eval_hate_recall": 0.6688925987757374,
            "eval_hate_f1": 0.6939953810623557,
            "eval_runtime": 36.4055,
            "eval_samples_per_second": 311.574,
            "eval_steps_per_second": 19.475
        }
    ],
    "hate": [
        {
            "eval_loss": 1.2447525262832642,
            "eval_ok_f1": 0.7950727883538633,
            "eval_ok_precision": 0.8392434988179669,
            "eval_ok_recall": 0.7553191489361702,
            "eval_hateful_f1": 0.7411598302687412,
            "eval_hateful_precision": 0.6949602122015915,
            "eval_hateful_recall": 0.793939393939394,
            "eval_micro_f1": 0.77125,
            "eval_macro_f1": 0.7681163549423218,
            "eval_macro_precision": 0.7671018838882446,
            "eval_macro_recall": 0.7746292948722839,
            "eval_acc": 0.77125,
            "eval_runtime": 3.3524,
            "eval_samples_per_second": 477.271,
            "eval_steps_per_second": 29.829,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.6002271771430969,
            "eval_ok_f1": 0.7849223946784921,
            "eval_ok_precision": 0.8194444444444444,
            "eval_ok_recall": 0.7531914893617021,
            "eval_hateful_f1": 0.7220630372492837,
            "eval_hateful_precision": 0.6847826086956522,
            "eval_hateful_recall": 0.7636363636363637,
            "eval_micro_f1": 0.7575,
            "eval_macro_f1": 0.7534927129745483,
            "eval_macro_precision": 0.7521135210990906,
            "eval_macro_recall": 0.7584139108657837,
            "eval_acc": 0.7575,
            "eval_runtime": 3.3861,
            "eval_samples_per_second": 472.526,
            "eval_steps_per_second": 29.533,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2958065271377563,
            "eval_ok_f1": 0.7389162561576355,
            "eval_ok_precision": 0.8771929824561403,
            "eval_ok_recall": 0.6382978723404256,
            "eval_hateful_f1": 0.7309644670050762,
            "eval_hateful_precision": 0.62882096069869,
            "eval_hateful_recall": 0.8727272727272727,
            "eval_micro_f1": 0.735,
            "eval_macro_f1": 0.7349404096603394,
            "eval_macro_precision": 0.7530069351196289,
            "eval_macro_recall": 0.7555125951766968,
            "eval_acc": 0.735,
            "eval_runtime": 3.477,
            "eval_samples_per_second": 460.172,
            "eval_steps_per_second": 28.761,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.279211163520813,
            "eval_ok_f1": 0.7824601366742597,
            "eval_ok_precision": 0.8419117647058824,
            "eval_ok_recall": 0.7308510638297873,
            "eval_hateful_f1": 0.7354570637119113,
            "eval_hateful_precision": 0.6772959183673469,
            "eval_hateful_recall": 0.8045454545454546,
            "eval_micro_f1": 0.76125,
            "eval_macro_f1": 0.7589585781097412,
            "eval_macro_precision": 0.7596038579940796,
            "eval_macro_recall": 0.7676982879638672,
            "eval_acc": 0.76125,
            "eval_runtime": 3.3665,
            "eval_samples_per_second": 475.277,
            "eval_steps_per_second": 29.705,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.6021965146064758,
            "eval_ok_f1": 0.7829591249280368,
            "eval_ok_precision": 0.8531994981179423,
            "eval_ok_recall": 0.723404255319149,
            "eval_hateful_f1": 0.7423103212576897,
            "eval_hateful_precision": 0.676214196762142,
            "eval_hateful_recall": 0.8227272727272728,
            "eval_micro_f1": 0.764375,
            "eval_macro_f1": 0.7626347541809082,
            "eval_macro_precision": 0.7647068500518799,
            "eval_macro_recall": 0.7730657458305359,
            "eval_acc": 0.764375,
            "eval_runtime": 3.3291,
            "eval_samples_per_second": 480.61,
            "eval_steps_per_second": 30.038,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 1.5789265632629395,
            "eval_neg_f1": 0.718335127377108,
            "eval_neg_precision": 0.7597722960151803,
            "eval_neg_recall": 0.6811840762164001,
            "eval_neu_f1": 0.5224655678482728,
            "eval_neu_precision": 0.4697523345513601,
            "eval_neu_recall": 0.5885045778229908,
            "eval_pos_f1": 0.7213259668508287,
            "eval_pos_precision": 0.7534626038781164,
            "eval_pos_recall": 0.6918185671894871,
            "eval_micro_f1": 0.6595539647577092,
            "eval_macro_f1": 0.6540422439575195,
            "eval_macro_precision": 0.6609957218170166,
            "eval_macro_recall": 0.6538357138633728,
            "eval_acc": 0.6595539647577092,
            "eval_runtime": 10.1231,
            "eval_samples_per_second": 717.568,
            "eval_steps_per_second": 44.848,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0677376985549927,
            "eval_neg_f1": 0.7167235494880546,
            "eval_neg_precision": 0.7591324200913242,
            "eval_neg_recall": 0.6788023137121469,
            "eval_neu_f1": 0.5246166263115415,
            "eval_neu_precision": 0.43478260869565216,
            "eval_neu_recall": 0.6612410986775178,
            "eval_pos_f1": 0.6766541822721598,
            "eval_pos_precision": 0.8232077764277035,
            "eval_pos_recall": 0.5743959304790165,
            "eval_micro_f1": 0.6401431718061674,
            "eval_macro_f1": 0.6393314003944397,
            "eval_macro_precision": 0.6723742485046387,
            "eval_macro_recall": 0.6381464600563049,
            "eval_acc": 0.6401431718061674,
            "eval_runtime": 10.3523,
            "eval_samples_per_second": 701.682,
            "eval_steps_per_second": 43.855,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.5394779443740845,
            "eval_neg_f1": 0.7117840204304998,
            "eval_neg_precision": 0.7672040896578843,
            "eval_neg_recall": 0.6638312351139843,
            "eval_neu_f1": 0.5148558758314855,
            "eval_neu_precision": 0.4563679245283019,
            "eval_neu_recall": 0.5905391658189216,
            "eval_pos_f1": 0.712962962962963,
            "eval_pos_precision": 0.7427652733118971,
            "eval_pos_recall": 0.685459940652819,
            "eval_micro_f1": 0.6510187224669604,
            "eval_macro_f1": 0.646534264087677,
            "eval_macro_precision": 0.6554457545280457,
            "eval_macro_recall": 0.6466100811958313,
            "eval_acc": 0.6510187224669604,
            "eval_runtime": 10.4229,
            "eval_samples_per_second": 696.928,
            "eval_steps_per_second": 43.558,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.577185869216919,
            "eval_neg_f1": 0.7240092411586992,
            "eval_neg_precision": 0.7578125,
            "eval_neg_recall": 0.6930928887376658,
            "eval_neu_f1": 0.5201334816462737,
            "eval_neu_precision": 0.46223803875049424,
            "eval_neu_recall": 0.5946083418107834,
            "eval_pos_f1": 0.7099409895596914,
            "eval_pos_precision": 0.7640449438202247,
            "eval_pos_recall": 0.6629927935565918,
            "eval_micro_f1": 0.6566629955947136,
            "eval_macro_f1": 0.6513612270355225,
            "eval_macro_precision": 0.6613652110099792,
            "eval_macro_recall": 0.6502313613891602,
            "eval_acc": 0.6566629955947136,
            "eval_runtime": 10.2113,
            "eval_samples_per_second": 711.366,
            "eval_steps_per_second": 44.46,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.6430978775024414,
            "eval_neg_f1": 0.7203420021375133,
            "eval_neg_precision": 0.7558878504672897,
            "eval_neg_recall": 0.6879891119428377,
            "eval_neu_f1": 0.521777581251382,
            "eval_neu_precision": 0.46147829487680875,
            "eval_neu_recall": 0.6002034587995931,
            "eval_pos_f1": 0.7105442951491687,
            "eval_pos_precision": 0.7677165354330708,
            "eval_pos_recall": 0.6612971598134803,
            "eval_micro_f1": 0.6555616740088106,
            "eval_macro_f1": 0.6508879661560059,
            "eval_macro_precision": 0.6616942286491394,
            "eval_macro_recall": 0.6498298645019531,
            "eval_acc": 0.6555616740088106,
            "eval_runtime": 10.7109,
            "eval_samples_per_second": 678.189,
            "eval_steps_per_second": 42.387,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.6623750925064087,
            "eval_others_f1": 0.7512755102040817,
            "eval_others_precision": 0.7948717948717948,
            "eval_others_recall": 0.7122128174123338,
            "eval_joy_f1": 0.6658385093167701,
            "eval_joy_precision": 0.6049661399548533,
            "eval_joy_recall": 0.7403314917127072,
            "eval_sadness_f1": 0.7389162561576355,
            "eval_sadness_precision": 0.7246376811594203,
            "eval_sadness_recall": 0.7537688442211056,
            "eval_anger_f1": 0.6243093922651933,
            "eval_anger_precision": 0.5885416666666666,
            "eval_anger_recall": 0.6647058823529411,
            "eval_surprise_f1": 0.3728813559322034,
            "eval_surprise_precision": 0.44,
            "eval_surprise_recall": 0.3235294117647059,
            "eval_disgust_f1": 0.09090909090909091,
            "eval_disgust_precision": 0.18181818181818182,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.4705882352941177,
            "eval_fear_precision": 0.36363636363636365,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6893261776982708,
            "eval_macro_f1": 0.5306740999221802,
            "eval_macro_precision": 0.5283531546592712,
            "eval_macro_recall": 0.5602601766586304,
            "eval_acc": 0.6893261776982708,
            "eval_runtime": 3.519,
            "eval_samples_per_second": 476.552,
            "eval_steps_per_second": 29.838,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.5375173091888428,
            "eval_others_f1": 0.7626903553299492,
            "eval_others_precision": 0.8024032042723631,
            "eval_others_recall": 0.7267230955259976,
            "eval_joy_f1": 0.678720445062587,
            "eval_joy_precision": 0.6834733893557423,
            "eval_joy_recall": 0.6740331491712708,
            "eval_sadness_f1": 0.7102803738317757,
            "eval_sadness_precision": 0.6637554585152838,
            "eval_sadness_recall": 0.7638190954773869,
            "eval_anger_f1": 0.5563549160671463,
            "eval_anger_precision": 0.46963562753036436,
            "eval_anger_recall": 0.6823529411764706,
            "eval_surprise_f1": 0.31034482758620696,
            "eval_surprise_precision": 0.375,
            "eval_surprise_recall": 0.2647058823529412,
            "eval_disgust_f1": 0.07692307692307693,
            "eval_disgust_precision": 0.10526315789473684,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.5217391304347826,
            "eval_fear_precision": 0.42857142857142855,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6827668455575432,
            "eval_macro_f1": 0.5167219042778015,
            "eval_macro_precision": 0.5040146112442017,
            "eval_macro_recall": 0.5484153032302856,
            "eval_acc": 0.6827668455575432,
            "eval_runtime": 3.8949,
            "eval_samples_per_second": 430.562,
            "eval_steps_per_second": 26.958,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.474609136581421,
            "eval_others_f1": 0.7113821138211381,
            "eval_others_precision": 0.8089368258859785,
            "eval_others_recall": 0.6348246674727932,
            "eval_joy_f1": 0.6398158803222095,
            "eval_joy_precision": 0.5483234714003945,
            "eval_joy_recall": 0.7679558011049724,
            "eval_sadness_f1": 0.7202072538860105,
            "eval_sadness_precision": 0.7433155080213903,
            "eval_sadness_recall": 0.6984924623115578,
            "eval_anger_f1": 0.5303030303030303,
            "eval_anger_precision": 0.4646017699115044,
            "eval_anger_recall": 0.6176470588235294,
            "eval_surprise_f1": 0.34710743801652894,
            "eval_surprise_precision": 0.39622641509433965,
            "eval_surprise_recall": 0.3088235294117647,
            "eval_disgust_f1": 0.12903225806451615,
            "eval_disgust_precision": 0.13793103448275862,
            "eval_disgust_recall": 0.12121212121212122,
            "eval_fear_f1": 0.5454545454545455,
            "eval_fear_precision": 0.46153846153846156,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6463923673225999,
            "eval_macro_f1": 0.5176146626472473,
            "eval_macro_precision": 0.5086961984634399,
            "eval_macro_recall": 0.5450888872146606,
            "eval_acc": 0.6463923673225999,
            "eval_runtime": 3.7605,
            "eval_samples_per_second": 445.95,
            "eval_steps_per_second": 27.922,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.627151370048523,
            "eval_others_f1": 0.7411167512690356,
            "eval_others_precision": 0.7797062750333779,
            "eval_others_recall": 0.7061668681983071,
            "eval_joy_f1": 0.645408163265306,
            "eval_joy_precision": 0.5995260663507109,
            "eval_joy_recall": 0.6988950276243094,
            "eval_sadness_f1": 0.7268292682926829,
            "eval_sadness_precision": 0.7061611374407583,
            "eval_sadness_recall": 0.7487437185929648,
            "eval_anger_f1": 0.5907859078590787,
            "eval_anger_precision": 0.5477386934673367,
            "eval_anger_recall": 0.6411764705882353,
            "eval_surprise_f1": 0.3149606299212598,
            "eval_surprise_precision": 0.3389830508474576,
            "eval_surprise_recall": 0.29411764705882354,
            "eval_disgust_f1": 0.09090909090909091,
            "eval_disgust_precision": 0.18181818181818182,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.5454545454545455,
            "eval_fear_precision": 0.46153846153846156,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6732259988073942,
            "eval_macro_f1": 0.5222092270851135,
            "eval_macro_precision": 0.5164960026741028,
            "eval_macro_recall": 0.5451961159706116,
            "eval_acc": 0.6732259988073942,
            "eval_runtime": 3.935,
            "eval_samples_per_second": 426.171,
            "eval_steps_per_second": 26.683,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.6676689386367798,
            "eval_others_f1": 0.7465667915106117,
            "eval_others_precision": 0.7716129032258064,
            "eval_others_recall": 0.7230955259975816,
            "eval_joy_f1": 0.6475195822454308,
            "eval_joy_precision": 0.6138613861386139,
            "eval_joy_recall": 0.6850828729281768,
            "eval_sadness_f1": 0.7437185929648241,
            "eval_sadness_precision": 0.7437185929648241,
            "eval_sadness_recall": 0.7437185929648241,
            "eval_anger_f1": 0.5882352941176471,
            "eval_anger_precision": 0.5203619909502263,
            "eval_anger_recall": 0.6764705882352942,
            "eval_surprise_f1": 0.33333333333333337,
            "eval_surprise_precision": 0.45,
            "eval_surprise_recall": 0.2647058823529412,
            "eval_disgust_f1": 0.0,
            "eval_disgust_precision": 0.0,
            "eval_disgust_recall": 0.0,
            "eval_fear_f1": 0.5217391304347826,
            "eval_fear_precision": 0.42857142857142855,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6791890280262374,
            "eval_macro_f1": 0.5115875601768494,
            "eval_macro_precision": 0.5040180087089539,
            "eval_macro_recall": 0.5371057391166687,
            "eval_acc": 0.6791890280262374,
            "eval_runtime": 3.9395,
            "eval_samples_per_second": 425.685,
            "eval_steps_per_second": 26.653,
            "epoch": 5.0
        }
    ],
    "model_name": "dccuchile/bert-base-spanish-wwm-uncased"
}