{
    "context_hate": [
        {
            "eval_loss": 0.08046090602874756,
            "eval_calls_f1": 0.6536412078152752,
            "eval_women_f1": 0.43186582809224316,
            "eval_lgbti_f1": 0.4682080924855492,
            "eval_racism_f1": 0.6570048309178743,
            "eval_class_f1": 0.4965986394557823,
            "eval_politics_f1": 0.5982905982905983,
            "eval_disabled_f1": 0.5324232081911262,
            "eval_appearance_f1": 0.7351778656126483,
            "eval_criminal_f1": 0.6149584487534627,
            "eval_mean_f1": 0.5764632225036621,
            "eval_mean_precision": 0.5826737880706787,
            "eval_mean_recall": 0.5762723684310913,
            "eval_hate_precision": 0.6817410966647823,
            "eval_hate_recall": 0.671118530884808,
            "eval_hate_f1": 0.6763881099270892,
            "eval_runtime": 41.663,
            "eval_samples_per_second": 272.256,
            "eval_steps_per_second": 17.018
        },
        {
            "eval_loss": 0.07898387312889099,
            "eval_calls_f1": 0.6443661971830986,
            "eval_women_f1": 0.451063829787234,
            "eval_lgbti_f1": 0.45373134328358206,
            "eval_racism_f1": 0.6727272727272728,
            "eval_class_f1": 0.437956204379562,
            "eval_politics_f1": 0.5913621262458473,
            "eval_disabled_f1": 0.508833922261484,
            "eval_appearance_f1": 0.714987714987715,
            "eval_criminal_f1": 0.6366120218579235,
            "eval_mean_f1": 0.5679600238800049,
            "eval_mean_precision": 0.5782063007354736,
            "eval_mean_recall": 0.5659571290016174,
            "eval_hate_precision": 0.6741953698475438,
            "eval_hate_recall": 0.664440734557596,
            "eval_hate_f1": 0.6692825112107623,
            "eval_runtime": 40.4777,
            "eval_samples_per_second": 280.228,
            "eval_steps_per_second": 17.516
        },
        {
            "eval_loss": 0.0821157693862915,
            "eval_calls_f1": 0.6509274873524452,
            "eval_women_f1": 0.4182194616977226,
            "eval_lgbti_f1": 0.4652406417112299,
            "eval_racism_f1": 0.6484375,
            "eval_class_f1": 0.4850498338870432,
            "eval_politics_f1": 0.6314049586776859,
            "eval_disabled_f1": 0.5423728813559322,
            "eval_appearance_f1": 0.7127003699136869,
            "eval_criminal_f1": 0.6446280991735538,
            "eval_mean_f1": 0.5776645541191101,
            "eval_mean_precision": 0.5655504465103149,
            "eval_mean_recall": 0.5950343012809753,
            "eval_hate_precision": 0.6664867781975176,
            "eval_hate_recall": 0.6872565386755703,
            "eval_hate_f1": 0.6767123287671233,
            "eval_runtime": 40.5757,
            "eval_samples_per_second": 279.552,
            "eval_steps_per_second": 17.474
        },
        {
            "eval_loss": 0.07533998042345047,
            "eval_calls_f1": 0.6491228070175439,
            "eval_women_f1": 0.45344129554655865,
            "eval_lgbti_f1": 0.46961325966850825,
            "eval_racism_f1": 0.6479690522243713,
            "eval_class_f1": 0.4641638225255973,
            "eval_politics_f1": 0.6267605633802817,
            "eval_disabled_f1": 0.5527272727272727,
            "eval_appearance_f1": 0.7148488830486203,
            "eval_criminal_f1": 0.6492434662998625,
            "eval_mean_f1": 0.5808767080307007,
            "eval_mean_precision": 0.5851872563362122,
            "eval_mean_recall": 0.5794651508331299,
            "eval_hate_precision": 0.6752747252747253,
            "eval_hate_recall": 0.6839176405119644,
            "eval_hate_f1": 0.6795687033453138,
            "eval_runtime": 40.5551,
            "eval_samples_per_second": 279.694,
            "eval_steps_per_second": 17.482
        },
        {
            "eval_loss": 0.08170833438634872,
            "eval_calls_f1": 0.6330434782608696,
            "eval_women_f1": 0.4435146443514644,
            "eval_lgbti_f1": 0.4734042553191489,
            "eval_racism_f1": 0.6626865671641791,
            "eval_class_f1": 0.4625850340136055,
            "eval_politics_f1": 0.6057529610829103,
            "eval_disabled_f1": 0.5614035087719298,
            "eval_appearance_f1": 0.7192755498059508,
            "eval_criminal_f1": 0.6226415094339622,
            "eval_mean_f1": 0.5760341286659241,
            "eval_mean_precision": 0.574034571647644,
            "eval_mean_recall": 0.5817045569419861,
            "eval_hate_precision": 0.6756302521008404,
            "eval_hate_recall": 0.671118530884808,
            "eval_hate_f1": 0.6733668341708543,
            "eval_runtime": 40.6364,
            "eval_samples_per_second": 279.134,
            "eval_steps_per_second": 17.447
        }
    ],
    "hate": [
        {
            "eval_loss": 1.1504418849945068,
            "eval_ok_f1": 0.8060538116591929,
            "eval_ok_precision": 0.8518957345971564,
            "eval_ok_recall": 0.7648936170212766,
            "eval_hateful_f1": 0.7556497175141242,
            "eval_hateful_precision": 0.7076719576719577,
            "eval_hateful_recall": 0.8106060606060606,
            "eval_micro_f1": 0.78375,
            "eval_macro_f1": 0.7808517813682556,
            "eval_macro_precision": 0.7797838449478149,
            "eval_macro_recall": 0.7877498269081116,
            "eval_acc": 0.78375,
            "eval_runtime": 3.7994,
            "eval_samples_per_second": 421.122,
            "eval_steps_per_second": 26.32,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1627006530761719,
            "eval_ok_f1": 0.8093340922026181,
            "eval_ok_precision": 0.8702570379436965,
            "eval_ok_recall": 0.7563829787234042,
            "eval_hateful_f1": 0.7678447678447679,
            "eval_hateful_precision": 0.7075351213282248,
            "eval_hateful_recall": 0.8393939393939394,
            "eval_micro_f1": 0.790625,
            "eval_macro_f1": 0.7885894775390625,
            "eval_macro_precision": 0.7888960838317871,
            "eval_macro_recall": 0.797888457775116,
            "eval_acc": 0.790625,
            "eval_runtime": 3.6096,
            "eval_samples_per_second": 443.267,
            "eval_steps_per_second": 27.704,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1309566497802734,
            "eval_ok_f1": 0.7930835734870317,
            "eval_ok_precision": 0.8654088050314466,
            "eval_ok_recall": 0.7319148936170212,
            "eval_hateful_f1": 0.7549488054607509,
            "eval_hateful_precision": 0.6869565217391305,
            "eval_hateful_recall": 0.8378787878787879,
            "eval_micro_f1": 0.775625,
            "eval_macro_f1": 0.7740161418914795,
            "eval_macro_precision": 0.7761826515197754,
            "eval_macro_recall": 0.7848968505859375,
            "eval_acc": 0.775625,
            "eval_runtime": 3.5018,
            "eval_samples_per_second": 456.905,
            "eval_steps_per_second": 28.557,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1256237030029297,
            "eval_ok_f1": 0.8041355542791498,
            "eval_ok_precision": 0.8739076154806492,
            "eval_ok_recall": 0.7446808510638298,
            "eval_hateful_f1": 0.766278272789582,
            "eval_hateful_precision": 0.6996245306633292,
            "eval_hateful_recall": 0.8469696969696969,
            "eval_micro_f1": 0.7868749999999999,
            "eval_macro_f1": 0.7852069139480591,
            "eval_macro_precision": 0.7867660522460938,
            "eval_macro_recall": 0.7958252429962158,
            "eval_acc": 0.786875,
            "eval_runtime": 3.5401,
            "eval_samples_per_second": 451.962,
            "eval_steps_per_second": 28.248,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2580630779266357,
            "eval_ok_f1": 0.7943760984182778,
            "eval_ok_precision": 0.8839634941329857,
            "eval_ok_recall": 0.7212765957446808,
            "eval_hateful_f1": 0.7649028801071668,
            "eval_hateful_precision": 0.6854741896758704,
            "eval_hateful_recall": 0.8651515151515151,
            "eval_micro_f1": 0.780625,
            "eval_macro_f1": 0.779639482498169,
            "eval_macro_precision": 0.7847188711166382,
            "eval_macro_recall": 0.7932140827178955,
            "eval_acc": 0.780625,
            "eval_runtime": 3.6104,
            "eval_samples_per_second": 443.161,
            "eval_steps_per_second": 27.698,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 0.7017053365707397,
            "eval_neg_f1": 0.7688294750570591,
            "eval_neg_precision": 0.7380281690140845,
            "eval_neg_recall": 0.8023137121469888,
            "eval_neu_f1": 0.5485,
            "eval_neu_precision": 0.539331366764995,
            "eval_neu_recall": 0.5579857578840285,
            "eval_pos_f1": 0.7455621301775147,
            "eval_pos_precision": 0.8049140049140049,
            "eval_pos_recall": 0.6943620178041543,
            "eval_micro_f1": 0.7011288546255506,
            "eval_macro_f1": 0.6876304745674133,
            "eval_macro_precision": 0.6940911412239075,
            "eval_macro_recall": 0.684887170791626,
            "eval_acc": 0.7011288546255506,
            "eval_runtime": 11.2297,
            "eval_samples_per_second": 646.857,
            "eval_steps_per_second": 40.429,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.3946715593338013,
            "eval_neg_f1": 0.7520572450805009,
            "eval_neg_precision": 0.7929083364768013,
            "eval_neg_recall": 0.715209254848588,
            "eval_neu_f1": 0.553020134228188,
            "eval_neu_precision": 0.4936102236421725,
            "eval_neu_recall": 0.6286876907426246,
            "eval_pos_f1": 0.7484333034914953,
            "eval_pos_precision": 0.7927927927927928,
            "eval_pos_recall": 0.708774904620602,
            "eval_micro_f1": 0.6897026431718062,
            "eval_macro_f1": 0.6845035552978516,
            "eval_macro_precision": 0.6931037902832031,
            "eval_macro_recall": 0.6842239499092102,
            "eval_acc": 0.6897026431718062,
            "eval_runtime": 10.8775,
            "eval_samples_per_second": 667.798,
            "eval_steps_per_second": 41.737,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7477219104766846,
            "eval_neg_f1": 0.763986013986014,
            "eval_neg_precision": 0.7856886012225818,
            "eval_neg_recall": 0.7434501531133039,
            "eval_neu_f1": 0.5580943121050073,
            "eval_neu_precision": 0.5344506517690876,
            "eval_neu_recall": 0.5839267548321465,
            "eval_pos_f1": 0.7686408180656158,
            "eval_pos_precision": 0.7725910064239828,
            "eval_pos_recall": 0.764730818143281,
            "eval_micro_f1": 0.7071861233480176,
            "eval_macro_f1": 0.6969070434570312,
            "eval_macro_precision": 0.6975767016410828,
            "eval_macro_recall": 0.6973692774772644,
            "eval_acc": 0.7071861233480177,
            "eval_runtime": 10.5703,
            "eval_samples_per_second": 687.208,
            "eval_steps_per_second": 42.95,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7651476860046387,
            "eval_neg_f1": 0.7720090293453725,
            "eval_neg_precision": 0.7336806619675146,
            "eval_neg_recall": 0.8145627764545764,
            "eval_neu_f1": 0.5402469135802469,
            "eval_neu_precision": 0.5249520153550864,
            "eval_neu_recall": 0.5564598168870803,
            "eval_pos_f1": 0.7362020579981291,
            "eval_pos_precision": 0.8210745957224831,
            "eval_pos_recall": 0.6672318779143704,
            "eval_micro_f1": 0.6968612334801763,
            "eval_macro_f1": 0.6828193068504333,
            "eval_macro_precision": 0.6932356953620911,
            "eval_macro_recall": 0.67941814661026,
            "eval_acc": 0.6968612334801763,
            "eval_runtime": 10.6454,
            "eval_samples_per_second": 682.357,
            "eval_steps_per_second": 42.647,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.961852490901947,
            "eval_neg_f1": 0.762780824341058,
            "eval_neg_precision": 0.7943994104642594,
            "eval_neg_recall": 0.7335828513099694,
            "eval_neu_f1": 0.5557265333040229,
            "eval_neu_precision": 0.4893534649632211,
            "eval_neu_recall": 0.6429298067141404,
            "eval_pos_f1": 0.7383263985205732,
            "eval_pos_precision": 0.8118962887646162,
            "eval_pos_recall": 0.6769817719372615,
            "eval_micro_f1": 0.6906662995594713,
            "eval_macro_f1": 0.6856112480163574,
            "eval_macro_precision": 0.698549747467041,
            "eval_macro_recall": 0.684498131275177,
            "eval_acc": 0.6906662995594713,
            "eval_runtime": 10.7606,
            "eval_samples_per_second": 675.056,
            "eval_steps_per_second": 42.191,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.510805606842041,
            "eval_others_f1": 0.7538265306122448,
            "eval_others_precision": 0.7975708502024291,
            "eval_others_recall": 0.7146311970979444,
            "eval_joy_f1": 0.6918075422626787,
            "eval_joy_precision": 0.6535626535626535,
            "eval_joy_recall": 0.7348066298342542,
            "eval_sadness_f1": 0.7714285714285714,
            "eval_sadness_precision": 0.7330316742081447,
            "eval_sadness_recall": 0.8140703517587939,
            "eval_anger_f1": 0.5799457994579946,
            "eval_anger_precision": 0.5376884422110553,
            "eval_anger_recall": 0.6294117647058823,
            "eval_surprise_f1": 0.4094488188976378,
            "eval_surprise_precision": 0.4406779661016949,
            "eval_surprise_recall": 0.38235294117647056,
            "eval_disgust_f1": 0.041666666666666664,
            "eval_disgust_precision": 0.06666666666666667,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.4528301886792453,
            "eval_fear_precision": 0.34285714285714286,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6946929039952295,
            "eval_macro_f1": 0.52870774269104,
            "eval_macro_precision": 0.5102936625480652,
            "eval_macro_recall": 0.567463219165802,
            "eval_acc": 0.6946929039952295,
            "eval_runtime": 4.8204,
            "eval_samples_per_second": 347.896,
            "eval_steps_per_second": 21.782,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.5024524927139282,
            "eval_others_f1": 0.7629629629629631,
            "eval_others_precision": 0.7793190416141236,
            "eval_others_recall": 0.747279322853688,
            "eval_joy_f1": 0.6983695652173914,
            "eval_joy_precision": 0.6871657754010695,
            "eval_joy_recall": 0.7099447513812155,
            "eval_sadness_f1": 0.7621359223300971,
            "eval_sadness_precision": 0.7370892018779343,
            "eval_sadness_recall": 0.7889447236180904,
            "eval_anger_f1": 0.572944297082228,
            "eval_anger_precision": 0.5217391304347826,
            "eval_anger_recall": 0.6352941176470588,
            "eval_surprise_f1": 0.34710743801652894,
            "eval_surprise_precision": 0.39622641509433965,
            "eval_surprise_recall": 0.3088235294117647,
            "eval_disgust_f1": 0.0,
            "eval_disgust_precision": 0.0,
            "eval_disgust_recall": 0.0,
            "eval_fear_f1": 0.4888888888888889,
            "eval_fear_precision": 0.4074074074074074,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6988670244484197,
            "eval_macro_f1": 0.518915593624115,
            "eval_macro_precision": 0.504135251045227,
            "eval_macro_recall": 0.5430567860603333,
            "eval_acc": 0.6988670244484197,
            "eval_runtime": 4.6918,
            "eval_samples_per_second": 357.43,
            "eval_steps_per_second": 22.379,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.575584053993225,
            "eval_others_f1": 0.76375,
            "eval_others_precision": 0.7904269081500647,
            "eval_others_recall": 0.7388149939540508,
            "eval_joy_f1": 0.7007874015748031,
            "eval_joy_precision": 0.6675,
            "eval_joy_recall": 0.7375690607734806,
            "eval_sadness_f1": 0.7476190476190476,
            "eval_sadness_precision": 0.7104072398190046,
            "eval_sadness_recall": 0.7889447236180904,
            "eval_anger_f1": 0.5626740947075208,
            "eval_anger_precision": 0.5343915343915344,
            "eval_anger_recall": 0.5941176470588235,
            "eval_surprise_f1": 0.3833333333333333,
            "eval_surprise_precision": 0.4423076923076923,
            "eval_surprise_recall": 0.3382352941176471,
            "eval_disgust_f1": 0.0,
            "eval_disgust_precision": 0.0,
            "eval_disgust_recall": 0.0,
            "eval_fear_f1": 0.4888888888888889,
            "eval_fear_precision": 0.4074074074074074,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6976744186046512,
            "eval_macro_f1": 0.5210075378417969,
            "eval_macro_precision": 0.5074915289878845,
            "eval_macro_recall": 0.544113278388977,
            "eval_acc": 0.6976744186046512,
            "eval_runtime": 5.0059,
            "eval_samples_per_second": 335.007,
            "eval_steps_per_second": 20.975,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.323079228401184,
            "eval_others_f1": 0.7459807073954985,
            "eval_others_precision": 0.7967032967032966,
            "eval_others_recall": 0.7013301088270859,
            "eval_joy_f1": 0.6884353741496598,
            "eval_joy_precision": 0.67828418230563,
            "eval_joy_recall": 0.6988950276243094,
            "eval_sadness_f1": 0.7402298850574712,
            "eval_sadness_precision": 0.6822033898305084,
            "eval_sadness_recall": 0.8090452261306532,
            "eval_anger_f1": 0.5310173697270472,
            "eval_anger_precision": 0.4592274678111588,
            "eval_anger_recall": 0.6294117647058823,
            "eval_surprise_f1": 0.3870967741935484,
            "eval_surprise_precision": 0.42857142857142855,
            "eval_surprise_recall": 0.35294117647058826,
            "eval_disgust_f1": 0.03773584905660378,
            "eval_disgust_precision": 0.05,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.4489795918367347,
            "eval_fear_precision": 0.3548387096774194,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6779964221824687,
            "eval_macro_f1": 0.511353611946106,
            "eval_macro_precision": 0.49283266067504883,
            "eval_macro_recall": 0.5475767850875854,
            "eval_acc": 0.6779964221824687,
            "eval_runtime": 4.8364,
            "eval_samples_per_second": 346.744,
            "eval_steps_per_second": 21.71,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.5660784244537354,
            "eval_others_f1": 0.7568253968253968,
            "eval_others_precision": 0.7967914438502673,
            "eval_others_recall": 0.720677146311971,
            "eval_joy_f1": 0.7024265644955299,
            "eval_joy_precision": 0.6532066508313539,
            "eval_joy_recall": 0.7596685082872928,
            "eval_sadness_f1": 0.7609756097560976,
            "eval_sadness_precision": 0.7393364928909952,
            "eval_sadness_recall": 0.7839195979899497,
            "eval_anger_f1": 0.5706521739130435,
            "eval_anger_precision": 0.5303030303030303,
            "eval_anger_recall": 0.6176470588235294,
            "eval_surprise_f1": 0.36220472440944884,
            "eval_surprise_precision": 0.3898305084745763,
            "eval_surprise_recall": 0.3382352941176471,
            "eval_disgust_f1": 0.0,
            "eval_disgust_precision": 0.0,
            "eval_disgust_recall": 0.0,
            "eval_fear_f1": 0.4489795918367347,
            "eval_fear_precision": 0.3548387096774194,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6952892069171139,
            "eval_macro_f1": 0.5145806074142456,
            "eval_macro_precision": 0.49490097165107727,
            "eval_macro_recall": 0.547322690486908,
            "eval_acc": 0.6952892069171139,
            "eval_runtime": 4.8285,
            "eval_samples_per_second": 347.31,
            "eval_steps_per_second": 21.746,
            "epoch": 5.0
        }
    ],
    "model_name": "models/beto-cased-20000/",
    "irony": [
        {
            "eval_loss": 0.4912949204444885,
            "eval_not ironic_f1": 0.8323746918652424,
            "eval_not ironic_precision": 0.8215733982157339,
            "eval_not ironic_recall": 0.8434637801831807,
            "eval_ironic_f1": 0.6500857632933106,
            "eval_ironic_precision": 0.6684303350970018,
            "eval_ironic_recall": 0.6327212020033389,
            "eval_micro_f1": 0.7733333333333333,
            "eval_macro_f1": 0.7412302494049072,
            "eval_macro_precision": 0.7450018525123596,
            "eval_macro_recall": 0.7380924820899963,
            "eval_acc": 0.7733333333333333,
            "eval_runtime": 4.3927,
            "eval_samples_per_second": 409.773,
            "eval_steps_per_second": 25.725,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2460943460464478,
            "eval_not ironic_f1": 0.8341194968553459,
            "eval_not ironic_precision": 0.7900223380491437,
            "eval_not ironic_recall": 0.8834304746044963,
            "eval_ironic_f1": 0.600378787878788,
            "eval_ironic_precision": 0.6936542669584245,
            "eval_ironic_recall": 0.5292153589315526,
            "eval_micro_f1": 0.7655555555555555,
            "eval_macro_f1": 0.7172491550445557,
            "eval_macro_precision": 0.741838276386261,
            "eval_macro_recall": 0.7063229084014893,
            "eval_acc": 0.7655555555555555,
            "eval_runtime": 4.3981,
            "eval_samples_per_second": 409.271,
            "eval_steps_per_second": 25.693,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7790044546127319,
            "eval_not ironic_f1": 0.831107619795758,
            "eval_not ironic_precision": 0.7866171003717473,
            "eval_not ironic_recall": 0.880932556203164,
            "eval_ironic_f1": 0.5920303605313093,
            "eval_ironic_precision": 0.6857142857142857,
            "eval_ironic_recall": 0.5208681135225376,
            "eval_micro_f1": 0.7611111111111111,
            "eval_macro_f1": 0.7115689516067505,
            "eval_macro_precision": 0.7361657023429871,
            "eval_macro_recall": 0.7009003162384033,
            "eval_acc": 0.7611111111111111,
            "eval_runtime": 4.4,
            "eval_samples_per_second": 409.094,
            "eval_steps_per_second": 25.682,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0863022804260254,
            "eval_not ironic_f1": 0.8295269168026101,
            "eval_not ironic_precision": 0.8129496402877698,
            "eval_not ironic_recall": 0.8467943380516236,
            "eval_ironic_f1": 0.6358885017421603,
            "eval_ironic_precision": 0.6648451730418944,
            "eval_ironic_recall": 0.6093489148580968,
            "eval_micro_f1": 0.7677777777777778,
            "eval_macro_f1": 0.7327077388763428,
            "eval_macro_precision": 0.738897442817688,
            "eval_macro_recall": 0.7280716300010681,
            "eval_acc": 0.7677777777777778,
            "eval_runtime": 4.4101,
            "eval_samples_per_second": 408.154,
            "eval_steps_per_second": 25.623,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.5006754398345947,
            "eval_not ironic_f1": 0.8208828522920204,
            "eval_not ironic_precision": 0.8372294372294372,
            "eval_not ironic_recall": 0.8051623646960866,
            "eval_ironic_f1": 0.6607717041800644,
            "eval_ironic_precision": 0.6372093023255814,
            "eval_ironic_recall": 0.6861435726210351,
            "eval_micro_f1": 0.7655555555555555,
            "eval_macro_f1": 0.7408273220062256,
            "eval_macro_precision": 0.7372193336486816,
            "eval_macro_recall": 0.745652973651886,
            "eval_acc": 0.7655555555555555,
            "eval_runtime": 4.4158,
            "eval_samples_per_second": 407.626,
            "eval_steps_per_second": 25.59,
            "epoch": 5.0
        }
    ]
}