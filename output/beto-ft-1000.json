{
    "context_hate": [
        {
            "eval_loss": 0.07583049684762955,
            "eval_calls_f1": 0.6274509803921569,
            "eval_women_f1": 0.40089086859688194,
            "eval_lgbti_f1": 0.44871794871794873,
            "eval_racism_f1": 0.6822335025380711,
            "eval_class_f1": 0.5494505494505495,
            "eval_politics_f1": 0.5845588235294118,
            "eval_disabled_f1": 0.512987012987013,
            "eval_appearance_f1": 0.7282051282051282,
            "eval_criminal_f1": 0.6637931034482758,
            "eval_mean_f1": 0.5775876045227051,
            "eval_mean_precision": 0.6104432940483093,
            "eval_mean_recall": 0.5610777139663696,
            "eval_hate_precision": 0.7074340527577938,
            "eval_hate_recall": 0.6566499721758486,
            "eval_hate_f1": 0.6810966810966812,
            "eval_runtime": 94.0694,
            "eval_samples_per_second": 120.581,
            "eval_steps_per_second": 7.537
        },
        {
            "eval_loss": 0.07857222110033035,
            "eval_calls_f1": 0.6473779385171791,
            "eval_women_f1": 0.4264392324093817,
            "eval_lgbti_f1": 0.44910179640718567,
            "eval_racism_f1": 0.6741344195519349,
            "eval_class_f1": 0.5422535211267606,
            "eval_politics_f1": 0.6031746031746031,
            "eval_disabled_f1": 0.5653710247349824,
            "eval_appearance_f1": 0.7429340511440108,
            "eval_criminal_f1": 0.6761768901569187,
            "eval_mean_f1": 0.5918848514556885,
            "eval_mean_precision": 0.6165605783462524,
            "eval_mean_recall": 0.5744593739509583,
            "eval_hate_precision": 0.7107930828861061,
            "eval_hate_recall": 0.6633277685030606,
            "eval_hate_f1": 0.6862406447898676,
            "eval_runtime": 94.6137,
            "eval_samples_per_second": 119.888,
            "eval_steps_per_second": 7.494
        },
        {
            "eval_loss": 0.07857222110033035,
            "eval_calls_f1": 0.6473779385171791,
            "eval_women_f1": 0.4264392324093817,
            "eval_lgbti_f1": 0.44910179640718567,
            "eval_racism_f1": 0.6741344195519349,
            "eval_class_f1": 0.5422535211267606,
            "eval_politics_f1": 0.6031746031746031,
            "eval_disabled_f1": 0.5653710247349824,
            "eval_appearance_f1": 0.7429340511440108,
            "eval_criminal_f1": 0.6761768901569187,
            "eval_mean_f1": 0.5918848514556885,
            "eval_mean_precision": 0.6165605783462524,
            "eval_mean_recall": 0.5744593739509583,
            "eval_hate_precision": 0.7107930828861061,
            "eval_hate_recall": 0.6633277685030606,
            "eval_hate_f1": 0.6862406447898676,
            "eval_runtime": 93.8741,
            "eval_samples_per_second": 120.832,
            "eval_steps_per_second": 7.553
        }
    ],
    "sentiment": [
        {
            "eval_loss": 1.6380295753479004,
            "eval_neg_f1": 0.7302283105022831,
            "eval_neg_precision": 0.7882492113564669,
            "eval_neg_recall": 0.6801633208574345,
            "eval_neu_f1": 0.5382759377056372,
            "eval_neu_precision": 0.47319706903200925,
            "eval_neu_recall": 0.6241098677517802,
            "eval_pos_f1": 0.7249666221628839,
            "eval_pos_precision": 0.7629976580796253,
            "eval_pos_recall": 0.6905468418821534,
            "eval_micro_f1": 0.668364537444934,
            "eval_macro_f1": 0.664490282535553,
            "eval_macro_precision": 0.6748146414756775,
            "eval_macro_recall": 0.6649399995803833,
            "eval_acc": 0.668364537444934,
            "eval_runtime": 27.8703,
            "eval_samples_per_second": 260.636,
            "eval_steps_per_second": 8.145,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.6380295753479004,
            "eval_neg_f1": 0.7302283105022831,
            "eval_neg_precision": 0.7882492113564669,
            "eval_neg_recall": 0.6801633208574345,
            "eval_neu_f1": 0.5382759377056372,
            "eval_neu_precision": 0.47319706903200925,
            "eval_neu_recall": 0.6241098677517802,
            "eval_pos_f1": 0.7249666221628839,
            "eval_pos_precision": 0.7629976580796253,
            "eval_pos_recall": 0.6905468418821534,
            "eval_micro_f1": 0.668364537444934,
            "eval_macro_f1": 0.664490282535553,
            "eval_macro_precision": 0.6748146414756775,
            "eval_macro_recall": 0.6649399995803833,
            "eval_acc": 0.668364537444934,
            "eval_runtime": 28.1744,
            "eval_samples_per_second": 257.823,
            "eval_steps_per_second": 8.057,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.6380295753479004,
            "eval_neg_f1": 0.7302283105022831,
            "eval_neg_precision": 0.7882492113564669,
            "eval_neg_recall": 0.6801633208574345,
            "eval_neu_f1": 0.5382759377056372,
            "eval_neu_precision": 0.47319706903200925,
            "eval_neu_recall": 0.6241098677517802,
            "eval_pos_f1": 0.7249666221628839,
            "eval_pos_precision": 0.7629976580796253,
            "eval_pos_recall": 0.6905468418821534,
            "eval_micro_f1": 0.668364537444934,
            "eval_macro_f1": 0.664490282535553,
            "eval_macro_precision": 0.6748146414756775,
            "eval_macro_recall": 0.6649399995803833,
            "eval_acc": 0.668364537444934,
            "eval_runtime": 28.1632,
            "eval_samples_per_second": 257.925,
            "eval_steps_per_second": 8.06,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.2198824882507324,
            "eval_others_f1": 0.7083333333333334,
            "eval_others_precision": 0.831973898858075,
            "eval_others_recall": 0.6166868198307134,
            "eval_joy_f1": 0.6894031668696711,
            "eval_joy_precision": 0.616557734204793,
            "eval_joy_recall": 0.7817679558011049,
            "eval_sadness_f1": 0.755,
            "eval_sadness_precision": 0.7512437810945274,
            "eval_sadness_recall": 0.7587939698492462,
            "eval_anger_f1": 0.49635036496350365,
            "eval_anger_precision": 0.42323651452282157,
            "eval_anger_recall": 0.6,
            "eval_surprise_f1": 0.3924050632911392,
            "eval_surprise_precision": 0.34444444444444444,
            "eval_surprise_recall": 0.45588235294117646,
            "eval_disgust_f1": 0.14492753623188404,
            "eval_disgust_precision": 0.1388888888888889,
            "eval_disgust_recall": 0.15151515151515152,
            "eval_fear_f1": 0.4363636363636364,
            "eval_fear_precision": 0.32432432432432434,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.652355396541443,
            "eval_macro_f1": 0.517540454864502,
            "eval_macro_precision": 0.49009567499160767,
            "eval_macro_recall": 0.5759018063545227,
            "eval_acc": 0.652355396541443,
            "eval_runtime": 6.7433,
            "eval_samples_per_second": 248.692,
            "eval_steps_per_second": 15.571,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2198824882507324,
            "eval_others_f1": 0.7083333333333334,
            "eval_others_precision": 0.831973898858075,
            "eval_others_recall": 0.6166868198307134,
            "eval_joy_f1": 0.6894031668696711,
            "eval_joy_precision": 0.616557734204793,
            "eval_joy_recall": 0.7817679558011049,
            "eval_sadness_f1": 0.755,
            "eval_sadness_precision": 0.7512437810945274,
            "eval_sadness_recall": 0.7587939698492462,
            "eval_anger_f1": 0.49635036496350365,
            "eval_anger_precision": 0.42323651452282157,
            "eval_anger_recall": 0.6,
            "eval_surprise_f1": 0.3924050632911392,
            "eval_surprise_precision": 0.34444444444444444,
            "eval_surprise_recall": 0.45588235294117646,
            "eval_disgust_f1": 0.14492753623188404,
            "eval_disgust_precision": 0.1388888888888889,
            "eval_disgust_recall": 0.15151515151515152,
            "eval_fear_f1": 0.4363636363636364,
            "eval_fear_precision": 0.32432432432432434,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.652355396541443,
            "eval_macro_f1": 0.517540454864502,
            "eval_macro_precision": 0.49009567499160767,
            "eval_macro_recall": 0.5759018063545227,
            "eval_acc": 0.652355396541443,
            "eval_runtime": 6.7344,
            "eval_samples_per_second": 249.02,
            "eval_steps_per_second": 15.592,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2198824882507324,
            "eval_others_f1": 0.7083333333333334,
            "eval_others_precision": 0.831973898858075,
            "eval_others_recall": 0.6166868198307134,
            "eval_joy_f1": 0.6894031668696711,
            "eval_joy_precision": 0.616557734204793,
            "eval_joy_recall": 0.7817679558011049,
            "eval_sadness_f1": 0.755,
            "eval_sadness_precision": 0.7512437810945274,
            "eval_sadness_recall": 0.7587939698492462,
            "eval_anger_f1": 0.49635036496350365,
            "eval_anger_precision": 0.42323651452282157,
            "eval_anger_recall": 0.6,
            "eval_surprise_f1": 0.3924050632911392,
            "eval_surprise_precision": 0.34444444444444444,
            "eval_surprise_recall": 0.45588235294117646,
            "eval_disgust_f1": 0.14492753623188404,
            "eval_disgust_precision": 0.1388888888888889,
            "eval_disgust_recall": 0.15151515151515152,
            "eval_fear_f1": 0.4363636363636364,
            "eval_fear_precision": 0.32432432432432434,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.652355396541443,
            "eval_macro_f1": 0.517540454864502,
            "eval_macro_precision": 0.49009567499160767,
            "eval_macro_recall": 0.5759018063545227,
            "eval_acc": 0.652355396541443,
            "eval_runtime": 6.5633,
            "eval_samples_per_second": 255.513,
            "eval_steps_per_second": 15.998,
            "epoch": 5.0
        }
    ],
    "model_name": "./models/beto-ft-1000/"
}