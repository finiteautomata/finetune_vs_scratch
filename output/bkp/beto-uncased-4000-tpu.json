{
    "context_hate": [
        {
            "eval_loss": 0.07818794250488281,
            "eval_calls_f1": 0.6576728499156829,
            "eval_women_f1": 0.40618101545253865,
            "eval_lgbti_f1": 0.43859649122807015,
            "eval_racism_f1": 0.6866866866866866,
            "eval_class_f1": 0.5314685314685315,
            "eval_politics_f1": 0.6124567474048442,
            "eval_disabled_f1": 0.5559566787003609,
            "eval_appearance_f1": 0.7509778357235984,
            "eval_criminal_f1": 0.6458923512747875,
            "eval_mean_f1": 0.5873210430145264,
            "eval_mean_precision": 0.6019814610481262,
            "eval_mean_recall": 0.579971432685852,
            "eval_hate_precision": 0.7084785133565621,
            "eval_hate_recall": 0.6789092932665554,
            "eval_hate_f1": 0.6933788007956805,
            "eval_runtime": 33.3933,
            "eval_samples_per_second": 339.679,
            "eval_steps_per_second": 21.232
        },
        {
            "eval_loss": 0.07801610231399536,
            "eval_calls_f1": 0.6690647482014388,
            "eval_women_f1": 0.4453125,
            "eval_lgbti_f1": 0.4751958224543081,
            "eval_racism_f1": 0.6782431052093973,
            "eval_class_f1": 0.5117845117845118,
            "eval_politics_f1": 0.6332179930795848,
            "eval_disabled_f1": 0.5454545454545454,
            "eval_appearance_f1": 0.7359198998748435,
            "eval_criminal_f1": 0.6192468619246864,
            "eval_mean_f1": 0.5903822183609009,
            "eval_mean_precision": 0.5878094434738159,
            "eval_mean_recall": 0.595078706741333,
            "eval_hate_precision": 0.685666851134477,
            "eval_hate_recall": 0.6894824707846411,
            "eval_hate_f1": 0.6875693673695894,
            "eval_runtime": 33.3085,
            "eval_samples_per_second": 340.543,
            "eval_steps_per_second": 21.286
        },
        {
            "eval_loss": 0.07999571412801743,
            "eval_calls_f1": 0.657293497363796,
            "eval_women_f1": 0.43736730360934184,
            "eval_lgbti_f1": 0.472934472934473,
            "eval_racism_f1": 0.6779999999999999,
            "eval_class_f1": 0.5372168284789645,
            "eval_politics_f1": 0.6054421768707482,
            "eval_disabled_f1": 0.5599999999999999,
            "eval_appearance_f1": 0.7320754716981132,
            "eval_criminal_f1": 0.6075949367088609,
            "eval_mean_f1": 0.5875471830368042,
            "eval_mean_precision": 0.5881956815719604,
            "eval_mean_recall": 0.5937130451202393,
            "eval_hate_precision": 0.6799557032115172,
            "eval_hate_recall": 0.6833611574846967,
            "eval_hate_f1": 0.68165417707466,
            "eval_runtime": 33.3106,
            "eval_samples_per_second": 340.522,
            "eval_steps_per_second": 21.285
        }
    ],
    "hate": [
        {
            "eval_loss": 0.9311405420303345,
            "eval_ok_f1": 0.7801500288517023,
            "eval_ok_precision": 0.8524590163934426,
            "eval_ok_recall": 0.7191489361702128,
            "eval_hateful_f1": 0.7402862985685073,
            "eval_hateful_precision": 0.6728624535315985,
            "eval_hateful_recall": 0.8227272727272728,
            "eval_micro_f1": 0.761875,
            "eval_macro_f1": 0.7602181434631348,
            "eval_macro_precision": 0.7626607418060303,
            "eval_macro_recall": 0.7709380984306335,
            "eval_acc": 0.761875,
            "eval_runtime": 3.0393,
            "eval_samples_per_second": 526.435,
            "eval_steps_per_second": 32.902,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2417714595794678,
            "eval_ok_f1": 0.7855020796197267,
            "eval_ok_precision": 0.8896366083445492,
            "eval_ok_recall": 0.7031914893617022,
            "eval_hateful_f1": 0.7620303230059328,
            "eval_hateful_precision": 0.6744457409568262,
            "eval_hateful_recall": 0.8757575757575757,
            "eval_micro_f1": 0.774375,
            "eval_macro_f1": 0.7737661600112915,
            "eval_macro_precision": 0.7820411920547485,
            "eval_macro_recall": 0.7894745469093323,
            "eval_acc": 0.774375,
            "eval_runtime": 3.0489,
            "eval_samples_per_second": 524.781,
            "eval_steps_per_second": 32.799,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2825618982315063,
            "eval_ok_f1": 0.7771156138259833,
            "eval_ok_precision": 0.8834688346883469,
            "eval_ok_recall": 0.6936170212765957,
            "eval_hateful_f1": 0.7542706964520368,
            "eval_hateful_precision": 0.665893271461717,
            "eval_hateful_recall": 0.8696969696969697,
            "eval_micro_f1": 0.7662500000000001,
            "eval_macro_f1": 0.765693187713623,
            "eval_macro_precision": 0.774681031703949,
            "eval_macro_recall": 0.7816569805145264,
            "eval_acc": 0.76625,
            "eval_runtime": 3.0661,
            "eval_samples_per_second": 521.832,
            "eval_steps_per_second": 32.615,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 1.081045389175415,
            "eval_neg_f1": 0.7523478260869565,
            "eval_neg_precision": 0.7694770544290288,
            "eval_neg_recall": 0.7359646138142225,
            "eval_neu_f1": 0.5542060278902384,
            "eval_neu_precision": 0.4967741935483871,
            "eval_neu_recall": 0.6266531027466938,
            "eval_pos_f1": 0.7382271468144044,
            "eval_pos_precision": 0.8104409528636594,
            "eval_pos_recall": 0.6778295888088173,
            "eval_micro_f1": 0.6875,
            "eval_macro_f1": 0.681593656539917,
            "eval_macro_precision": 0.692230761051178,
            "eval_macro_recall": 0.6801490783691406,
            "eval_acc": 0.6875,
            "eval_runtime": 9.2843,
            "eval_samples_per_second": 782.399,
            "eval_steps_per_second": 48.9,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7660906910896301,
            "eval_neg_f1": 0.7529370506750833,
            "eval_neg_precision": 0.7767727930535456,
            "eval_neg_recall": 0.7305205852330725,
            "eval_neu_f1": 0.5404329435182881,
            "eval_neu_precision": 0.5289819775937652,
            "eval_neu_recall": 0.5523906408952187,
            "eval_pos_f1": 0.7540574282147317,
            "eval_pos_precision": 0.7404985696771557,
            "eval_pos_recall": 0.768122085629504,
            "eval_micro_f1": 0.6945209251101322,
            "eval_macro_f1": 0.6824758052825928,
            "eval_macro_precision": 0.6820843815803528,
            "eval_macro_recall": 0.6836778521537781,
            "eval_acc": 0.6945209251101322,
            "eval_runtime": 9.3266,
            "eval_samples_per_second": 778.85,
            "eval_steps_per_second": 48.678,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.4736601114273071,
            "eval_neg_f1": 0.7505345687811831,
            "eval_neg_precision": 0.7878787878787878,
            "eval_neg_recall": 0.7165702619938754,
            "eval_neu_f1": 0.5553522415370539,
            "eval_neu_precision": 0.5045719035743973,
            "eval_neu_recall": 0.6174974567650051,
            "eval_pos_f1": 0.7477992957746479,
            "eval_pos_precision": 0.7775743707093822,
            "eval_pos_recall": 0.7202204323866045,
            "eval_micro_f1": 0.6909416299559471,
            "eval_macro_f1": 0.6845620274543762,
            "eval_macro_precision": 0.6900083422660828,
            "eval_macro_recall": 0.684762716293335,
            "eval_acc": 0.6909416299559471,
            "eval_runtime": 9.3401,
            "eval_samples_per_second": 777.723,
            "eval_steps_per_second": 48.608,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.7118960618972778,
            "eval_others_f1": 0.7683000604960678,
            "eval_others_precision": 0.7687651331719129,
            "eval_others_recall": 0.7678355501813785,
            "eval_joy_f1": 0.6711229946524063,
            "eval_joy_precision": 0.6502590673575129,
            "eval_joy_recall": 0.6933701657458563,
            "eval_sadness_f1": 0.7518427518427518,
            "eval_sadness_precision": 0.7355769230769231,
            "eval_sadness_recall": 0.7688442211055276,
            "eval_anger_f1": 0.5982404692082111,
            "eval_anger_precision": 0.5964912280701754,
            "eval_anger_recall": 0.6,
            "eval_surprise_f1": 0.35714285714285715,
            "eval_surprise_precision": 0.45454545454545453,
            "eval_surprise_recall": 0.29411764705882354,
            "eval_disgust_f1": 0.12244897959183672,
            "eval_disgust_precision": 0.1875,
            "eval_disgust_recall": 0.09090909090909091,
            "eval_fear_f1": 0.5454545454545455,
            "eval_fear_precision": 0.46153846153846156,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.7012522361359571,
            "eval_macro_f1": 0.5449361205101013,
            "eval_macro_precision": 0.5506680607795715,
            "eval_macro_recall": 0.5545347929000854,
            "eval_acc": 0.7012522361359571,
            "eval_runtime": 3.4966,
            "eval_samples_per_second": 479.603,
            "eval_steps_per_second": 30.029,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.5134097337722778,
            "eval_others_f1": 0.7595419847328244,
            "eval_others_precision": 0.8013422818791947,
            "eval_others_recall": 0.7218863361547763,
            "eval_joy_f1": 0.6919060052219321,
            "eval_joy_precision": 0.655940594059406,
            "eval_joy_recall": 0.7320441988950276,
            "eval_sadness_f1": 0.7563451776649746,
            "eval_sadness_precision": 0.764102564102564,
            "eval_sadness_recall": 0.7487437185929648,
            "eval_anger_f1": 0.5691489361702128,
            "eval_anger_precision": 0.5194174757281553,
            "eval_anger_recall": 0.6294117647058823,
            "eval_surprise_f1": 0.3609022556390977,
            "eval_surprise_precision": 0.36923076923076925,
            "eval_surprise_recall": 0.35294117647058826,
            "eval_disgust_f1": 0.09836065573770493,
            "eval_disgust_precision": 0.10714285714285714,
            "eval_disgust_recall": 0.09090909090909091,
            "eval_fear_f1": 0.4999999999999999,
            "eval_fear_precision": 0.38235294117647056,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.6905187835420393,
            "eval_macro_f1": 0.5337435603141785,
            "eval_macro_precision": 0.5142185091972351,
            "eval_macro_recall": 0.5711655020713806,
            "eval_acc": 0.6905187835420393,
            "eval_runtime": 3.5185,
            "eval_samples_per_second": 476.629,
            "eval_steps_per_second": 29.843,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2483842372894287,
            "eval_others_f1": 0.7493540051679587,
            "eval_others_precision": 0.8044382801664355,
            "eval_others_recall": 0.7013301088270859,
            "eval_joy_f1": 0.6507936507936508,
            "eval_joy_precision": 0.6243654822335025,
            "eval_joy_recall": 0.6795580110497238,
            "eval_sadness_f1": 0.7493670886075949,
            "eval_sadness_precision": 0.7551020408163265,
            "eval_sadness_recall": 0.7437185929648241,
            "eval_anger_f1": 0.5714285714285714,
            "eval_anger_precision": 0.5045045045045045,
            "eval_anger_recall": 0.6588235294117647,
            "eval_surprise_f1": 0.33939393939393936,
            "eval_surprise_precision": 0.28865979381443296,
            "eval_surprise_recall": 0.4117647058823529,
            "eval_disgust_f1": 0.12244897959183672,
            "eval_disgust_precision": 0.1875,
            "eval_disgust_recall": 0.09090909090909091,
            "eval_fear_f1": 0.4897959183673469,
            "eval_fear_precision": 0.3870967741935484,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6732259988073942,
            "eval_macro_f1": 0.5246546268463135,
            "eval_macro_precision": 0.507381021976471,
            "eval_macro_recall": 0.5646815299987793,
            "eval_acc": 0.6732259988073942,
            "eval_runtime": 3.4915,
            "eval_samples_per_second": 480.305,
            "eval_steps_per_second": 30.073,
            "epoch": 5.0
        }
    ],
    "model_name": "models/beto-uncased-4000-tpu/"
}