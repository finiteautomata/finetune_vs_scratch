{
    "context_hate": [
        {
            "eval_loss": 0.07922288775444031,
            "eval_calls_f1": 0.6621621621621621,
            "eval_women_f1": 0.43881856540084385,
            "eval_lgbti_f1": 0.4674556213017751,
            "eval_racism_f1": 0.6779999999999999,
            "eval_class_f1": 0.4705882352941176,
            "eval_politics_f1": 0.6228373702422145,
            "eval_disabled_f1": 0.5328947368421053,
            "eval_appearance_f1": 0.743362831858407,
            "eval_criminal_f1": 0.6320224719101124,
            "eval_mean_f1": 0.5831269025802612,
            "eval_mean_precision": 0.5854232907295227,
            "eval_mean_recall": 0.5891158580780029,
            "eval_hate_precision": 0.6869759642258245,
            "eval_hate_recall": 0.6839176405119644,
            "eval_hate_f1": 0.6854433909648634,
            "eval_runtime": 39.2729,
            "eval_samples_per_second": 288.825,
            "eval_steps_per_second": 18.053
        },
        {
            "eval_loss": 0.0793837234377861,
            "eval_calls_f1": 0.6551724137931033,
            "eval_women_f1": 0.4580777096114519,
            "eval_lgbti_f1": 0.4642857142857143,
            "eval_racism_f1": 0.6788813886210222,
            "eval_class_f1": 0.4545454545454546,
            "eval_politics_f1": 0.5846153846153846,
            "eval_disabled_f1": 0.5376344086021505,
            "eval_appearance_f1": 0.7178217821782179,
            "eval_criminal_f1": 0.6178861788617886,
            "eval_mean_f1": 0.5743244886398315,
            "eval_mean_precision": 0.5766748189926147,
            "eval_mean_recall": 0.5784211754798889,
            "eval_hate_precision": 0.6738173817381738,
            "eval_hate_recall": 0.6816917084028937,
            "eval_hate_f1": 0.677731673582296,
            "eval_runtime": 41.1039,
            "eval_samples_per_second": 275.959,
            "eval_steps_per_second": 17.249
        },
        {
            "eval_loss": 0.07803747802972794,
            "eval_calls_f1": 0.6459412780656304,
            "eval_women_f1": 0.4360587002096436,
            "eval_lgbti_f1": 0.4741144414168938,
            "eval_racism_f1": 0.6738916256157635,
            "eval_class_f1": 0.48109965635738833,
            "eval_politics_f1": 0.6161616161616161,
            "eval_disabled_f1": 0.5480427046263344,
            "eval_appearance_f1": 0.7342747111681642,
            "eval_criminal_f1": 0.6341463414634146,
            "eval_mean_f1": 0.5826367735862732,
            "eval_mean_precision": 0.5817692279815674,
            "eval_mean_recall": 0.5874610543251038,
            "eval_hate_precision": 0.6767454645409565,
            "eval_hate_recall": 0.6850306065664997,
            "eval_hate_f1": 0.680862831858407,
            "eval_runtime": 39.0982,
            "eval_samples_per_second": 290.116,
            "eval_steps_per_second": 18.134
        }
    ],
    "hate": [
        {
            "eval_loss": 0.5006516575813293,
            "eval_ok_f1": 0.779445727482679,
            "eval_ok_precision": 0.8522727272727273,
            "eval_ok_recall": 0.7180851063829787,
            "eval_hateful_f1": 0.7397820163487738,
            "eval_hateful_precision": 0.6720297029702971,
            "eval_hateful_recall": 0.8227272727272728,
            "eval_micro_f1": 0.76125,
            "eval_macro_f1": 0.7596138715744019,
            "eval_macro_precision": 0.7621512413024902,
            "eval_macro_recall": 0.770406186580658,
            "eval_acc": 0.76125,
            "eval_runtime": 3.694,
            "eval_samples_per_second": 433.129,
            "eval_steps_per_second": 27.071,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2016663551330566,
            "eval_ok_f1": 0.7879146919431279,
            "eval_ok_precision": 0.8890374331550802,
            "eval_ok_recall": 0.7074468085106383,
            "eval_hateful_f1": 0.7632275132275133,
            "eval_hateful_precision": 0.6772300469483568,
            "eval_hateful_recall": 0.8742424242424243,
            "eval_micro_f1": 0.7762499999999999,
            "eval_macro_f1": 0.7755711078643799,
            "eval_macro_precision": 0.7831337451934814,
            "eval_macro_recall": 0.7908446192741394,
            "eval_acc": 0.77625,
            "eval_runtime": 3.501,
            "eval_samples_per_second": 457.018,
            "eval_steps_per_second": 28.564,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.043684720993042,
            "eval_ok_f1": 0.8130630630630632,
            "eval_ok_precision": 0.8636363636363636,
            "eval_ok_recall": 0.7680851063829788,
            "eval_hateful_f1": 0.7668539325842697,
            "eval_hateful_precision": 0.7146596858638743,
            "eval_hateful_recall": 0.8272727272727273,
            "eval_micro_f1": 0.7925,
            "eval_macro_f1": 0.7899584770202637,
            "eval_macro_precision": 0.7891480326652527,
            "eval_macro_recall": 0.7976789474487305,
            "eval_acc": 0.7925,
            "eval_runtime": 3.5551,
            "eval_samples_per_second": 450.063,
            "eval_steps_per_second": 28.129,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 0.7231040596961975,
            "eval_neg_f1": 0.7542134831460674,
            "eval_neg_precision": 0.779107725788901,
            "eval_neg_recall": 0.7308608370193943,
            "eval_neu_f1": 0.5499276410998554,
            "eval_neu_precision": 0.5229357798165137,
            "eval_neu_recall": 0.5798575788402849,
            "eval_pos_f1": 0.7656850192061458,
            "eval_pos_precision": 0.770949720670391,
            "eval_pos_recall": 0.7604917337855023,
            "eval_micro_f1": 0.699614537444934,
            "eval_macro_f1": 0.6899420619010925,
            "eval_macro_precision": 0.6909977793693542,
            "eval_macro_recall": 0.690403401851654,
            "eval_acc": 0.699614537444934,
            "eval_runtime": 9.5832,
            "eval_samples_per_second": 757.994,
            "eval_steps_per_second": 47.375,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7334454655647278,
            "eval_neg_f1": 0.7583682008368201,
            "eval_neg_precision": 0.7776188773686092,
            "eval_neg_recall": 0.7400476352500851,
            "eval_neu_f1": 0.5544369000234137,
            "eval_neu_precision": 0.5136659436008677,
            "eval_neu_recall": 0.602238046795524,
            "eval_pos_f1": 0.754257907542579,
            "eval_pos_precision": 0.7886216466234968,
            "eval_pos_recall": 0.7227638830012717,
            "eval_micro_f1": 0.697136563876652,
            "eval_macro_f1": 0.6890210509300232,
            "eval_macro_precision": 0.6933021545410156,
            "eval_macro_recall": 0.6883499026298523,
            "eval_acc": 0.697136563876652,
            "eval_runtime": 10.3374,
            "eval_samples_per_second": 702.689,
            "eval_steps_per_second": 43.918,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0015755891799927,
            "eval_neg_f1": 0.7487914055505819,
            "eval_neg_precision": 0.7902494331065759,
            "eval_neg_recall": 0.7114664851990473,
            "eval_neu_f1": 0.5568396722000419,
            "eval_neu_precision": 0.47440028643036164,
            "eval_neu_recall": 0.6739572736520855,
            "eval_pos_f1": 0.7318355640535372,
            "eval_pos_precision": 0.838904109589041,
            "eval_pos_recall": 0.649003815175922,
            "eval_micro_f1": 0.6810297356828194,
            "eval_macro_f1": 0.6791555285453796,
            "eval_macro_precision": 0.7011845707893372,
            "eval_macro_recall": 0.6781425476074219,
            "eval_acc": 0.6810297356828194,
            "eval_runtime": 10.3069,
            "eval_samples_per_second": 704.767,
            "eval_steps_per_second": 44.048,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.585323691368103,
            "eval_others_f1": 0.7574414186193795,
            "eval_others_precision": 0.7952127659574468,
            "eval_others_recall": 0.7230955259975816,
            "eval_joy_f1": 0.6932989690721649,
            "eval_joy_precision": 0.6497584541062802,
            "eval_joy_recall": 0.7430939226519337,
            "eval_sadness_f1": 0.7446300715990454,
            "eval_sadness_precision": 0.7090909090909091,
            "eval_sadness_recall": 0.7839195979899497,
            "eval_anger_f1": 0.5604395604395604,
            "eval_anger_precision": 0.5257731958762887,
            "eval_anger_recall": 0.6,
            "eval_surprise_f1": 0.3898305084745763,
            "eval_surprise_precision": 0.46,
            "eval_surprise_recall": 0.3382352941176471,
            "eval_disgust_f1": 0.03773584905660378,
            "eval_disgust_precision": 0.05,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.5777777777777777,
            "eval_fear_precision": 0.48148148148148145,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.6929039952295766,
            "eval_macro_f1": 0.5373077392578125,
            "eval_macro_precision": 0.5244738459587097,
            "eval_macro_recall": 0.5629813075065613,
            "eval_acc": 0.6929039952295766,
            "eval_runtime": 4.6081,
            "eval_samples_per_second": 363.922,
            "eval_steps_per_second": 22.786,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.5512197017669678,
            "eval_others_f1": 0.7573300062383033,
            "eval_others_precision": 0.7822164948453608,
            "eval_others_recall": 0.7339782345828295,
            "eval_joy_f1": 0.6961178045515396,
            "eval_joy_precision": 0.6753246753246753,
            "eval_joy_recall": 0.7182320441988951,
            "eval_sadness_f1": 0.75,
            "eval_sadness_precision": 0.746268656716418,
            "eval_sadness_recall": 0.7537688442211056,
            "eval_anger_f1": 0.5552699228791774,
            "eval_anger_precision": 0.4931506849315068,
            "eval_anger_recall": 0.6352941176470588,
            "eval_surprise_f1": 0.3760683760683761,
            "eval_surprise_precision": 0.4489795918367347,
            "eval_surprise_recall": 0.3235294117647059,
            "eval_disgust_f1": 0.07142857142857144,
            "eval_disgust_precision": 0.08695652173913043,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.5238095238095238,
            "eval_fear_precision": 0.4583333333333333,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.691711389385808,
            "eval_macro_f1": 0.5328606367111206,
            "eval_macro_precision": 0.52731853723526,
            "eval_macro_recall": 0.5480743050575256,
            "eval_acc": 0.691711389385808,
            "eval_runtime": 4.7394,
            "eval_samples_per_second": 353.845,
            "eval_steps_per_second": 22.155,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.556312084197998,
            "eval_others_f1": 0.7501605651894669,
            "eval_others_precision": 0.8,
            "eval_others_recall": 0.7061668681983071,
            "eval_joy_f1": 0.6903553299492385,
            "eval_joy_precision": 0.6384976525821596,
            "eval_joy_recall": 0.7513812154696132,
            "eval_sadness_f1": 0.7584541062801934,
            "eval_sadness_precision": 0.7302325581395349,
            "eval_sadness_recall": 0.7889447236180904,
            "eval_anger_f1": 0.5904255319148937,
            "eval_anger_precision": 0.5388349514563107,
            "eval_anger_recall": 0.6529411764705882,
            "eval_surprise_f1": 0.38461538461538464,
            "eval_surprise_precision": 0.4032258064516129,
            "eval_surprise_recall": 0.36764705882352944,
            "eval_disgust_f1": 0.04444444444444444,
            "eval_disgust_precision": 0.08333333333333333,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.5,
            "eval_fear_precision": 0.4230769230769231,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6923076923076923,
            "eval_macro_f1": 0.5312079191207886,
            "eval_macro_precision": 0.5167430639266968,
            "eval_macro_recall": 0.5583564639091492,
            "eval_acc": 0.6923076923076923,
            "eval_runtime": 4.9136,
            "eval_samples_per_second": 341.301,
            "eval_steps_per_second": 21.369,
            "epoch": 5.0
        }
    ],
    "model_name": "models/beto-cased-15000/"
}