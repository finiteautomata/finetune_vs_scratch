{
    "context_hate": [
        {
            "eval_loss": 0.5310505628585815,
            "eval_calls_f1": 0.2871287128712871,
            "eval_women_f1": 0.21284403669724766,
            "eval_lgbti_f1": 0.183206106870229,
            "eval_racism_f1": 0.5081521739130435,
            "eval_class_f1": 0.2702702702702703,
            "eval_politics_f1": 0.2778675282714055,
            "eval_disabled_f1": 0.12324929971988796,
            "eval_appearance_f1": 0.45054945054945056,
            "eval_criminal_f1": 0.2236024844720497,
            "eval_mean_f1": 0.2818744480609894,
            "eval_mean_precision": 0.18715770542621613,
            "eval_mean_recall": 0.6383375525474548,
            "eval_hate_precision": 0.1682769726247987,
            "eval_hate_recall": 0.2742782152230971,
            "eval_hate_f1": 0.2085828343313373,
            "eval_runtime": 41.8108,
            "eval_samples_per_second": 119.586,
            "eval_steps_per_second": 7.486,
            "epoch": 2.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 0.8256248235702515,
            "eval_neg_f1": 0.7293646823411707,
            "eval_neg_precision": 0.7665615141955836,
            "eval_neg_recall": 0.6956106870229007,
            "eval_neu_f1": 0.512035010940919,
            "eval_neu_precision": 0.4875,
            "eval_neu_recall": 0.5391705069124424,
            "eval_pos_f1": 0.7343558282208589,
            "eval_pos_precision": 0.7219541616405307,
            "eval_pos_recall": 0.7471910112359551,
            "eval_micro_f1": 0.6714,
            "eval_macro_f1": 0.6585851907730103,
            "eval_macro_precision": 0.6586718559265137,
            "eval_macro_recall": 0.6606574058532715,
            "eval_acc": 0.6714,
            "eval_runtime": 19.6197,
            "eval_samples_per_second": 254.845,
            "eval_steps_per_second": 8.002,
            "epoch": 2.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.1069961786270142,
            "eval_others_f1": 0.7020523708421796,
            "eval_others_precision": 0.8464163822525598,
            "eval_others_recall": 0.599758162031439,
            "eval_joy_f1": 0.6525323910482921,
            "eval_joy_precision": 0.5687885010266941,
            "eval_joy_recall": 0.7651933701657458,
            "eval_sadness_f1": 0.7216981132075473,
            "eval_sadness_precision": 0.68,
            "eval_sadness_recall": 0.7688442211055276,
            "eval_anger_f1": 0.3278688524590164,
            "eval_anger_precision": 0.37037037037037035,
            "eval_anger_recall": 0.29411764705882354,
            "eval_surprise_f1": 0.3694267515923567,
            "eval_surprise_precision": 0.3258426966292135,
            "eval_surprise_recall": 0.4264705882352941,
            "eval_disgust_f1": 0.19230769230769232,
            "eval_disgust_precision": 0.12195121951219512,
            "eval_disgust_recall": 0.45454545454545453,
            "eval_fear_f1": 0.56,
            "eval_fear_precision": 0.4375,
            "eval_fear_recall": 0.7777777777777778,
            "eval_micro_f1": 0.616577221228384,
            "eval_macro_f1": 0.5036979913711548,
            "eval_macro_precision": 0.4786956310272217,
            "eval_macro_recall": 0.5838152766227722,
            "eval_acc": 0.616577221228384,
            "eval_runtime": 7.1445,
            "eval_samples_per_second": 234.727,
            "eval_steps_per_second": 14.697,
            "epoch": 2.0
        }
    ],
    "model_name": "dccuchile/bert-base-spanish-wwm-uncased"
}