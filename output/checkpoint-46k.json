{
    "context_hate": [
        {
            "eval_loss": 0.08783739805221558,
            "eval_calls_f1": 0.5582137161084529,
            "eval_women_f1": 0.3801065719360569,
            "eval_lgbti_f1": 0.4467005076142132,
            "eval_racism_f1": 0.6188811188811189,
            "eval_class_f1": 0.4024390243902439,
            "eval_politics_f1": 0.5604900459418071,
            "eval_disabled_f1": 0.4584717607973422,
            "eval_appearance_f1": 0.6658851113716294,
            "eval_criminal_f1": 0.5832290362953692,
            "eval_mean_f1": 0.5193796753883362,
            "eval_mean_precision": 0.47402653098106384,
            "eval_mean_recall": 0.5765501856803894,
            "eval_hate_precision": 0.6042989741084513,
            "eval_hate_recall": 0.6883695047301057,
            "eval_hate_f1": 0.6436004162330905,
            "eval_runtime": 35.1208,
            "eval_samples_per_second": 322.971,
            "eval_steps_per_second": 20.187
        },
        {
            "eval_loss": 0.08782122284173965,
            "eval_calls_f1": 0.5653495440729484,
            "eval_women_f1": 0.39625585023400933,
            "eval_lgbti_f1": 0.47826086956521735,
            "eval_racism_f1": 0.6049180327868853,
            "eval_class_f1": 0.4146341463414634,
            "eval_politics_f1": 0.569182389937107,
            "eval_disabled_f1": 0.46451612903225803,
            "eval_appearance_f1": 0.6420581655480985,
            "eval_criminal_f1": 0.5558312655086848,
            "eval_mean_f1": 0.5212229490280151,
            "eval_mean_precision": 0.4623716175556183,
            "eval_mean_recall": 0.6001675128936768,
            "eval_hate_precision": 0.5885036496350365,
            "eval_hate_recall": 0.7178631051752922,
            "eval_hate_f1": 0.6467786412634746,
            "eval_runtime": 34.7439,
            "eval_samples_per_second": 326.474,
            "eval_steps_per_second": 20.406
        },
        {
            "eval_loss": 0.08545663207769394,
            "eval_calls_f1": 0.5850556438791733,
            "eval_women_f1": 0.36054421768707484,
            "eval_lgbti_f1": 0.4914004914004914,
            "eval_racism_f1": 0.6221821460775473,
            "eval_class_f1": 0.43749999999999994,
            "eval_politics_f1": 0.5723577235772358,
            "eval_disabled_f1": 0.4509803921568628,
            "eval_appearance_f1": 0.6559263521288837,
            "eval_criminal_f1": 0.5691699604743085,
            "eval_mean_f1": 0.527235209941864,
            "eval_mean_precision": 0.4848044812679291,
            "eval_mean_recall": 0.579809308052063,
            "eval_hate_precision": 0.6136931534232883,
            "eval_hate_recall": 0.6833611574846967,
            "eval_hate_f1": 0.6466561348077936,
            "eval_runtime": 34.4834,
            "eval_samples_per_second": 328.941,
            "eval_steps_per_second": 20.561
        },
        {
            "eval_loss": 0.08247455954551697,
            "eval_calls_f1": 0.6023688663282573,
            "eval_women_f1": 0.389351081530782,
            "eval_lgbti_f1": 0.45,
            "eval_racism_f1": 0.639853747714808,
            "eval_class_f1": 0.4332129963898917,
            "eval_politics_f1": 0.5909849749582637,
            "eval_disabled_f1": 0.4565916398713826,
            "eval_appearance_f1": 0.6690307328605201,
            "eval_criminal_f1": 0.5949535192563081,
            "eval_mean_f1": 0.5362608432769775,
            "eval_mean_precision": 0.50725257396698,
            "eval_mean_recall": 0.5740014910697937,
            "eval_hate_precision": 0.6302349336057201,
            "eval_hate_recall": 0.6867000556483027,
            "eval_hate_f1": 0.6572569906790945,
            "eval_runtime": 34.5647,
            "eval_samples_per_second": 328.167,
            "eval_steps_per_second": 20.512
        },
        {
            "eval_loss": 0.08469752967357635,
            "eval_calls_f1": 0.5608974358974358,
            "eval_women_f1": 0.35000000000000003,
            "eval_lgbti_f1": 0.4756756756756757,
            "eval_racism_f1": 0.6237712243074174,
            "eval_class_f1": 0.4444444444444444,
            "eval_politics_f1": 0.5771144278606966,
            "eval_disabled_f1": 0.44927536231884063,
            "eval_appearance_f1": 0.6674259681093395,
            "eval_criminal_f1": 0.5641677255400255,
            "eval_mean_f1": 0.5236413478851318,
            "eval_mean_precision": 0.49255576729774475,
            "eval_mean_recall": 0.5629963874816895,
            "eval_hate_precision": 0.6255661801711122,
            "eval_hate_recall": 0.6917084028937117,
            "eval_hate_f1": 0.6569767441860466,
            "eval_runtime": 32.4527,
            "eval_samples_per_second": 349.524,
            "eval_steps_per_second": 21.847
        }
    ],
    "hate": [
        {
            "eval_loss": 0.8272106647491455,
            "eval_ok_f1": 0.8029115341545352,
            "eval_ok_precision": 0.8475177304964538,
            "eval_ok_recall": 0.7627659574468085,
            "eval_hateful_f1": 0.7510608203677511,
            "eval_hateful_precision": 0.7042440318302388,
            "eval_hateful_recall": 0.8045454545454546,
            "eval_micro_f1": 0.78,
            "eval_macro_f1": 0.7769861817359924,
            "eval_macro_precision": 0.7758808732032776,
            "eval_macro_recall": 0.7836557030677795,
            "eval_acc": 0.78,
            "eval_runtime": 3.4814,
            "eval_samples_per_second": 459.579,
            "eval_steps_per_second": 28.724,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7173323035240173,
            "eval_ok_f1": 0.7935222672064777,
            "eval_ok_precision": 0.8694550063371356,
            "eval_ok_recall": 0.7297872340425532,
            "eval_hateful_f1": 0.7573079537729436,
            "eval_hateful_precision": 0.686806411837238,
            "eval_hateful_recall": 0.843939393939394,
            "eval_micro_f1": 0.776875,
            "eval_macro_f1": 0.7754150629043579,
            "eval_macro_precision": 0.7781307101249695,
            "eval_macro_recall": 0.7868633270263672,
            "eval_acc": 0.776875,
            "eval_runtime": 3.6014,
            "eval_samples_per_second": 444.273,
            "eval_steps_per_second": 27.767,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8029695153236389,
            "eval_ok_f1": 0.7997750281214847,
            "eval_ok_precision": 0.8484486873508353,
            "eval_ok_recall": 0.7563829787234042,
            "eval_hateful_f1": 0.7496483825597751,
            "eval_hateful_precision": 0.699475065616798,
            "eval_hateful_recall": 0.8075757575757576,
            "eval_micro_f1": 0.7775,
            "eval_macro_f1": 0.7747117280960083,
            "eval_macro_precision": 0.7739619016647339,
            "eval_macro_recall": 0.7819793820381165,
            "eval_acc": 0.7775,
            "eval_runtime": 3.5621,
            "eval_samples_per_second": 449.171,
            "eval_steps_per_second": 28.073,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7808749675750732,
            "eval_ok_f1": 0.7751937984496123,
            "eval_ok_precision": 0.8819538670284939,
            "eval_ok_recall": 0.6914893617021277,
            "eval_hateful_f1": 0.7524622455679579,
            "eval_hateful_precision": 0.6639629200463499,
            "eval_hateful_recall": 0.8681818181818182,
            "eval_micro_f1": 0.764375,
            "eval_macro_f1": 0.7638280391693115,
            "eval_macro_precision": 0.7729583978652954,
            "eval_macro_recall": 0.77983558177948,
            "eval_acc": 0.764375,
            "eval_runtime": 3.5227,
            "eval_samples_per_second": 454.199,
            "eval_steps_per_second": 28.387,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8007693290710449,
            "eval_ok_f1": 0.8145294441386902,
            "eval_ok_precision": 0.8437856328392246,
            "eval_ok_recall": 0.7872340425531915,
            "eval_hateful_f1": 0.7563268257411424,
            "eval_hateful_precision": 0.7233748271092669,
            "eval_hateful_recall": 0.7924242424242425,
            "eval_micro_f1": 0.789375,
            "eval_macro_f1": 0.7854281663894653,
            "eval_macro_precision": 0.7835802435874939,
            "eval_macro_recall": 0.7898291349411011,
            "eval_acc": 0.789375,
            "eval_runtime": 3.434,
            "eval_samples_per_second": 465.924,
            "eval_steps_per_second": 29.12,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 1.0172669887542725,
            "eval_neg_f1": 0.7435228655885932,
            "eval_neg_precision": 0.7603129445234709,
            "eval_neg_recall": 0.7274583191561755,
            "eval_neu_f1": 0.5308100623124855,
            "eval_neu_precision": 0.48584706379383186,
            "eval_neu_recall": 0.5849440488301119,
            "eval_pos_f1": 0.7353735373537355,
            "eval_pos_precision": 0.7836930455635491,
            "eval_pos_recall": 0.6926663840610429,
            "eval_micro_f1": 0.6775881057268722,
            "eval_macro_f1": 0.6699021458625793,
            "eval_macro_precision": 0.6766176819801331,
            "eval_macro_recall": 0.6683562397956848,
            "eval_acc": 0.6775881057268722,
            "eval_runtime": 10.7959,
            "eval_samples_per_second": 672.845,
            "eval_steps_per_second": 42.053,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8780868053436279,
            "eval_neg_f1": 0.7386464039582965,
            "eval_neg_precision": 0.7683823529411765,
            "eval_neg_recall": 0.7111262334127254,
            "eval_neu_f1": 0.5288184438040345,
            "eval_neu_precision": 0.5009099181073703,
            "eval_neu_recall": 0.5600203458799593,
            "eval_pos_f1": 0.7336875664187035,
            "eval_pos_precision": 0.7357203751065644,
            "eval_pos_recall": 0.731665960152607,
            "eval_micro_f1": 0.6768997797356828,
            "eval_macro_f1": 0.667050838470459,
            "eval_macro_precision": 0.6683375835418701,
            "eval_macro_recall": 0.6676041483879089,
            "eval_acc": 0.6768997797356828,
            "eval_runtime": 10.5771,
            "eval_samples_per_second": 686.77,
            "eval_steps_per_second": 42.923,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7610516548156738,
            "eval_neg_f1": 0.7406746385864715,
            "eval_neg_precision": 0.7789039039039038,
            "eval_neg_recall": 0.7060224566178972,
            "eval_neu_f1": 0.543971787524796,
            "eval_neu_precision": 0.47996888370283936,
            "eval_neu_recall": 0.6276703967446592,
            "eval_pos_f1": 0.7333637192342753,
            "eval_pos_precision": 0.7930014785608674,
            "eval_pos_recall": 0.682068673166596,
            "eval_micro_f1": 0.6770374449339207,
            "eval_macro_f1": 0.6726700663566589,
            "eval_macro_precision": 0.6839580535888672,
            "eval_macro_recall": 0.6719204783439636,
            "eval_acc": 0.6770374449339207,
            "eval_runtime": 10.7991,
            "eval_samples_per_second": 672.646,
            "eval_steps_per_second": 42.04,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8821548819541931,
            "eval_neg_f1": 0.7469796341042457,
            "eval_neg_precision": 0.7579684763572679,
            "eval_neg_recall": 0.7363048656005444,
            "eval_neu_f1": 0.535224153705398,
            "eval_neu_precision": 0.486284289276808,
            "eval_neu_recall": 0.595116988809766,
            "eval_pos_f1": 0.7299403943145346,
            "eval_pos_precision": 0.7948077883175237,
            "eval_pos_recall": 0.6748622297583722,
            "eval_micro_f1": 0.6781387665198237,
            "eval_macro_f1": 0.6707146763801575,
            "eval_macro_precision": 0.6796868443489075,
            "eval_macro_recall": 0.6687613129615784,
            "eval_acc": 0.6781387665198237,
            "eval_runtime": 10.5746,
            "eval_samples_per_second": 686.928,
            "eval_steps_per_second": 42.933,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0315086841583252,
            "eval_neg_f1": 0.7378157239416578,
            "eval_neg_precision": 0.7730152814014163,
            "eval_neg_recall": 0.7056822048315754,
            "eval_neu_f1": 0.5210401891252955,
            "eval_neu_precision": 0.48674911660777387,
            "eval_neu_recall": 0.560528992878942,
            "eval_pos_f1": 0.7399486740804107,
            "eval_pos_precision": 0.7466551575312904,
            "eval_pos_recall": 0.7333615938957185,
            "eval_micro_f1": 0.675385462555066,
            "eval_macro_f1": 0.6662681698799133,
            "eval_macro_precision": 0.6688065528869629,
            "eval_macro_recall": 0.6665242910385132,
            "eval_acc": 0.675385462555066,
            "eval_runtime": 10.1647,
            "eval_samples_per_second": 714.627,
            "eval_steps_per_second": 44.664,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.2415030002593994,
            "eval_others_f1": 0.7345597897503285,
            "eval_others_precision": 0.8043165467625899,
            "eval_others_recall": 0.6759371221281741,
            "eval_joy_f1": 0.6525198938992043,
            "eval_joy_precision": 0.6275510204081632,
            "eval_joy_recall": 0.6795580110497238,
            "eval_sadness_f1": 0.7441860465116279,
            "eval_sadness_precision": 0.6926406926406926,
            "eval_sadness_recall": 0.8040201005025126,
            "eval_anger_f1": 0.5493333333333332,
            "eval_anger_precision": 0.5024390243902439,
            "eval_anger_recall": 0.6058823529411764,
            "eval_surprise_f1": 0.41025641025641024,
            "eval_surprise_precision": 0.36363636363636365,
            "eval_surprise_recall": 0.47058823529411764,
            "eval_disgust_f1": 0.21212121212121215,
            "eval_disgust_precision": 0.21212121212121213,
            "eval_disgust_recall": 0.21212121212121213,
            "eval_fear_f1": 0.3921568627450981,
            "eval_fear_precision": 0.30303030303030304,
            "eval_fear_recall": 0.5555555555555556,
            "eval_micro_f1": 0.6660703637447823,
            "eval_macro_f1": 0.5278761982917786,
            "eval_macro_precision": 0.5008193254470825,
            "eval_macro_recall": 0.5719518065452576,
            "eval_acc": 0.6660703637447823,
            "eval_runtime": 4.4444,
            "eval_samples_per_second": 377.331,
            "eval_steps_per_second": 23.625,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.21929132938385,
            "eval_others_f1": 0.7436065573770493,
            "eval_others_precision": 0.8123209169054442,
            "eval_others_recall": 0.6856106408706167,
            "eval_joy_f1": 0.6746347941567065,
            "eval_joy_precision": 0.649616368286445,
            "eval_joy_recall": 0.7016574585635359,
            "eval_sadness_f1": 0.7442922374429223,
            "eval_sadness_precision": 0.6820083682008368,
            "eval_sadness_recall": 0.8190954773869347,
            "eval_anger_f1": 0.5736434108527132,
            "eval_anger_precision": 0.511520737327189,
            "eval_anger_recall": 0.6529411764705882,
            "eval_surprise_f1": 0.39436619718309857,
            "eval_surprise_precision": 0.3783783783783784,
            "eval_surprise_recall": 0.4117647058823529,
            "eval_disgust_f1": 0.163265306122449,
            "eval_disgust_precision": 0.25,
            "eval_disgust_recall": 0.12121212121212122,
            "eval_fear_f1": 0.33333333333333326,
            "eval_fear_precision": 0.23809523809523808,
            "eval_fear_recall": 0.5555555555555556,
            "eval_micro_f1": 0.6779964221824687,
            "eval_macro_f1": 0.5181631445884705,
            "eval_macro_precision": 0.5031343102455139,
            "eval_macro_recall": 0.5639767646789551,
            "eval_acc": 0.6779964221824687,
            "eval_runtime": 4.6682,
            "eval_samples_per_second": 359.237,
            "eval_steps_per_second": 22.492,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2240617275238037,
            "eval_others_f1": 0.7419141914191419,
            "eval_others_precision": 0.8168604651162791,
            "eval_others_recall": 0.6795646916565901,
            "eval_joy_f1": 0.6675094816687738,
            "eval_joy_precision": 0.6153846153846154,
            "eval_joy_recall": 0.7292817679558011,
            "eval_sadness_f1": 0.7565011820330969,
            "eval_sadness_precision": 0.7142857142857143,
            "eval_sadness_recall": 0.8040201005025126,
            "eval_anger_f1": 0.6,
            "eval_anger_precision": 0.555,
            "eval_anger_recall": 0.6529411764705882,
            "eval_surprise_f1": 0.39189189189189183,
            "eval_surprise_precision": 0.3625,
            "eval_surprise_recall": 0.4264705882352941,
            "eval_disgust_f1": 0.14814814814814814,
            "eval_disgust_precision": 0.19047619047619047,
            "eval_disgust_recall": 0.12121212121212122,
            "eval_fear_f1": 0.41509433962264153,
            "eval_fear_precision": 0.3142857142857143,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6803816338700059,
            "eval_macro_f1": 0.5315799117088318,
            "eval_macro_precision": 0.5098274946212769,
            "eval_macro_recall": 0.5749430656433105,
            "eval_acc": 0.6803816338700059,
            "eval_runtime": 4.476,
            "eval_samples_per_second": 374.667,
            "eval_steps_per_second": 23.459,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.176619052886963,
            "eval_others_f1": 0.7423352902804956,
            "eval_others_precision": 0.8059490084985835,
            "eval_others_recall": 0.6880290205562273,
            "eval_joy_f1": 0.6565096952908588,
            "eval_joy_precision": 0.6583333333333333,
            "eval_joy_recall": 0.6546961325966851,
            "eval_sadness_f1": 0.7566265060240964,
            "eval_sadness_precision": 0.7268518518518519,
            "eval_sadness_recall": 0.7889447236180904,
            "eval_anger_f1": 0.5251989389920425,
            "eval_anger_precision": 0.4782608695652174,
            "eval_anger_recall": 0.5823529411764706,
            "eval_surprise_f1": 0.38554216867469876,
            "eval_surprise_precision": 0.32653061224489793,
            "eval_surprise_recall": 0.47058823529411764,
            "eval_disgust_f1": 0.17073170731707318,
            "eval_disgust_precision": 0.14285714285714285,
            "eval_disgust_recall": 0.21212121212121213,
            "eval_fear_f1": 0.33898305084745767,
            "eval_fear_precision": 0.24390243902439024,
            "eval_fear_recall": 0.5555555555555556,
            "eval_micro_f1": 0.6624925462134764,
            "eval_macro_f1": 0.510846734046936,
            "eval_macro_precision": 0.4832408130168915,
            "eval_macro_recall": 0.5646125674247742,
            "eval_acc": 0.6624925462134764,
            "eval_runtime": 4.4913,
            "eval_samples_per_second": 373.386,
            "eval_steps_per_second": 23.378,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2625937461853027,
            "eval_others_f1": 0.7341772151898734,
            "eval_others_precision": 0.8175074183976261,
            "eval_others_recall": 0.6662636033857315,
            "eval_joy_f1": 0.675094816687737,
            "eval_joy_precision": 0.6223776223776224,
            "eval_joy_recall": 0.7375690607734806,
            "eval_sadness_f1": 0.7410926365795725,
            "eval_sadness_precision": 0.7027027027027027,
            "eval_sadness_recall": 0.7839195979899497,
            "eval_anger_f1": 0.5662337662337662,
            "eval_anger_precision": 0.5069767441860465,
            "eval_anger_recall": 0.6411764705882353,
            "eval_surprise_f1": 0.4161073825503355,
            "eval_surprise_precision": 0.38271604938271603,
            "eval_surprise_recall": 0.45588235294117646,
            "eval_disgust_f1": 0.07407407407407407,
            "eval_disgust_precision": 0.09523809523809523,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.3773584905660377,
            "eval_fear_precision": 0.2857142857142857,
            "eval_fear_recall": 0.5555555555555556,
            "eval_micro_f1": 0.6714370900417412,
            "eval_macro_f1": 0.5120197534561157,
            "eval_macro_precision": 0.48760467767715454,
            "eval_macro_recall": 0.5572817921638489,
            "eval_acc": 0.6714370900417412,
            "eval_runtime": 4.2498,
            "eval_samples_per_second": 394.605,
            "eval_steps_per_second": 24.707,
            "epoch": 5.0
        }
    ],
    "model_name": "models/checkpoint-46000/"
}