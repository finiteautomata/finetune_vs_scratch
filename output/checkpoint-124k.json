{
    "context_hate": [
        {
            "eval_loss": 0.07897384464740753,
            "eval_calls_f1": 0.6143790849673203,
            "eval_women_f1": 0.42142857142857143,
            "eval_lgbti_f1": 0.48484848484848486,
            "eval_racism_f1": 0.6307277628032345,
            "eval_class_f1": 0.44179104477611936,
            "eval_politics_f1": 0.5917721518987342,
            "eval_disabled_f1": 0.5051194539249146,
            "eval_appearance_f1": 0.7236679058240396,
            "eval_criminal_f1": 0.5890603085553998,
            "eval_mean_f1": 0.5558660626411438,
            "eval_mean_precision": 0.5271622538566589,
            "eval_mean_recall": 0.5924848914146423,
            "eval_hate_precision": 0.6633192389006343,
            "eval_hate_recall": 0.6983861992209237,
            "eval_hate_f1": 0.6804011927351586,
            "eval_runtime": 32.3481,
            "eval_samples_per_second": 350.654,
            "eval_steps_per_second": 21.918
        },
        {
            "eval_loss": 0.07979699969291687,
            "eval_calls_f1": 0.6054421768707483,
            "eval_women_f1": 0.45296167247386754,
            "eval_lgbti_f1": 0.4636118598382749,
            "eval_racism_f1": 0.6571699905033239,
            "eval_class_f1": 0.41496598639455784,
            "eval_politics_f1": 0.603225806451613,
            "eval_disabled_f1": 0.47798742138364775,
            "eval_appearance_f1": 0.7038834951456311,
            "eval_criminal_f1": 0.583883751651255,
            "eval_mean_f1": 0.5514591336250305,
            "eval_mean_precision": 0.5242457985877991,
            "eval_mean_recall": 0.5861084461212158,
            "eval_hate_precision": 0.6551543694400838,
            "eval_hate_recall": 0.6967167501391207,
            "eval_hate_f1": 0.6752966558791802,
            "eval_runtime": 32.7297,
            "eval_samples_per_second": 346.566,
            "eval_steps_per_second": 21.662
        },
        {
            "eval_loss": 0.0792999193072319,
            "eval_calls_f1": 0.6306620209059235,
            "eval_women_f1": 0.40559440559440557,
            "eval_lgbti_f1": 0.46994535519125685,
            "eval_racism_f1": 0.6468952734012976,
            "eval_class_f1": 0.46349206349206357,
            "eval_politics_f1": 0.611111111111111,
            "eval_disabled_f1": 0.5252525252525253,
            "eval_appearance_f1": 0.7172582619339045,
            "eval_criminal_f1": 0.6060606060606061,
            "eval_mean_f1": 0.5640302300453186,
            "eval_mean_precision": 0.5374724864959717,
            "eval_mean_recall": 0.5964534282684326,
            "eval_hate_precision": 0.6603970741901777,
            "eval_hate_recall": 0.7033945464663328,
            "eval_hate_f1": 0.6812180005389383,
            "eval_runtime": 33.4571,
            "eval_samples_per_second": 339.031,
            "eval_steps_per_second": 21.191
        },
        {
            "eval_loss": 0.07430283725261688,
            "eval_calls_f1": 0.6259259259259259,
            "eval_women_f1": 0.4066666666666667,
            "eval_lgbti_f1": 0.453781512605042,
            "eval_racism_f1": 0.6342857142857142,
            "eval_class_f1": 0.4382716049382716,
            "eval_politics_f1": 0.6303236797274275,
            "eval_disabled_f1": 0.4768211920529801,
            "eval_appearance_f1": 0.6948356807511737,
            "eval_criminal_f1": 0.5953757225433526,
            "eval_mean_f1": 0.5506985783576965,
            "eval_mean_precision": 0.5353328585624695,
            "eval_mean_recall": 0.5737714171409607,
            "eval_hate_precision": 0.6522666666666667,
            "eval_hate_recall": 0.6805787423483584,
            "eval_hate_f1": 0.6661220043572984,
            "eval_runtime": 33.7857,
            "eval_samples_per_second": 335.734,
            "eval_steps_per_second": 20.985
        },
        {
            "eval_loss": 0.07589663565158844,
            "eval_calls_f1": 0.6289517470881864,
            "eval_women_f1": 0.38148148148148153,
            "eval_lgbti_f1": 0.4857142857142857,
            "eval_racism_f1": 0.634508348794063,
            "eval_class_f1": 0.45714285714285713,
            "eval_politics_f1": 0.6063492063492063,
            "eval_disabled_f1": 0.46645367412140576,
            "eval_appearance_f1": 0.7203907203907203,
            "eval_criminal_f1": 0.5934065934065934,
            "eval_mean_f1": 0.552711009979248,
            "eval_mean_precision": 0.5290805101394653,
            "eval_mean_recall": 0.5848956108093262,
            "eval_hate_precision": 0.6657667386609071,
            "eval_hate_recall": 0.6861435726210351,
            "eval_hate_f1": 0.675801589476569,
            "eval_runtime": 33.6925,
            "eval_samples_per_second": 336.662,
            "eval_steps_per_second": 21.043
        }
    ],
    "hate": [
        {
            "eval_loss": 0.8132903575897217,
            "eval_ok_f1": 0.8143917761279269,
            "eval_ok_precision": 0.8791615289765722,
            "eval_ok_recall": 0.7585106382978724,
            "eval_hateful_f1": 0.7757073844030365,
            "eval_hateful_precision": 0.7122940430925222,
            "eval_hateful_recall": 0.8515151515151516,
            "eval_micro_f1": 0.796875,
            "eval_macro_f1": 0.7950495481491089,
            "eval_macro_precision": 0.7957277894020081,
            "eval_macro_recall": 0.8050129413604736,
            "eval_acc": 0.796875,
            "eval_runtime": 3.4066,
            "eval_samples_per_second": 469.68,
            "eval_steps_per_second": 29.355,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8244415521621704,
            "eval_ok_f1": 0.8092290377039955,
            "eval_ok_precision": 0.8590203106332138,
            "eval_ok_recall": 0.7648936170212766,
            "eval_hateful_f1": 0.7617709065354883,
            "eval_hateful_precision": 0.7103538663171691,
            "eval_hateful_recall": 0.8212121212121212,
            "eval_micro_f1": 0.788125,
            "eval_macro_f1": 0.7854999303817749,
            "eval_macro_precision": 0.7846870422363281,
            "eval_macro_recall": 0.7930528521537781,
            "eval_acc": 0.788125,
            "eval_runtime": 3.5562,
            "eval_samples_per_second": 449.923,
            "eval_steps_per_second": 28.12,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7888362407684326,
            "eval_ok_f1": 0.8191430161380079,
            "eval_ok_precision": 0.8588098016336057,
            "eval_ok_recall": 0.7829787234042553,
            "eval_hateful_f1": 0.7683535281539557,
            "eval_hateful_precision": 0.7254374158815612,
            "eval_hateful_recall": 0.8166666666666667,
            "eval_micro_f1": 0.796875,
            "eval_macro_f1": 0.7937482595443726,
            "eval_macro_precision": 0.7921236157417297,
            "eval_macro_recall": 0.7998226881027222,
            "eval_acc": 0.796875,
            "eval_runtime": 3.3346,
            "eval_samples_per_second": 479.817,
            "eval_steps_per_second": 29.989,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.786295473575592,
            "eval_ok_f1": 0.8176240936977133,
            "eval_ok_precision": 0.8593200468933178,
            "eval_ok_recall": 0.7797872340425532,
            "eval_hateful_f1": 0.767590618336887,
            "eval_hateful_precision": 0.7228915662650602,
            "eval_hateful_recall": 0.8181818181818182,
            "eval_micro_f1": 0.7956250000000001,
            "eval_macro_f1": 0.7926073670387268,
            "eval_macro_precision": 0.7911058068275452,
            "eval_macro_recall": 0.7989845275878906,
            "eval_acc": 0.795625,
            "eval_runtime": 3.6202,
            "eval_samples_per_second": 441.97,
            "eval_steps_per_second": 27.623,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7363095283508301,
            "eval_ok_f1": 0.7946167349327091,
            "eval_ok_precision": 0.88296488946684,
            "eval_ok_recall": 0.7223404255319149,
            "eval_hateful_f1": 0.7645875251509053,
            "eval_hateful_precision": 0.6859205776173285,
            "eval_hateful_recall": 0.8636363636363636,
            "eval_micro_f1": 0.780625,
            "eval_macro_f1": 0.7796021699905396,
            "eval_macro_precision": 0.7844427824020386,
            "eval_macro_recall": 0.7929884195327759,
            "eval_acc": 0.780625,
            "eval_runtime": 3.4688,
            "eval_samples_per_second": 461.259,
            "eval_steps_per_second": 28.829,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 1.0140355825424194,
            "eval_neg_f1": 0.752335624889829,
            "eval_neg_precision": 0.7805413313825896,
            "eval_neg_recall": 0.726097312010888,
            "eval_neu_f1": 0.5421960072595282,
            "eval_neu_precision": 0.4893529893529894,
            "eval_neu_recall": 0.6078331637843337,
            "eval_pos_f1": 0.7497189116258152,
            "eval_pos_precision": 0.7983716475095786,
            "eval_pos_recall": 0.7066553624417126,
            "eval_micro_f1": 0.6877753303964758,
            "eval_macro_f1": 0.6814168095588684,
            "eval_macro_precision": 0.6894219517707825,
            "eval_macro_recall": 0.6801953315734863,
            "eval_acc": 0.6877753303964758,
            "eval_runtime": 9.5078,
            "eval_samples_per_second": 764.002,
            "eval_steps_per_second": 47.75,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.0888839960098267,
            "eval_neg_f1": 0.7577836411609499,
            "eval_neg_precision": 0.7844136926438456,
            "eval_neg_recall": 0.7329023477373257,
            "eval_neu_f1": 0.536333802156587,
            "eval_neu_precision": 0.4973913043478261,
            "eval_neu_recall": 0.5818921668362157,
            "eval_pos_f1": 0.754642779112956,
            "eval_pos_precision": 0.778629395852119,
            "eval_pos_recall": 0.7320898685883849,
            "eval_micro_f1": 0.6917676211453745,
            "eval_macro_f1": 0.6829200387001038,
            "eval_macro_precision": 0.6868114471435547,
            "eval_macro_recall": 0.6822948455810547,
            "eval_acc": 0.6917676211453745,
            "eval_runtime": 9.9261,
            "eval_samples_per_second": 731.806,
            "eval_steps_per_second": 45.738,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.733742892742157,
            "eval_neg_f1": 0.7567084078711986,
            "eval_neg_precision": 0.7978121463598642,
            "eval_neg_recall": 0.7196325280707724,
            "eval_neu_f1": 0.5597014925373134,
            "eval_neu_precision": 0.4922779922779923,
            "eval_neu_recall": 0.6485249237029501,
            "eval_pos_f1": 0.7517115472387038,
            "eval_pos_precision": 0.8141374196737519,
            "eval_pos_recall": 0.6981771937261552,
            "eval_micro_f1": 0.693419603524229,
            "eval_macro_f1": 0.689373791217804,
            "eval_macro_precision": 0.7014091610908508,
            "eval_macro_recall": 0.6887782216072083,
            "eval_acc": 0.693419603524229,
            "eval_runtime": 10.5899,
            "eval_samples_per_second": 685.936,
            "eval_steps_per_second": 42.871,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7332988381385803,
            "eval_neg_f1": 0.764191390842051,
            "eval_neg_precision": 0.7704011065006916,
            "eval_neg_recall": 0.7580809799251446,
            "eval_neu_f1": 0.5513513513513513,
            "eval_neu_precision": 0.49474535165723527,
            "eval_neu_recall": 0.6225839267548321,
            "eval_pos_f1": 0.7418369743951139,
            "eval_pos_precision": 0.8319283456269758,
            "eval_pos_recall": 0.6693514200932599,
            "eval_micro_f1": 0.6925936123348018,
            "eval_macro_f1": 0.6857932209968567,
            "eval_macro_precision": 0.6990249752998352,
            "eval_macro_recall": 0.6833387017250061,
            "eval_acc": 0.6925936123348018,
            "eval_runtime": 10.2678,
            "eval_samples_per_second": 707.456,
            "eval_steps_per_second": 44.216,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7184465527534485,
            "eval_neg_f1": 0.7657336726039016,
            "eval_neg_precision": 0.763531799729364,
            "eval_neg_recall": 0.7679482817284791,
            "eval_neu_f1": 0.5399849586362496,
            "eval_neu_precision": 0.532377656945131,
            "eval_neu_recall": 0.5478128179043744,
            "eval_pos_f1": 0.76442721791559,
            "eval_pos_precision": 0.7768052516411379,
            "eval_pos_recall": 0.7524374735057228,
            "eval_micro_f1": 0.7033314977973568,
            "eval_macro_f1": 0.6900486350059509,
            "eval_macro_precision": 0.6909048557281494,
            "eval_macro_recall": 0.6893995404243469,
            "eval_acc": 0.7033314977973568,
            "eval_runtime": 10.2862,
            "eval_samples_per_second": 706.189,
            "eval_steps_per_second": 44.137,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.2149182558059692,
            "eval_others_f1": 0.7431192660550459,
            "eval_others_precision": 0.8111587982832618,
            "eval_others_recall": 0.6856106408706167,
            "eval_joy_f1": 0.6806833114323259,
            "eval_joy_precision": 0.6491228070175439,
            "eval_joy_recall": 0.7154696132596685,
            "eval_sadness_f1": 0.7761904761904761,
            "eval_sadness_precision": 0.7375565610859729,
            "eval_sadness_recall": 0.8190954773869347,
            "eval_anger_f1": 0.5721784776902887,
            "eval_anger_precision": 0.5165876777251185,
            "eval_anger_recall": 0.6411764705882353,
            "eval_surprise_f1": 0.40259740259740256,
            "eval_surprise_precision": 0.36046511627906974,
            "eval_surprise_recall": 0.45588235294117646,
            "eval_disgust_f1": 0.06557377049180328,
            "eval_disgust_precision": 0.07142857142857142,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.3529411764705882,
            "eval_fear_precision": 0.2727272727272727,
            "eval_fear_recall": 0.5,
            "eval_micro_f1": 0.6797853309481217,
            "eval_macro_f1": 0.5133262872695923,
            "eval_macro_precision": 0.4884352684020996,
            "eval_macro_recall": 0.5539772510528564,
            "eval_acc": 0.6797853309481217,
            "eval_runtime": 4.5074,
            "eval_samples_per_second": 372.052,
            "eval_steps_per_second": 23.295,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2103943824768066,
            "eval_others_f1": 0.7339084273390842,
            "eval_others_precision": 0.8132352941176471,
            "eval_others_recall": 0.6686819830713422,
            "eval_joy_f1": 0.6781002638522429,
            "eval_joy_precision": 0.648989898989899,
            "eval_joy_recall": 0.7099447513812155,
            "eval_sadness_f1": 0.7594339622641509,
            "eval_sadness_precision": 0.7155555555555555,
            "eval_sadness_recall": 0.8090452261306532,
            "eval_anger_f1": 0.57985257985258,
            "eval_anger_precision": 0.4978902953586498,
            "eval_anger_recall": 0.6941176470588235,
            "eval_surprise_f1": 0.38620689655172413,
            "eval_surprise_precision": 0.36363636363636365,
            "eval_surprise_recall": 0.4117647058823529,
            "eval_disgust_f1": 0.03636363636363636,
            "eval_disgust_precision": 0.045454545454545456,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.41379310344827586,
            "eval_fear_precision": 0.3,
            "eval_fear_recall": 0.6666666666666666,
            "eval_micro_f1": 0.6738223017292785,
            "eval_macro_f1": 0.5125226974487305,
            "eval_macro_precision": 0.4835374355316162,
            "eval_macro_recall": 0.5700749158859253,
            "eval_acc": 0.6738223017292785,
            "eval_runtime": 4.395,
            "eval_samples_per_second": 381.574,
            "eval_steps_per_second": 23.891,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1787734031677246,
            "eval_others_f1": 0.7343124165554072,
            "eval_others_precision": 0.819672131147541,
            "eval_others_recall": 0.6650544135429263,
            "eval_joy_f1": 0.6798516687268233,
            "eval_joy_precision": 0.6152125279642058,
            "eval_joy_recall": 0.7596685082872928,
            "eval_sadness_f1": 0.7621247113163973,
            "eval_sadness_precision": 0.7051282051282052,
            "eval_sadness_recall": 0.8291457286432161,
            "eval_anger_f1": 0.5940054495912807,
            "eval_anger_precision": 0.5532994923857868,
            "eval_anger_recall": 0.6411764705882353,
            "eval_surprise_f1": 0.39999999999999997,
            "eval_surprise_precision": 0.37662337662337664,
            "eval_surprise_recall": 0.4264705882352941,
            "eval_disgust_f1": 0.0851063829787234,
            "eval_disgust_precision": 0.14285714285714285,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.4727272727272727,
            "eval_fear_precision": 0.35135135135135137,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.6815742397137746,
            "eval_macro_f1": 0.5325897336006165,
            "eval_macro_precision": 0.5091634392738342,
            "eval_macro_recall": 0.5863348245620728,
            "eval_acc": 0.6815742397137746,
            "eval_runtime": 4.361,
            "eval_samples_per_second": 384.544,
            "eval_steps_per_second": 24.077,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.1494791507720947,
            "eval_others_f1": 0.7407407407407408,
            "eval_others_precision": 0.8175182481751825,
            "eval_others_recall": 0.6771463119709794,
            "eval_joy_f1": 0.6900129701686122,
            "eval_joy_precision": 0.6503667481662592,
            "eval_joy_recall": 0.7348066298342542,
            "eval_sadness_f1": 0.7673860911270984,
            "eval_sadness_precision": 0.7339449541284404,
            "eval_sadness_recall": 0.8040201005025126,
            "eval_anger_f1": 0.543010752688172,
            "eval_anger_precision": 0.5,
            "eval_anger_recall": 0.5941176470588235,
            "eval_surprise_f1": 0.358974358974359,
            "eval_surprise_precision": 0.3181818181818182,
            "eval_surprise_recall": 0.4117647058823529,
            "eval_disgust_f1": 0.13698630136986303,
            "eval_disgust_precision": 0.125,
            "eval_disgust_recall": 0.15151515151515152,
            "eval_fear_f1": 0.490566037735849,
            "eval_fear_precision": 0.37142857142857144,
            "eval_fear_recall": 0.7222222222222222,
            "eval_micro_f1": 0.6756112104949314,
            "eval_macro_f1": 0.532525360584259,
            "eval_macro_precision": 0.5023486018180847,
            "eval_macro_recall": 0.5850846171379089,
            "eval_acc": 0.6756112104949314,
            "eval_runtime": 4.3953,
            "eval_samples_per_second": 381.542,
            "eval_steps_per_second": 23.889,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.2336094379425049,
            "eval_others_f1": 0.7299270072992701,
            "eval_others_precision": 0.8088235294117647,
            "eval_others_recall": 0.6650544135429263,
            "eval_joy_f1": 0.676962676962677,
            "eval_joy_precision": 0.6337349397590362,
            "eval_joy_recall": 0.7265193370165746,
            "eval_sadness_f1": 0.7777777777777777,
            "eval_sadness_precision": 0.7488372093023256,
            "eval_sadness_recall": 0.8090452261306532,
            "eval_anger_f1": 0.5561224489795918,
            "eval_anger_precision": 0.49099099099099097,
            "eval_anger_recall": 0.6411764705882353,
            "eval_surprise_f1": 0.37837837837837834,
            "eval_surprise_precision": 0.35,
            "eval_surprise_recall": 0.4117647058823529,
            "eval_disgust_f1": 0.03448275862068965,
            "eval_disgust_precision": 0.04,
            "eval_disgust_recall": 0.030303030303030304,
            "eval_fear_f1": 0.3448275862068966,
            "eval_fear_precision": 0.25,
            "eval_fear_recall": 0.5555555555555556,
            "eval_micro_f1": 0.669051878354204,
            "eval_macro_f1": 0.49978262186050415,
            "eval_macro_precision": 0.47462669014930725,
            "eval_macro_recall": 0.548488438129425,
            "eval_acc": 0.669051878354204,
            "eval_runtime": 4.4709,
            "eval_samples_per_second": 375.092,
            "eval_steps_per_second": 23.485,
            "epoch": 5.0
        }
    ],
    "model_name": "models/checkpoint-124000/"
}