{
    "context_hate": [
        {
            "eval_loss": 0.07988955080509186,
            "eval_calls_f1": 0.66110183639399,
            "eval_women_f1": 0.43064182194616973,
            "eval_lgbti_f1": 0.4539877300613497,
            "eval_racism_f1": 0.6804733727810651,
            "eval_class_f1": 0.4915824915824916,
            "eval_politics_f1": 0.614334470989761,
            "eval_disabled_f1": 0.5743944636678201,
            "eval_appearance_f1": 0.7295285359801489,
            "eval_criminal_f1": 0.6274509803921567,
            "eval_mean_f1": 0.5848328471183777,
            "eval_mean_precision": 0.5875959992408752,
            "eval_mean_recall": 0.5905810594558716,
            "eval_hate_precision": 0.6940715883668904,
            "eval_hate_recall": 0.6905954368391765,
            "eval_hate_f1": 0.692329149232915,
            "eval_runtime": 34.2421,
            "eval_samples_per_second": 331.259,
            "eval_steps_per_second": 20.706
        },
        {
            "eval_loss": 0.07828860729932785,
            "eval_calls_f1": 0.6771929824561403,
            "eval_women_f1": 0.4159663865546218,
            "eval_lgbti_f1": 0.4666666666666667,
            "eval_racism_f1": 0.6844262295081966,
            "eval_class_f1": 0.4677966101694916,
            "eval_politics_f1": 0.6387959866220736,
            "eval_disabled_f1": 0.5522388059701493,
            "eval_appearance_f1": 0.7331670822942643,
            "eval_criminal_f1": 0.6185852981969486,
            "eval_mean_f1": 0.5838706493377686,
            "eval_mean_precision": 0.5882960557937622,
            "eval_mean_recall": 0.5829442143440247,
            "eval_hate_precision": 0.6943820224719102,
            "eval_hate_recall": 0.6878130217028381,
            "eval_hate_f1": 0.6910819122169417,
            "eval_runtime": 38.6359,
            "eval_samples_per_second": 293.587,
            "eval_steps_per_second": 18.351
        },
        {
            "eval_loss": 0.077285997569561,
            "eval_calls_f1": 0.6725978647686832,
            "eval_women_f1": 0.4116504854368932,
            "eval_lgbti_f1": 0.3713355048859935,
            "eval_racism_f1": 0.6692991115498519,
            "eval_class_f1": 0.488135593220339,
            "eval_politics_f1": 0.6042692939244664,
            "eval_disabled_f1": 0.542124542124542,
            "eval_appearance_f1": 0.6973848069738481,
            "eval_criminal_f1": 0.6171107994389902,
            "eval_mean_f1": 0.5637675523757935,
            "eval_mean_precision": 0.5713168382644653,
            "eval_mean_recall": 0.5644981861114502,
            "eval_hate_precision": 0.6733295259851514,
            "eval_hate_recall": 0.656093489148581,
            "eval_hate_f1": 0.664599774520857,
            "eval_runtime": 34.616,
            "eval_samples_per_second": 327.68,
            "eval_steps_per_second": 20.482
        }
    ],
    "hate": [
        {
            "eval_loss": 0.5632985830307007,
            "eval_ok_f1": 0.7601173020527859,
            "eval_ok_precision": 0.8470588235294118,
            "eval_ok_recall": 0.6893617021276596,
            "eval_hateful_f1": 0.7264214046822742,
            "eval_hateful_precision": 0.6502994011976048,
            "eval_hateful_recall": 0.8227272727272728,
            "eval_micro_f1": 0.7443750000000001,
            "eval_macro_f1": 0.7432693243026733,
            "eval_macro_precision": 0.7486791610717773,
            "eval_macro_recall": 0.7560445070266724,
            "eval_acc": 0.744375,
            "eval_runtime": 3.241,
            "eval_samples_per_second": 493.676,
            "eval_steps_per_second": 30.855,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.9285244941711426,
            "eval_ok_f1": 0.8063457330415755,
            "eval_ok_precision": 0.829954954954955,
            "eval_ok_recall": 0.7840425531914894,
            "eval_hateful_f1": 0.7419825072886298,
            "eval_hateful_precision": 0.7148876404494382,
            "eval_hateful_recall": 0.7712121212121212,
            "eval_micro_f1": 0.77875,
            "eval_macro_f1": 0.7741641402244568,
            "eval_macro_precision": 0.7724213004112244,
            "eval_macro_recall": 0.7776273488998413,
            "eval_acc": 0.77875,
            "eval_runtime": 3.2184,
            "eval_samples_per_second": 497.135,
            "eval_steps_per_second": 31.071,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.8964370489120483,
            "eval_ok_f1": 0.7837360047142016,
            "eval_ok_precision": 0.8784676354029062,
            "eval_ok_recall": 0.7074468085106383,
            "eval_hateful_f1": 0.7558216899534265,
            "eval_hateful_precision": 0.6737841043890866,
            "eval_hateful_recall": 0.8606060606060606,
            "eval_micro_f1": 0.770625,
            "eval_macro_f1": 0.769778847694397,
            "eval_macro_precision": 0.7761258482933044,
            "eval_macro_recall": 0.7840264439582825,
            "eval_acc": 0.770625,
            "eval_runtime": 3.0818,
            "eval_samples_per_second": 519.175,
            "eval_steps_per_second": 32.448,
            "epoch": 5.0
        }
    ],
    "sentiment": [
        {
            "eval_loss": 0.7300756573677063,
            "eval_neg_f1": 0.7601951899616591,
            "eval_neg_precision": 0.7792068595927116,
            "eval_neg_recall": 0.7420891459680163,
            "eval_neu_f1": 0.533832709113608,
            "eval_neu_precision": 0.5242766061794998,
            "eval_neu_recall": 0.5437436419125127,
            "eval_pos_f1": 0.7640543364681296,
            "eval_pos_precision": 0.7535037098103875,
            "eval_pos_recall": 0.77490462060195,
            "eval_micro_f1": 0.6990638766519823,
            "eval_macro_f1": 0.686027467250824,
            "eval_macro_precision": 0.6856624484062195,
            "eval_macro_recall": 0.6869125366210938,
            "eval_acc": 0.6990638766519823,
            "eval_runtime": 9.9595,
            "eval_samples_per_second": 729.355,
            "eval_steps_per_second": 45.585,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7341070771217346,
            "eval_neg_f1": 0.7537495640041856,
            "eval_neg_precision": 0.7731663685152057,
            "eval_neg_recall": 0.7352841102415788,
            "eval_neu_f1": 0.5375475285171102,
            "eval_neu_precision": 0.5044603033006244,
            "eval_neu_recall": 0.5752797558494405,
            "eval_pos_f1": 0.7540340165721763,
            "eval_pos_precision": 0.7763807813201616,
            "eval_pos_recall": 0.7329376854599406,
            "eval_micro_f1": 0.6912169603524229,
            "eval_macro_f1": 0.6817770004272461,
            "eval_macro_precision": 0.6846691966056824,
            "eval_macro_recall": 0.6811671257019043,
            "eval_acc": 0.6912169603524229,
            "eval_runtime": 9.9234,
            "eval_samples_per_second": 732.007,
            "eval_steps_per_second": 45.75,
            "epoch": 5.0
        },
        {
            "eval_loss": 0.7878579497337341,
            "eval_neg_f1": 0.7626593179469514,
            "eval_neg_precision": 0.7722357865364492,
            "eval_neg_recall": 0.7533174549166383,
            "eval_neu_f1": 0.5451092117758785,
            "eval_neu_precision": 0.5111308993766697,
            "eval_neu_recall": 0.5839267548321465,
            "eval_pos_f1": 0.7507760532150775,
            "eval_pos_precision": 0.7870757787075778,
            "eval_pos_recall": 0.7176769817719373,
            "eval_micro_f1": 0.695897577092511,
            "eval_macro_f1": 0.6861815452575684,
            "eval_macro_precision": 0.6901474595069885,
            "eval_macro_recall": 0.6849737167358398,
            "eval_acc": 0.695897577092511,
            "eval_runtime": 9.9878,
            "eval_samples_per_second": 727.289,
            "eval_steps_per_second": 45.456,
            "epoch": 5.0
        }
    ],
    "emotion": [
        {
            "eval_loss": 1.6051225662231445,
            "eval_others_f1": 0.7650340979541229,
            "eval_others_precision": 0.7849872773536896,
            "eval_others_recall": 0.7460701330108828,
            "eval_joy_f1": 0.6790450928381963,
            "eval_joy_precision": 0.6530612244897959,
            "eval_joy_recall": 0.7071823204419889,
            "eval_sadness_f1": 0.7506172839506173,
            "eval_sadness_precision": 0.7378640776699029,
            "eval_sadness_recall": 0.7638190954773869,
            "eval_anger_f1": 0.6356164383561644,
            "eval_anger_precision": 0.5948717948717949,
            "eval_anger_recall": 0.6823529411764706,
            "eval_surprise_f1": 0.421875,
            "eval_surprise_precision": 0.45,
            "eval_surprise_recall": 0.39705882352941174,
            "eval_disgust_f1": 0.09090909090909091,
            "eval_disgust_precision": 0.18181818181818182,
            "eval_disgust_recall": 0.06060606060606061,
            "eval_fear_f1": 0.4444444444444445,
            "eval_fear_precision": 0.37037037037037035,
            "eval_fear_recall": 0.5555555555555556,
            "eval_micro_f1": 0.7036374478234944,
            "eval_macro_f1": 0.5410773158073425,
            "eval_macro_precision": 0.5389961004257202,
            "eval_macro_recall": 0.55894935131073,
            "eval_acc": 0.7036374478234944,
            "eval_runtime": 3.4723,
            "eval_samples_per_second": 482.97,
            "eval_steps_per_second": 30.24,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.525099515914917,
            "eval_others_f1": 0.767911818738518,
            "eval_others_precision": 0.7779156327543424,
            "eval_others_recall": 0.7581620314389359,
            "eval_joy_f1": 0.6927223719676551,
            "eval_joy_precision": 0.6763157894736842,
            "eval_joy_recall": 0.7099447513812155,
            "eval_sadness_f1": 0.7572815533980582,
            "eval_sadness_precision": 0.7323943661971831,
            "eval_sadness_recall": 0.7839195979899497,
            "eval_anger_f1": 0.64,
            "eval_anger_precision": 0.6222222222222222,
            "eval_anger_recall": 0.6588235294117647,
            "eval_surprise_f1": 0.4132231404958678,
            "eval_surprise_precision": 0.4716981132075472,
            "eval_surprise_recall": 0.36764705882352944,
            "eval_disgust_f1": 0.12000000000000001,
            "eval_disgust_precision": 0.17647058823529413,
            "eval_disgust_recall": 0.09090909090909091,
            "eval_fear_f1": 0.4782608695652174,
            "eval_fear_precision": 0.39285714285714285,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.7101967799642218,
            "eval_macro_f1": 0.5527713894844055,
            "eval_macro_precision": 0.549981951713562,
            "eval_macro_recall": 0.5686452984809875,
            "eval_acc": 0.7101967799642218,
            "eval_runtime": 3.67,
            "eval_samples_per_second": 456.943,
            "eval_steps_per_second": 28.61,
            "epoch": 5.0
        },
        {
            "eval_loss": 1.654165267944336,
            "eval_others_f1": 0.7520299812617115,
            "eval_others_precision": 0.7777777777777778,
            "eval_others_recall": 0.727932285368803,
            "eval_joy_f1": 0.6823529411764706,
            "eval_joy_precision": 0.6476426799007444,
            "eval_joy_recall": 0.7209944751381215,
            "eval_sadness_f1": 0.7602905569007264,
            "eval_sadness_precision": 0.7336448598130841,
            "eval_sadness_recall": 0.7889447236180904,
            "eval_anger_f1": 0.6171428571428571,
            "eval_anger_precision": 0.6,
            "eval_anger_recall": 0.6352941176470588,
            "eval_surprise_f1": 0.3902439024390244,
            "eval_surprise_precision": 0.43636363636363634,
            "eval_surprise_recall": 0.35294117647058826,
            "eval_disgust_f1": 0.10526315789473685,
            "eval_disgust_precision": 0.125,
            "eval_disgust_recall": 0.09090909090909091,
            "eval_fear_f1": 0.4888888888888889,
            "eval_fear_precision": 0.4074074074074074,
            "eval_fear_recall": 0.6111111111111112,
            "eval_micro_f1": 0.6952892069171139,
            "eval_macro_f1": 0.5423160791397095,
            "eval_macro_precision": 0.5325480103492737,
            "eval_macro_recall": 0.5611609816551208,
            "eval_acc": 0.6952892069171139,
            "eval_runtime": 3.7005,
            "eval_samples_per_second": 453.179,
            "eval_steps_per_second": 28.374,
            "epoch": 5.0
        }
    ],
    "model_name": "models/beto-uncased-15000-last/"
}